
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>barotropy.mcerp.stats module &#8212; barotropy v0.2.4 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=880b6864"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'source/api/barotropy.mcerp.stats';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">barotropy v0.2.4 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../tutorials.html">Tutorials</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/flashing_nozzle_fluent.html">Flashing nozzle Fluent tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials/centrifugal_impeller_cfx.html">Centrifugal impeller CFX tutorial</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../barotropic_model.html">Barotropic model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">Bibliography</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="barotropy.html">API Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="barotropy.barotropic_model.html">Barotropic model</a></li>
<li class="toctree-l2"><a class="reference internal" href="barotropy.properties.html">Fluid properties</a></li>

<li class="toctree-l2"><a class="reference internal" href="barotropy.math.html">Math functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="barotropy.graphics.html">Graphic functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="barotropy.utilities.html">Utility functions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="barotropy.fluent_automation.html">Fluent automation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="barotropy.fluent_automation.fluent_automation.html">barotropy.fluent_automation.fluent_automation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="barotropy.fluent_automation.fluent_plot_nozzle_data.html">barotropy.fluent_automation.fluent_plot_nozzle_data module</a></li>
<li class="toctree-l3"><a class="reference internal" href="barotropy.fluent_automation.stream_residuals.html">barotropy.fluent_automation.stream_residuals module</a></li>
<li class="toctree-l3"><a class="reference internal" href="barotropy.fluent_automation.stream_transcript.html">barotropy.fluent_automation.stream_transcript module</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/source/api/barotropy.mcerp.stats.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>barotropy.mcerp.stats module</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mcerp-real-time-latin-hypercube-sampling-based-monte-carlo-error-propagation">mcerp: Real-time latin-hypercube-sampling-based Monte Carlo Error Propagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.anderson"><code class="docutils literal notranslate"><span class="pre">anderson()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ansari"><code class="docutils literal notranslate"><span class="pre">ansari()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.bartlett"><code class="docutils literal notranslate"><span class="pre">bartlett()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.bayes_mvs"><code class="docutils literal notranslate"><span class="pre">bayes_mvs()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.binom_test"><code class="docutils literal notranslate"><span class="pre">binom_test()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.chisquare"><code class="docutils literal notranslate"><span class="pre">chisquare()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.describe"><code class="docutils literal notranslate"><span class="pre">describe()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.f_oneway"><code class="docutils literal notranslate"><span class="pre">f_oneway()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.fligner"><code class="docutils literal notranslate"><span class="pre">fligner()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.friedmanchisquare"><code class="docutils literal notranslate"><span class="pre">friedmanchisquare()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.gmean"><code class="docutils literal notranslate"><span class="pre">gmean()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.hmean"><code class="docutils literal notranslate"><span class="pre">hmean()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kendalltau"><code class="docutils literal notranslate"><span class="pre">kendalltau()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kruskal"><code class="docutils literal notranslate"><span class="pre">kruskal()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ks_2samp"><code class="docutils literal notranslate"><span class="pre">ks_2samp()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kstest"><code class="docutils literal notranslate"><span class="pre">kstest()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kurtosis"><code class="docutils literal notranslate"><span class="pre">kurtosis()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kurtosistest"><code class="docutils literal notranslate"><span class="pre">kurtosistest()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.levene"><code class="docutils literal notranslate"><span class="pre">levene()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.linregress"><code class="docutils literal notranslate"><span class="pre">linregress()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.mannwhitneyu"><code class="docutils literal notranslate"><span class="pre">mannwhitneyu()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.mode"><code class="docutils literal notranslate"><span class="pre">mode()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.moment"><code class="docutils literal notranslate"><span class="pre">moment()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.mood"><code class="docutils literal notranslate"><span class="pre">mood()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.normaltest"><code class="docutils literal notranslate"><span class="pre">normaltest()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.pearsonr"><code class="docutils literal notranslate"><span class="pre">pearsonr()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.percentileofscore"><code class="docutils literal notranslate"><span class="pre">percentileofscore()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.pointbiserialr"><code class="docutils literal notranslate"><span class="pre">pointbiserialr()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.rankdata"><code class="docutils literal notranslate"><span class="pre">rankdata()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ranksums"><code class="docutils literal notranslate"><span class="pre">ranksums()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.scoreatpercentile"><code class="docutils literal notranslate"><span class="pre">scoreatpercentile()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.sem"><code class="docutils literal notranslate"><span class="pre">sem()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.shapiro"><code class="docutils literal notranslate"><span class="pre">shapiro()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.skew"><code class="docutils literal notranslate"><span class="pre">skew()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.skewtest"><code class="docutils literal notranslate"><span class="pre">skewtest()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.spearmanr"><code class="docutils literal notranslate"><span class="pre">spearmanr()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tmax"><code class="docutils literal notranslate"><span class="pre">tmax()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tmean"><code class="docutils literal notranslate"><span class="pre">tmean()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tmin"><code class="docutils literal notranslate"><span class="pre">tmin()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tsem"><code class="docutils literal notranslate"><span class="pre">tsem()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tstd"><code class="docutils literal notranslate"><span class="pre">tstd()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ttest_1samp"><code class="docutils literal notranslate"><span class="pre">ttest_1samp()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ttest_ind"><code class="docutils literal notranslate"><span class="pre">ttest_ind()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ttest_rel"><code class="docutils literal notranslate"><span class="pre">ttest_rel()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tvar"><code class="docutils literal notranslate"><span class="pre">tvar()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.variation"><code class="docutils literal notranslate"><span class="pre">variation()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.wilcoxon"><code class="docutils literal notranslate"><span class="pre">wilcoxon()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.wrap"><code class="docutils literal notranslate"><span class="pre">wrap()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.zmap"><code class="docutils literal notranslate"><span class="pre">zmap()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.zscore"><code class="docutils literal notranslate"><span class="pre">zscore()</span></code></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="module-barotropy.mcerp.stats">
<span id="barotropy-mcerp-stats-module"></span><h1>barotropy.mcerp.stats module<a class="headerlink" href="#module-barotropy.mcerp.stats" title="Link to this heading">#</a></h1>
<section id="mcerp-real-time-latin-hypercube-sampling-based-monte-carlo-error-propagation">
<h2>mcerp: Real-time latin-hypercube-sampling-based Monte Carlo Error Propagation<a class="headerlink" href="#mcerp-real-time-latin-hypercube-sampling-based-monte-carlo-error-propagation" title="Link to this heading">#</a></h2>
<p>Generalizes many statistical functions that work on numeric objects (from the 
scipy.stats module) to be compatible with objects defined by statistical
distributions.</p>
<p>NOTE: Although all of these functions can be used without this import, this 
package was created for convenience and transparent operation. For usage,
see the respective documentation at</p>
<p><a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/stats.html#statistical-functions">http://docs.scipy.org/doc/scipy/reference/stats.html#statistical-functions</a></p>
<p>Author: Abraham Lee
Copyright: 2013</p>
</section>
<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.anderson">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">anderson</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.anderson" title="Link to this definition">#</a></dt>
<dd><p>Anderson-Darling test for data coming from a particular distribution.</p>
<p>The Anderson-Darling test tests the null hypothesis that a sample is
drawn from a population that follows a particular distribution.
For the Anderson-Darling test, the critical values depend on
which distribution is being tested against.  This function works
for normal, exponential, logistic, weibull_min, or Gumbel (Extreme Value
Type I) distributions.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">array_like</span></dt><dd><p>Array of sample data.</p>
</dd>
<dt><strong>dist</strong><span class="classifier">{‘norm’, ‘expon’, ‘logistic’, ‘gumbel’, ‘gumbel_l’, ‘gumbel_r’, ‘extreme1’, ‘weibull_min’}, optional</span></dt><dd><p>The type of distribution to test against.  The default is ‘norm’.
The names ‘extreme1’, ‘gumbel_l’ and ‘gumbel’ are synonyms for the
same distribution.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>result</strong><span class="classifier">AndersonResult</span></dt><dd><p>An object with the following attributes:</p>
<dl>
<dt>statistic<span class="classifier">float</span></dt><dd><p>The Anderson-Darling test statistic.</p>
</dd>
<dt>critical_values<span class="classifier">list</span></dt><dd><p>The critical values for this distribution.</p>
</dd>
<dt>significance_level<span class="classifier">list</span></dt><dd><p>The significance levels for the corresponding critical values
in percents.  The function returns critical values for a
differing set of significance levels depending on the
distribution that is being tested against.</p>
</dd>
<dt>fit_result<span class="classifier"><cite>~scipy.stats._result_classes.FitResult</cite></span></dt><dd><p>An object containing the results of fitting the distribution to
the data.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.kstest" title="barotropy.mcerp.stats.kstest"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kstest</span></code></a></dt><dd><p>The Kolmogorov-Smirnov test for goodness-of-fit.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Critical values provided are for the following significance levels:</p>
<dl class="simple">
<dt>normal/exponential</dt><dd><p>15%, 10%, 5%, 2.5%, 1%</p>
</dd>
<dt>logistic</dt><dd><p>25%, 10%, 5%, 2.5%, 1%, 0.5%</p>
</dd>
<dt>gumbel_l / gumbel_r</dt><dd><p>25%, 10%, 5%, 2.5%, 1%</p>
</dd>
<dt>weibull_min</dt><dd><p>50%, 25%, 15%, 10%, 5%, 2.5%, 1%, 0.5%</p>
</dd>
</dl>
<p>If the returned statistic is larger than these critical values then
for the corresponding significance level, the null hypothesis that
the data come from the chosen distribution can be rejected.
The returned statistic is referred to as ‘A2’ in the references.</p>
<p>For <cite>weibull_min</cite>, maximum likelihood estimation is known to be
challenging. If the test returns successfully, then the first order
conditions for a maximum likelihood estimate have been verified and
the critical values correspond relatively well to the significance levels,
provided that the sample is sufficiently large (&gt;10 observations [7]).
However, for some data - especially data with no left tail - <cite>anderson</cite>
is likely to result in an error message. In this case, consider
performing a custom goodness of fit test using
<cite>scipy.stats.monte_carlo_test</cite>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r3e675864f9de-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm">https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm</a></p>
</div>
<div class="citation" id="r3e675864f9de-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Stephens, M. A. (1974). EDF Statistics for Goodness of Fit and
Some Comparisons, Journal of the American Statistical Association,
Vol. 69, pp. 730-737.</p>
</div>
<div class="citation" id="r3e675864f9de-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>Stephens, M. A. (1976). Asymptotic Results for Goodness-of-Fit
Statistics with Unknown Parameters, Annals of Statistics, Vol. 4,
pp. 357-369.</p>
</div>
<div class="citation" id="r3e675864f9de-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>Stephens, M. A. (1977). Goodness of Fit for the Extreme Value
Distribution, Biometrika, Vol. 64, pp. 583-588.</p>
</div>
<div class="citation" id="r3e675864f9de-5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></span>
<p>Stephens, M. A. (1977). Goodness of Fit with Special Reference
to Tests for Exponentiality , Technical Report No. 262,
Department of Statistics, Stanford University, Stanford, CA.</p>
</div>
<div class="citation" id="r3e675864f9de-6" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></span>
<p>Stephens, M. A. (1979). Tests of Fit for the Logistic Distribution
Based on the Empirical Distribution Function, Biometrika, Vol. 66,
pp. 591-595.</p>
</div>
<div class="citation" id="r3e675864f9de-7" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></span>
<p>Richard A. Lockhart and Michael A. Stephens “Estimation and Tests of
Fit for the Three-Parameter Weibull Distribution”
Journal of the Royal Statistical Society.Series B(Methodological)
Vol. 56, No. 3 (1994), pp. 491-500, Table 0.</p>
</div>
</div>
<p class="rubric">Examples</p>
<p>Test the null hypothesis that a random sample was drawn from a normal
distribution (with unspecified mean and standard deviation).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">anderson</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">35</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">anderson</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">0.8398018749744764</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">critical_values</span>
<span class="go">array([0.527, 0.6  , 0.719, 0.839, 0.998])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">significance_level</span>
<span class="go">array([15. , 10. ,  5. ,  2.5,  1. ])</span>
</pre></div>
</div>
<p>The value of the statistic (barely) exceeds the critical value associated
with a significance level of 2.5%, so the null hypothesis may be rejected
at a significance level of 2.5%, but not at a significance level of 1%.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.ansari">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">ansari</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.ansari" title="Link to this definition">#</a></dt>
<dd><p>Perform the Ansari-Bradley test for equal scale parameters.</p>
<p>The Ansari-Bradley test (<a class="reference internal" href="#ra847194dd0cf-1" id="id8">[1]</a>, <a class="reference internal" href="#ra847194dd0cf-2" id="id9">[2]</a>) is a non-parametric test
for the equality of the scale parameter of the distributions
from which two samples were drawn. The null hypothesis states that
the ratio of the scale of the distribution underlying <cite>x</cite> to the scale
of the distribution underlying <cite>y</cite> is 1.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x, y</strong><span class="classifier">array_like</span></dt><dd><p>Arrays of sample data.</p>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
The following options are available:</p>
<ul class="simple">
<li><p>‘two-sided’: the ratio of scales is not equal to 1.</p></li>
<li><p>‘less’: the ratio of scales is less than 1.</p></li>
<li><p>‘greater’: the ratio of scales is greater than 1.</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.7.0.</span></p>
</div>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The Ansari-Bradley test statistic.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The p-value of the hypothesis test.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.fligner" title="barotropy.mcerp.stats.fligner"><code class="xref py py-func docutils literal notranslate"><span class="pre">fligner()</span></code></a></dt><dd><p>A non-parametric test for the equality of k variances</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.mood" title="barotropy.mcerp.stats.mood"><code class="xref py py-func docutils literal notranslate"><span class="pre">mood()</span></code></a></dt><dd><p>A non-parametric test for the equality of two scale parameters</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The p-value given is exact when the sample sizes are both less than
55 and there are no ties, otherwise a normal approximation for the
p-value is used.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="ra847194dd0cf-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">1</a><span class="fn-bracket">]</span></span>
<p>Ansari, A. R. and Bradley, R. A. (1960) Rank-sum tests for
dispersions, Annals of Mathematical Statistics, 31, 1174-1189.</p>
</div>
<div class="citation" id="ra847194dd0cf-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">2</a><span class="fn-bracket">]</span></span>
<p>Sprent, Peter and N.C. Smeeton.  Applied nonparametric
statistical methods.  3rd ed. Chapman and Hall/CRC. 2001.
Section 5.8.2.</p>
</div>
<div class="citation" id="ra847194dd0cf-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>Nathaniel E. Helwig “Nonparametric Dispersion and Equality
Tests” at <a class="reference external" href="http://users.stat.umn.edu/~helwig/notes/npde-Notes.pdf">http://users.stat.umn.edu/~helwig/notes/npde-Notes.pdf</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">ansari</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
</pre></div>
</div>
<p>For these examples, we’ll create three random data sets.  The first
two, with sizes 35 and 25, are drawn from a normal distribution with
mean 0 and standard deviation 2.  The third data set has size 25 and
is drawn from a normal distribution with standard deviation 1.25.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">35</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x3</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.25</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
<p>First we apply <cite>ansari</cite> to <cite>x1</cite> and <cite>x2</cite>.  These samples are drawn
from the same distribution, so we expect the Ansari-Bradley test
should not lead us to conclude that the scales of the distributions
are different.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ansari</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
<span class="go">AnsariResult(statistic=541.0, pvalue=0.9762532927399098)</span>
</pre></div>
</div>
<p>With a p-value close to 1, we cannot conclude that there is a
significant difference in the scales (as expected).</p>
<p>Now apply the test to <cite>x1</cite> and <cite>x3</cite>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ansari</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x3</span><span class="p">)</span>
<span class="go">AnsariResult(statistic=425.0, pvalue=0.0003087020407974518)</span>
</pre></div>
</div>
<p>The probability of observing such an extreme value of the statistic
under the null hypothesis of equal scales is only 0.03087%. We take this
as evidence against the null hypothesis in favor of the alternative:
the scales of the distributions from which the samples were drawn
are not equal.</p>
<p>We can use the <cite>alternative</cite> parameter to perform a one-tailed test.
In the above example, the scale of <cite>x1</cite> is greater than <cite>x3</cite> and so
the ratio of scales of <cite>x1</cite> and <cite>x3</cite> is greater than 1. This means
that the p-value when <code class="docutils literal notranslate"><span class="pre">alternative='greater'</span></code> should be near 0 and
hence we should be able to reject the null hypothesis:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ansari</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="go">AnsariResult(statistic=425.0, pvalue=0.0001543510203987259)</span>
</pre></div>
</div>
<p>As we can see, the p-value is indeed quite low. Use of
<code class="docutils literal notranslate"><span class="pre">alternative='less'</span></code> should thus yield a large p-value:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ansari</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;less&#39;</span><span class="p">)</span>
<span class="go">AnsariResult(statistic=425.0, pvalue=0.9998643258449039)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.bartlett">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">bartlett</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.bartlett" title="Link to this definition">#</a></dt>
<dd><p>Perform Bartlett’s test for equal variances.</p>
<p>Bartlett’s test tests the null hypothesis that all input samples
are from populations with equal variances.  For samples
from significantly non-normal populations, Levene’s test
<cite>levene</cite> is more robust.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample1, sample2, …</strong><span class="classifier">array_like</span></dt><dd><p>arrays of sample data.  Only 1d arrays are accepted, they may have
different lengths.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The test statistic.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The p-value of the test.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.fligner" title="barotropy.mcerp.stats.fligner"><code class="xref py py-func docutils literal notranslate"><span class="pre">fligner()</span></code></a></dt><dd><p>A non-parametric test for the equality of k variances</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.levene" title="barotropy.mcerp.stats.levene"><code class="xref py py-func docutils literal notranslate"><span class="pre">levene()</span></code></a></dt><dd><p>A robust parametric test for equality of k variances</p>
</dd>
<dt><span class="xref std std-ref">hypothesis_bartlett</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Conover et al. (1981) examine many of the existing parametric and
nonparametric tests by extensive simulations and they conclude that the
tests proposed by Fligner and Killeen (1976) and Levene (1960) appear to be
superior in terms of robustness of departures from normality and power
(<a class="reference internal" href="#r3af82847476e-3" id="id13">[3]</a>).</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r3af82847476e-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm">https://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm</a></p>
</div>
<div class="citation" id="r3af82847476e-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Snedecor, George W. and Cochran, William G. (1989), Statistical
Methods, Eighth Edition, Iowa State University Press.</p>
</div>
<div class="citation" id="r3af82847476e-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id13">3</a><span class="fn-bracket">]</span></span>
<p>Park, C. and Lindsay, B. G. (1999). Robust Scale Estimation and
Hypothesis Testing based on Quadratic Inference Function. Technical
Report #99-03, Center for Likelihood Studies, Pennsylvania State
University.</p>
</div>
<div class="citation" id="r3af82847476e-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>Bartlett, M. S. (1937). Properties of Sufficiency and Statistical
Tests. Proceedings of the Royal Society of London. Series A,
Mathematical and Physical Sciences, Vol. 160, No.901, pp. 268-282.</p>
</div>
</div>
<p class="rubric">Examples</p>
<p>Test whether the lists <cite>a</cite>, <cite>b</cite> and <cite>c</cite> come from populations
with equal variances.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.88</span><span class="p">,</span> <span class="mf">9.12</span><span class="p">,</span> <span class="mf">9.04</span><span class="p">,</span> <span class="mf">8.98</span><span class="p">,</span> <span class="mf">9.00</span><span class="p">,</span> <span class="mf">9.08</span><span class="p">,</span> <span class="mf">9.01</span><span class="p">,</span> <span class="mf">8.85</span><span class="p">,</span> <span class="mf">9.06</span><span class="p">,</span> <span class="mf">8.99</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.88</span><span class="p">,</span> <span class="mf">8.95</span><span class="p">,</span> <span class="mf">9.29</span><span class="p">,</span> <span class="mf">9.44</span><span class="p">,</span> <span class="mf">9.15</span><span class="p">,</span> <span class="mf">9.58</span><span class="p">,</span> <span class="mf">8.36</span><span class="p">,</span> <span class="mf">9.18</span><span class="p">,</span> <span class="mf">8.67</span><span class="p">,</span> <span class="mf">9.05</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.95</span><span class="p">,</span> <span class="mf">9.12</span><span class="p">,</span> <span class="mf">8.95</span><span class="p">,</span> <span class="mf">8.85</span><span class="p">,</span> <span class="mf">9.03</span><span class="p">,</span> <span class="mf">8.84</span><span class="p">,</span> <span class="mf">9.07</span><span class="p">,</span> <span class="mf">8.98</span><span class="p">,</span> <span class="mf">8.86</span><span class="p">,</span> <span class="mf">8.98</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stat</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">bartlett</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span>
<span class="go">1.1254782518834628e-05</span>
</pre></div>
</div>
<p>The very small p-value suggests that the populations do not have equal
variances.</p>
<p>This is not surprising, given that the sample variance of <cite>b</cite> is much
larger than that of <cite>a</cite> and <cite>c</cite>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">]]</span>
<span class="go">[0.007054444444444413, 0.13073888888888888, 0.008890000000000002]</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_bartlett</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.bayes_mvs">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">bayes_mvs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.bayes_mvs" title="Link to this definition">#</a></dt>
<dd><p>Bayesian confidence intervals for the mean, var, and std.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>data</strong><span class="classifier">array_like</span></dt><dd><p>Input data, if multi-dimensional it is flattened to 1-D by <cite>bayes_mvs</cite>.
Requires 2 or more data points.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, optional</span></dt><dd><p>Probability that the returned confidence interval contains
the true parameter.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>mean_cntr, var_cntr, std_cntr</strong><span class="classifier">tuple</span></dt><dd><p>The three results are for the mean, variance and standard deviation,
respectively.  Each result is a tuple of the form:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">center</span><span class="p">,</span> <span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">))</span>
</pre></div>
</div>
<p>with <code class="docutils literal notranslate"><span class="pre">center</span></code> the mean of the conditional pdf of the value given the
data, and <code class="docutils literal notranslate"><span class="pre">(lower,</span> <span class="pre">upper)</span></code> a confidence interval, centered on the
median, containing the estimate to a probability <code class="docutils literal notranslate"><span class="pre">alpha</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">mvsdist</span></code></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Each tuple of mean, variance, and standard deviation estimates represent
the (center, (lower, upper)) with center the mean of the conditional pdf
of the value given the data and (lower, upper) is a confidence interval
centered on the median, containing the estimate to a probability
<code class="docutils literal notranslate"><span class="pre">alpha</span></code>.</p>
<p>Converts data to 1-D and assumes all data has the same mean and variance.
Uses Jeffrey’s prior for variance and std.</p>
<p>Equivalent to <code class="docutils literal notranslate"><span class="pre">tuple((x.mean(),</span> <span class="pre">x.interval(alpha))</span> <span class="pre">for</span> <span class="pre">x</span> <span class="pre">in</span> <span class="pre">mvsdist(dat))</span></code></p>
<p class="rubric">References</p>
<p>T.E. Oliphant, “A Bayesian perspective on estimating mean, variance, and
standard-deviation from data”, <a class="reference external" href="https://scholarsarchive.byu.edu/facpub/278">https://scholarsarchive.byu.edu/facpub/278</a>,
2006.</p>
<p class="rubric">Examples</p>
<p>First a basic example to demonstrate the outputs:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">13</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">bayes_mvs</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mean</span>
<span class="go">Mean(statistic=9.0, minmax=(7.103650222612533, 10.896349777387467))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">var</span>
<span class="go">Variance(statistic=10.0, minmax=(3.176724206, 24.45910382))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">std</span>
<span class="go">Std_dev(statistic=2.9724954732045084,</span>
<span class="go">        minmax=(1.7823367265645143, 4.945614605014631))</span>
</pre></div>
</div>
<p>Now we generate some normally distributed random data, and get estimates of
mean and standard deviation with 95% confidence intervals for those
estimates:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res_mean</span><span class="p">,</span> <span class="n">res_var</span><span class="p">,</span> <span class="n">res_std</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">bayes_mvs</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Histogram of data&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">res_mean</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Estimated mean&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">axvspan</span><span class="p">(</span><span class="n">res_mean</span><span class="o">.</span><span class="n">minmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">res_mean</span><span class="o">.</span><span class="n">minmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span>
<span class="gp">... </span>           <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;Estimated mean (95</span><span class="si">% li</span><span class="s1">mits)&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">res_std</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Estimated scale&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">axvspan</span><span class="p">(</span><span class="n">res_std</span><span class="o">.</span><span class="n">minmax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">res_std</span><span class="o">.</span><span class="n">minmax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
<span class="gp">... </span>           <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;Estimated scale (95</span><span class="si">% li</span><span class="s1">mits)&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.binom_test">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">binom_test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.binom_test" title="Link to this definition">#</a></dt>
<dd><p>Perform a test that the probability of success is p.</p>
<p>The binomial test <a class="reference internal" href="#r64899ec992f2-1" id="id18">[1]</a> is a test of the null hypothesis that the
probability of success in a Bernoulli experiment is <cite>p</cite>.</p>
<p>Details of the test can be found in many texts on statistics, such
as section 24.5 of <a class="reference internal" href="#r64899ec992f2-2" id="id19">[2]</a>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>k</strong><span class="classifier">int</span></dt><dd><p>The number of successes.</p>
</dd>
<dt><strong>n</strong><span class="classifier">int</span></dt><dd><p>The number of trials.</p>
</dd>
<dt><strong>p</strong><span class="classifier">float, optional</span></dt><dd><p>The hypothesized probability of success, i.e. the expected
proportion of successes.  The value must be in the interval
<code class="docutils literal notranslate"><span class="pre">0</span> <span class="pre">&lt;=</span> <span class="pre">p</span> <span class="pre">&lt;=</span> <span class="pre">1</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">=</span> <span class="pre">0.5</span></code>.</p>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘greater’, ‘less’}, optional</span></dt><dd><p>Indicates the alternative hypothesis. The default value is
‘two-sided’.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>result</strong><span class="classifier"><cite>~scipy.stats._result_classes.BinomTestResult</cite> instance</span></dt><dd><p>The return value is an object with the following attributes:</p>
<dl class="simple">
<dt>k<span class="classifier">int</span></dt><dd><p>The number of successes (copied from <cite>binomtest</cite> input).</p>
</dd>
<dt>n<span class="classifier">int</span></dt><dd><p>The number of trials (copied from <cite>binomtest</cite> input).</p>
</dd>
<dt>alternative<span class="classifier">str</span></dt><dd><p>Indicates the alternative hypothesis specified in the input
to <cite>binomtest</cite>.  It will be one of <code class="docutils literal notranslate"><span class="pre">'two-sided'</span></code>, <code class="docutils literal notranslate"><span class="pre">'greater'</span></code>,
or <code class="docutils literal notranslate"><span class="pre">'less'</span></code>.</p>
</dd>
<dt>statistic<span class="classifier">float</span></dt><dd><p>The estimate of the proportion of successes.</p>
</dd>
<dt>pvalue<span class="classifier">float</span></dt><dd><p>The p-value of the hypothesis test.</p>
</dd>
</dl>
<p>The object has the following methods:</p>
<dl class="simple">
<dt>proportion_ci(confidence_level=0.95, method=’exact’) :</dt><dd><p>Compute the confidence interval for <code class="docutils literal notranslate"><span class="pre">statistic</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.7.0.</span></p>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r64899ec992f2-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">1</a><span class="fn-bracket">]</span></span>
<p>Binomial test, <a class="reference external" href="https://en.wikipedia.org/wiki/Binomial_test">https://en.wikipedia.org/wiki/Binomial_test</a></p>
</div>
<div class="citation" id="r64899ec992f2-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">2</a><span class="fn-bracket">]</span></span>
<p>Jerrold H. Zar, Biostatistical Analysis (fifth edition),
Prentice Hall, Upper Saddle River, New Jersey USA (2010)</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">binomtest</span>
</pre></div>
</div>
<p>A car manufacturer claims that no more than 10% of their cars are unsafe.
15 cars are inspected for safety, 3 were found to be unsafe. Test the
manufacturer’s claim:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span> <span class="o">=</span> <span class="n">binomtest</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">0.18406106910639114</span>
</pre></div>
</div>
<p>The null hypothesis cannot be rejected at the 5% level of significance
because the returned p-value is greater than the critical value of 5%.</p>
<p>The test statistic is equal to the estimated proportion, which is simply
<code class="docutils literal notranslate"><span class="pre">3/15</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">0.2</span>
</pre></div>
</div>
<p>We can use the <cite>proportion_ci()</cite> method of the result to compute the
confidence interval of the estimate:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">result</span><span class="o">.</span><span class="n">proportion_ci</span><span class="p">(</span><span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
<span class="go">ConfidenceInterval(low=0.05684686759024681, high=1.0)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.chisquare">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">chisquare</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.chisquare" title="Link to this definition">#</a></dt>
<dd><p>Perform Pearson’s chi-squared test.</p>
<p>Pearson’s chi-squared test <a class="reference internal" href="#r767e314b8a96-1" id="id22">[1]</a> is a goodness-of-fit test for a multinomial
distribution with given probabilities; that is, it assesses the null hypothesis
that the observed frequencies (counts) are obtained by independent
sampling of <em>N</em> observations from a categorical distribution with given
expected frequencies.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>f_obs</strong><span class="classifier">array_like</span></dt><dd><p>Observed frequencies in each category.</p>
</dd>
<dt><strong>f_exp</strong><span class="classifier">array_like, optional</span></dt><dd><p>Expected frequencies in each category. By default, the categories are
assumed to be equally likely.</p>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>“Delta degrees of freedom”: adjustment to the degrees of freedom
for the p-value.  The p-value is computed using a chi-squared
distribution with <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">-</span> <span class="pre">1</span> <span class="pre">-</span> <span class="pre">ddof</span></code> degrees of freedom, where <code class="docutils literal notranslate"><span class="pre">k</span></code>
is the number of categories.  The default value of <cite>ddof</cite> is 0.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>The axis of the broadcast result of <cite>f_obs</cite> and <cite>f_exp</cite> along which to
apply the test.  If axis is None, all values in <cite>f_obs</cite> are treated
as a single data set.  Default is 0.</p>
</dd>
<dt><strong>sum_check</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether to perform a check that <code class="docutils literal notranslate"><span class="pre">sum(f_obs)</span> <span class="pre">-</span> <span class="pre">sum(f_exp)</span> <span class="pre">==</span> <span class="pre">0</span></code>. If True,
(default) raise an error when the relative difference exceeds the square root
of the precision of the data type. See Notes for rationale and possible
exceptions.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt>res: Power_divergenceResult</dt><dd><p>An object containing attributes:</p>
<dl class="simple">
<dt>statistic<span class="classifier">float or ndarray</span></dt><dd><p>The chi-squared test statistic.  The value is a float if <cite>axis</cite> is
None or <cite>f_obs</cite> and <cite>f_exp</cite> are 1-D.</p>
</dd>
<dt>pvalue<span class="classifier">float or ndarray</span></dt><dd><p>The p-value of the test.  The value is a float if <cite>ddof</cite> and the
result attribute <cite>statistic</cite> are scalars.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.stats.power_divergence</span></code></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.stats.fisher_exact</span></code></dt><dd><p>Fisher exact test on a 2x2 contingency table.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.stats.barnard_exact</span></code></dt><dd><p>An unconditional exact test. An alternative to chi-squared test for small sample sizes.</p>
</dd>
<dt><span class="xref std std-ref">hypothesis_chisquare</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This test is invalid when the observed or expected frequencies in each
category are too small.  A typical rule is that all of the observed
and expected frequencies should be at least 5. According to <a class="reference internal" href="#r767e314b8a96-2" id="id23">[2]</a>, the
total number of observations is recommended to be greater than 13,
otherwise exact tests (such as Barnard’s Exact test) should be used
because they do not overreject.</p>
<p>The default degrees of freedom, k-1, are for the case when no parameters
of the distribution are estimated. If p parameters are estimated by
efficient maximum likelihood then the correct degrees of freedom are
k-1-p. If the parameters are estimated in a different way, then the
dof can be between k-1-p and k-1. However, it is also possible that
the asymptotic distribution is not chi-square, in which case this test
is not appropriate.</p>
<p>For Pearson’s chi-squared test, the total observed and expected counts must match
for the p-value to accurately reflect the probability of observing such an extreme
value of the statistic under the null hypothesis.
This function may be used to perform other statistical tests that do not require
the total counts to be equal. For instance, to test the null hypothesis that
<code class="docutils literal notranslate"><span class="pre">f_obs[i]</span></code> is Poisson-distributed with expectation <code class="docutils literal notranslate"><span class="pre">f_exp[i]</span></code>, set <code class="docutils literal notranslate"><span class="pre">ddof=-1</span></code>
and <code class="docutils literal notranslate"><span class="pre">sum_check=False</span></code>. This test follows from the fact that a Poisson random
variable with mean and variance <code class="docutils literal notranslate"><span class="pre">f_exp[i]</span></code> is approximately normal with the
same mean and variance; the chi-squared statistic standardizes, squares, and sums
the observations; and the sum of <code class="docutils literal notranslate"><span class="pre">n</span></code> squared standard normal variables follows
the chi-squared distribution with <code class="docutils literal notranslate"><span class="pre">n</span></code> degrees of freedom.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r767e314b8a96-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id22">1</a><span class="fn-bracket">]</span></span>
<p>“Pearson’s chi-squared test”.
<em>Wikipedia</em>. <a class="reference external" href="https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test">https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test</a></p>
</div>
<div class="citation" id="r767e314b8a96-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id23">2</a><span class="fn-bracket">]</span></span>
<p>Pearson, Karl. “On the criterion that a given system of deviations from the probable
in the case of a correlated system of variables is such that it can be reasonably
supposed to have arisen from random sampling”, Philosophical Magazine. Series 5. 50
(1900), pp. 157-175.</p>
</div>
</div>
<p class="rubric">Examples</p>
<p>When only the mandatory <cite>f_obs</cite> argument is given, it is assumed that the
expected frequencies are uniform and given by the mean of the observed
frequencies:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">chisquare</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chisquare</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="go">Power_divergenceResult(statistic=2.0, pvalue=0.84914503608460956)</span>
</pre></div>
</div>
<p>The optional <cite>f_exp</cite> argument gives the expected frequencies.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">chisquare</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="n">f_exp</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="go">Power_divergenceResult(statistic=3.5, pvalue=0.62338762774958223)</span>
</pre></div>
</div>
<p>When <cite>f_obs</cite> is 2-D, by default the test is applied to each column.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">24</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">obs</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(6, 2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chisquare</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
<span class="go">Power_divergenceResult(statistic=array([2.        , 6.66666667]), pvalue=array([0.84914504, 0.24663415]))</span>
</pre></div>
</div>
<p>By setting <code class="docutils literal notranslate"><span class="pre">axis=None</span></code>, the test is applied to all data in the array,
which is equivalent to applying the test to the flattened array.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">chisquare</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="go">Power_divergenceResult(statistic=23.31034482758621, pvalue=0.015975692534127565)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">chisquare</span><span class="p">(</span><span class="n">obs</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
<span class="go">Power_divergenceResult(statistic=23.310344827586206, pvalue=0.01597569253412758)</span>
</pre></div>
</div>
<p><cite>ddof</cite> is the change to make to the default degrees of freedom.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">chisquare</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">Power_divergenceResult(statistic=2.0, pvalue=0.7357588823428847)</span>
</pre></div>
</div>
<p>The calculation of the p-values is done by broadcasting the
chi-squared statistic with <cite>ddof</cite>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">chisquare</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span> <span class="n">ddof</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">Power_divergenceResult(statistic=2.0, pvalue=array([0.84914504, 0.73575888, 0.5724067 ]))</span>
</pre></div>
</div>
<p><cite>f_obs</cite> and <cite>f_exp</cite> are also broadcast.  In the following, <cite>f_obs</cite> has
shape (6,) and <cite>f_exp</cite> has shape (2, 6), so the result of broadcasting
<cite>f_obs</cite> and <cite>f_exp</cite> has shape (2, 6).  To compute the desired chi-squared
statistics, we use <code class="docutils literal notranslate"><span class="pre">axis=1</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">chisquare</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">],</span>
<span class="gp">... </span>          <span class="n">f_exp</span><span class="o">=</span><span class="p">[[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">]],</span>
<span class="gp">... </span>          <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">Power_divergenceResult(statistic=array([3.5 , 9.25]), pvalue=array([0.62338763, 0.09949846]))</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_chisquare</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.describe">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">describe</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.describe" title="Link to this definition">#</a></dt>
<dd><p>Compute several descriptive statistics of the passed array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Input data.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>Axis along which statistics are calculated. Default is 0.
If None, compute over the whole array <cite>a</cite>.</p>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>Delta degrees of freedom (only for variance).  Default is 1.</p>
</dd>
<dt><strong>bias</strong><span class="classifier">bool, optional</span></dt><dd><p>If False, then the skewness and kurtosis calculations are corrected
for statistical bias.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘raise’, ‘omit’}, optional</span></dt><dd><p>Defines how to handle when input contains nan.
The following options are available (default is ‘propagate’):</p>
<ul class="simple">
<li><p>‘propagate’: returns nan</p></li>
<li><p>‘raise’: throws an error</p></li>
<li><p>‘omit’: performs the calculations ignoring nan values</p></li>
</ul>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>nobs</strong><span class="classifier">int or ndarray of ints</span></dt><dd><p>Number of observations (length of data along <cite>axis</cite>).
When ‘omit’ is chosen as nan_policy, the length along each axis
slice is counted separately.</p>
</dd>
<dt>minmax: tuple of ndarrays or floats</dt><dd><p>Minimum and maximum value of <cite>a</cite> along the given axis.</p>
</dd>
<dt><strong>mean</strong><span class="classifier">ndarray or float</span></dt><dd><p>Arithmetic mean of <cite>a</cite> along the given axis.</p>
</dd>
<dt><strong>variance</strong><span class="classifier">ndarray or float</span></dt><dd><p>Unbiased variance of <cite>a</cite> along the given axis; denominator is number
of observations minus one.</p>
</dd>
<dt><strong>skewness</strong><span class="classifier">ndarray or float</span></dt><dd><p>Skewness of <cite>a</cite> along the given axis, based on moment calculations
with denominator equal to the number of observations, i.e. no degrees
of freedom correction.</p>
</dd>
<dt><strong>kurtosis</strong><span class="classifier">ndarray or float</span></dt><dd><p>Kurtosis (Fisher) of <cite>a</cite> along the given axis.  The kurtosis is
normalized so that it is zero for the normal distribution.  No
degrees of freedom are used.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>ValueError</dt><dd><p>If size of <cite>a</cite> is 0.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.skew" title="barotropy.mcerp.stats.skew"><code class="xref py py-obj docutils literal notranslate"><span class="pre">skew</span></code></a>, <a class="reference internal" href="#barotropy.mcerp.stats.kurtosis" title="barotropy.mcerp.stats.kurtosis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kurtosis</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">DescribeResult(nobs=10, minmax=(0, 9), mean=4.5,</span>
<span class="go">               variance=9.166666666666666, skewness=0.0,</span>
<span class="go">               kurtosis=-1.2242424242424244)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="go">DescribeResult(nobs=2, minmax=(array([1, 2]), array([3, 4])),</span>
<span class="go">               mean=array([2., 3.]), variance=array([2., 2.]),</span>
<span class="go">               skewness=array([0., 0.]), kurtosis=array([-2., -2.]))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.f_oneway">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">f_oneway</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.f_oneway" title="Link to this definition">#</a></dt>
<dd><p>Perform one-way ANOVA.</p>
<p>The one-way ANOVA tests the null hypothesis that two or more groups have
the same population mean.  The test is applied to samples from two or
more groups, possibly with differing sizes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample1, sample2, …</strong><span class="classifier">array_like</span></dt><dd><p>The sample measurements for each group.  There must be at least
two arguments.  If the arrays are multidimensional, then all the
dimensions of the array must be the same except for <cite>axis</cite>.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The computed F statistic of the test.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The associated p-value from the F distribution.</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Warns<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><cite>~scipy.stats.ConstantInputWarning</cite></dt><dd><p>Emitted if all values within each of the input arrays are identical.
In this case the F statistic is either infinite or isn’t defined,
so <code class="docutils literal notranslate"><span class="pre">np.inf</span></code> or <code class="docutils literal notranslate"><span class="pre">np.nan</span></code> is returned.</p>
</dd>
<dt>RuntimeWarning</dt><dd><p>Emitted if the length of any input array is 0, or if all the input
arrays have length 1.  <code class="docutils literal notranslate"><span class="pre">np.nan</span></code> is returned for the F statistic
and the p-value in these cases.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The ANOVA test has important assumptions that must be satisfied in order
for the associated p-value to be valid.</p>
<ol class="arabic simple">
<li><p>The samples are independent.</p></li>
<li><p>Each sample is from a normally distributed population.</p></li>
<li><p>The population standard deviations of the groups are all equal.  This
property is known as homoscedasticity.</p></li>
</ol>
<p>If these assumptions are not true for a given set of data, it may still
be possible to use the Kruskal-Wallis H-test (<cite>scipy.stats.kruskal</cite>) or
the Alexander-Govern test (<cite>scipy.stats.alexandergovern</cite>) although with
some loss of power.</p>
<p>The length of each group must be at least one, and there must be at
least one group with length greater than one.  If these conditions
are not satisfied, a warning is generated and (<code class="docutils literal notranslate"><span class="pre">np.nan</span></code>, <code class="docutils literal notranslate"><span class="pre">np.nan</span></code>)
is returned.</p>
<p>If all values in each group are identical, and there exist at least two
groups with different values, the function generates a warning and
returns (<code class="docutils literal notranslate"><span class="pre">np.inf</span></code>, 0).</p>
<p>If all values in all groups are the same, function generates a warning
and returns (<code class="docutils literal notranslate"><span class="pre">np.nan</span></code>, <code class="docutils literal notranslate"><span class="pre">np.nan</span></code>).</p>
<p>The algorithm is from Heiman <a class="reference internal" href="#r467caa6c492a-2" id="id26">[2]</a>, pp.394-7.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r467caa6c492a-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>R. Lowry, “Concepts and Applications of Inferential Statistics”,
Chapter 14, 2014, <a class="reference external" href="http://vassarstats.net/textbook/">http://vassarstats.net/textbook/</a></p>
</div>
<div class="citation" id="r467caa6c492a-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id26">2</a><span class="fn-bracket">]</span></span>
<p>G.W. Heiman, “Understanding research methods and statistics: An
integrated introduction for psychology”, Houghton, Mifflin and
Company, 2001.</p>
</div>
<div class="citation" id="r467caa6c492a-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id30">3</a><span class="fn-bracket">]</span></span>
<p>G.H. McDonald, “Handbook of Biological Statistics”, One-way ANOVA.
<a class="reference external" href="http://www.biostathandbook.com/onewayanova.html">http://www.biostathandbook.com/onewayanova.html</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">f_oneway</span>
</pre></div>
</div>
<p>Here are some data <a class="reference internal" href="#r467caa6c492a-3" id="id30">[3]</a> on a shell measurement (the length of the anterior
adductor muscle scar, standardized by dividing by length) in the mussel
Mytilus trossulus from five locations: Tillamook, Oregon; Newport, Oregon;
Petersburg, Alaska; Magadan, Russia; and Tvarminne, Finland, taken from a
much larger data set used in McDonald et al. (1991).</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tillamook</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0571</span><span class="p">,</span> <span class="mf">0.0813</span><span class="p">,</span> <span class="mf">0.0831</span><span class="p">,</span> <span class="mf">0.0976</span><span class="p">,</span> <span class="mf">0.0817</span><span class="p">,</span> <span class="mf">0.0859</span><span class="p">,</span> <span class="mf">0.0735</span><span class="p">,</span>
<span class="gp">... </span>             <span class="mf">0.0659</span><span class="p">,</span> <span class="mf">0.0923</span><span class="p">,</span> <span class="mf">0.0836</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">newport</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0873</span><span class="p">,</span> <span class="mf">0.0662</span><span class="p">,</span> <span class="mf">0.0672</span><span class="p">,</span> <span class="mf">0.0819</span><span class="p">,</span> <span class="mf">0.0749</span><span class="p">,</span> <span class="mf">0.0649</span><span class="p">,</span> <span class="mf">0.0835</span><span class="p">,</span>
<span class="gp">... </span>           <span class="mf">0.0725</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">petersburg</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0974</span><span class="p">,</span> <span class="mf">0.1352</span><span class="p">,</span> <span class="mf">0.0817</span><span class="p">,</span> <span class="mf">0.1016</span><span class="p">,</span> <span class="mf">0.0968</span><span class="p">,</span> <span class="mf">0.1064</span><span class="p">,</span> <span class="mf">0.105</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">magadan</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1033</span><span class="p">,</span> <span class="mf">0.0915</span><span class="p">,</span> <span class="mf">0.0781</span><span class="p">,</span> <span class="mf">0.0685</span><span class="p">,</span> <span class="mf">0.0677</span><span class="p">,</span> <span class="mf">0.0697</span><span class="p">,</span> <span class="mf">0.0764</span><span class="p">,</span>
<span class="gp">... </span>           <span class="mf">0.0689</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tvarminne</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0703</span><span class="p">,</span> <span class="mf">0.1026</span><span class="p">,</span> <span class="mf">0.0956</span><span class="p">,</span> <span class="mf">0.0973</span><span class="p">,</span> <span class="mf">0.1039</span><span class="p">,</span> <span class="mf">0.1045</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f_oneway</span><span class="p">(</span><span class="n">tillamook</span><span class="p">,</span> <span class="n">newport</span><span class="p">,</span> <span class="n">petersburg</span><span class="p">,</span> <span class="n">magadan</span><span class="p">,</span> <span class="n">tvarminne</span><span class="p">)</span>
<span class="go">F_onewayResult(statistic=7.121019471642447, pvalue=0.0002812242314534544)</span>
</pre></div>
</div>
<p><cite>f_oneway</cite> accepts multidimensional input arrays.  When the inputs
are multidimensional and <cite>axis</cite> is not given, the test is performed
along the first axis of the input arrays.  For the following data, the
test is performed three times, once for each column.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">9.87</span><span class="p">,</span> <span class="mf">9.03</span><span class="p">,</span> <span class="mf">6.81</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">7.18</span><span class="p">,</span> <span class="mf">8.35</span><span class="p">,</span> <span class="mf">7.00</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">8.39</span><span class="p">,</span> <span class="mf">7.58</span><span class="p">,</span> <span class="mf">7.68</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">7.45</span><span class="p">,</span> <span class="mf">6.33</span><span class="p">,</span> <span class="mf">9.35</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">6.41</span><span class="p">,</span> <span class="mf">7.10</span><span class="p">,</span> <span class="mf">9.33</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">8.00</span><span class="p">,</span> <span class="mf">8.24</span><span class="p">,</span> <span class="mf">8.44</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">6.35</span><span class="p">,</span> <span class="mf">7.30</span><span class="p">,</span> <span class="mf">7.16</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">6.65</span><span class="p">,</span> <span class="mf">6.68</span><span class="p">,</span> <span class="mf">7.63</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">5.72</span><span class="p">,</span> <span class="mf">7.73</span><span class="p">,</span> <span class="mf">6.72</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">7.01</span><span class="p">,</span> <span class="mf">9.19</span><span class="p">,</span> <span class="mf">7.41</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">7.75</span><span class="p">,</span> <span class="mf">7.87</span><span class="p">,</span> <span class="mf">8.30</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">6.90</span><span class="p">,</span> <span class="mf">7.97</span><span class="p">,</span> <span class="mf">6.97</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">3.31</span><span class="p">,</span> <span class="mf">8.77</span><span class="p">,</span> <span class="mf">1.01</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">8.25</span><span class="p">,</span> <span class="mf">3.24</span><span class="p">,</span> <span class="mf">3.62</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">6.32</span><span class="p">,</span> <span class="mf">8.81</span><span class="p">,</span> <span class="mf">5.19</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">7.48</span><span class="p">,</span> <span class="mf">8.83</span><span class="p">,</span> <span class="mf">8.91</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">8.59</span><span class="p">,</span> <span class="mf">6.01</span><span class="p">,</span> <span class="mf">6.07</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">3.07</span><span class="p">,</span> <span class="mf">9.72</span><span class="p">,</span> <span class="mf">7.48</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F</span> <span class="o">=</span> <span class="n">f_oneway</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">array([1.75676344, 0.03701228, 3.76439349])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">array([0.20630784, 0.96375203, 0.04733157])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.fligner">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">fligner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.fligner" title="Link to this definition">#</a></dt>
<dd><p>Perform Fligner-Killeen test for equality of variance.</p>
<p>Fligner’s test tests the null hypothesis that all input samples
are from populations with equal variances.  Fligner-Killeen’s test is
distribution free when populations are identical <a class="reference internal" href="#r69149b8fffb4-2" id="id31">[2]</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample1, sample2, …</strong><span class="classifier">array_like</span></dt><dd><p>Arrays of sample data.  Need not be the same length.</p>
</dd>
<dt><strong>center</strong><span class="classifier">{‘mean’, ‘median’, ‘trimmed’}, optional</span></dt><dd><p>Keyword argument controlling which function of the data is used in
computing the test statistic.  The default is ‘median’.</p>
</dd>
<dt><strong>proportiontocut</strong><span class="classifier">float, optional</span></dt><dd><p>When <cite>center</cite> is ‘trimmed’, this gives the proportion of data points
to cut from each end. (See <cite>scipy.stats.trim_mean</cite>.)
Default is 0.05.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The test statistic.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The p-value for the hypothesis test.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.bartlett" title="barotropy.mcerp.stats.bartlett"><code class="xref py py-func docutils literal notranslate"><span class="pre">bartlett()</span></code></a></dt><dd><p>A parametric test for equality of k variances in normal samples</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.levene" title="barotropy.mcerp.stats.levene"><code class="xref py py-func docutils literal notranslate"><span class="pre">levene()</span></code></a></dt><dd><p>A robust parametric test for equality of k variances</p>
</dd>
<dt><span class="xref std std-ref">hypothesis_fligner</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>As with Levene’s test there are three variants of Fligner’s test that
differ by the measure of central tendency used in the test.  See <cite>levene</cite>
for more information.</p>
<p>Conover et al. (1981) examine many of the existing parametric and
nonparametric tests by extensive simulations and they conclude that the
tests proposed by Fligner and Killeen (1976) and Levene (1960) appear to be
superior in terms of robustness of departures from normality and power
<a class="reference internal" href="#r69149b8fffb4-3" id="id32">[3]</a>.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r69149b8fffb4-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Park, C. and Lindsay, B. G. (1999). Robust Scale Estimation and
Hypothesis Testing based on Quadratic Inference Function. Technical
Report #99-03, Center for Likelihood Studies, Pennsylvania State
University.
<a class="reference external" href="https://cecas.clemson.edu/~cspark/cv/paper/qif/draftqif2.pdf">https://cecas.clemson.edu/~cspark/cv/paper/qif/draftqif2.pdf</a></p>
</div>
<div class="citation" id="r69149b8fffb4-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id31">2</a><span class="fn-bracket">]</span></span>
<p>Fligner, M.A. and Killeen, T.J. (1976). Distribution-free two-sample
tests for scale. Journal of the American Statistical Association.
71(353), 210-213.</p>
</div>
<div class="citation" id="r69149b8fffb4-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id32">3</a><span class="fn-bracket">]</span></span>
<p>Park, C. and Lindsay, B. G. (1999). Robust Scale Estimation and
Hypothesis Testing based on Quadratic Inference Function. Technical
Report #99-03, Center for Likelihood Studies, Pennsylvania State
University.</p>
</div>
<div class="citation" id="r69149b8fffb4-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>Conover, W. J., Johnson, M. E. and Johnson M. M. (1981). A
comparative study of tests for homogeneity of variances, with
applications to the outer continental shelf bidding data.
Technometrics, 23(4), 351-361.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
</pre></div>
</div>
<p>Test whether the lists <cite>a</cite>, <cite>b</cite> and <cite>c</cite> come from populations
with equal variances.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.88</span><span class="p">,</span> <span class="mf">9.12</span><span class="p">,</span> <span class="mf">9.04</span><span class="p">,</span> <span class="mf">8.98</span><span class="p">,</span> <span class="mf">9.00</span><span class="p">,</span> <span class="mf">9.08</span><span class="p">,</span> <span class="mf">9.01</span><span class="p">,</span> <span class="mf">8.85</span><span class="p">,</span> <span class="mf">9.06</span><span class="p">,</span> <span class="mf">8.99</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.88</span><span class="p">,</span> <span class="mf">8.95</span><span class="p">,</span> <span class="mf">9.29</span><span class="p">,</span> <span class="mf">9.44</span><span class="p">,</span> <span class="mf">9.15</span><span class="p">,</span> <span class="mf">9.58</span><span class="p">,</span> <span class="mf">8.36</span><span class="p">,</span> <span class="mf">9.18</span><span class="p">,</span> <span class="mf">8.67</span><span class="p">,</span> <span class="mf">9.05</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.95</span><span class="p">,</span> <span class="mf">9.12</span><span class="p">,</span> <span class="mf">8.95</span><span class="p">,</span> <span class="mf">8.85</span><span class="p">,</span> <span class="mf">9.03</span><span class="p">,</span> <span class="mf">8.84</span><span class="p">,</span> <span class="mf">9.07</span><span class="p">,</span> <span class="mf">8.98</span><span class="p">,</span> <span class="mf">8.86</span><span class="p">,</span> <span class="mf">8.98</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stat</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">fligner</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span>
<span class="go">0.00450826080004775</span>
</pre></div>
</div>
<p>The small p-value suggests that the populations do not have equal
variances.</p>
<p>This is not surprising, given that the sample variance of <cite>b</cite> is much
larger than that of <cite>a</cite> and <cite>c</cite>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">]]</span>
<span class="go">[0.007054444444444413, 0.13073888888888888, 0.008890000000000002]</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_fligner</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.friedmanchisquare">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">friedmanchisquare</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.friedmanchisquare" title="Link to this definition">#</a></dt>
<dd><p>Compute the Friedman test for repeated samples.</p>
<p>The Friedman test tests the null hypothesis that repeated samples of
the same individuals have the same distribution.  It is often used
to test for consistency among samples obtained in different ways.
For example, if two sampling techniques are used on the same set of
individuals, the Friedman test can be used to determine if the two
sampling techniques are consistent.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample1, sample2, sample3…</strong><span class="classifier">array_like</span></dt><dd><p>Arrays of observations.  All of the arrays must have the same number
of elements.  At least three samples must be given.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The test statistic, correcting for ties.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The associated p-value assuming that the test statistic has a chi
squared distribution.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><span class="xref std std-ref">hypothesis_friedmanchisquare</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Due to the assumption that the test statistic has a chi squared
distribution, the p-value is only reliable for n &gt; 10 and more than
6 repeated samples.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rec5abc37ba82-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Friedman_test">https://en.wikipedia.org/wiki/Friedman_test</a></p>
</div>
<div class="citation" id="rec5abc37ba82-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Demsar, J. (2006). Statistical comparisons of classifiers over
multiple data sets. Journal of Machine Learning Research, 7, 1-30.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">friedmanchisquare</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">friedmanchisquare</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">(11.428571428571416, 0.043514520866727614)</span>
</pre></div>
</div>
<p>The p-value is less than 0.05; however, as noted above, the results may not
be reliable since we have a small number of repeated samples.</p>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_friedmanchisquare</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.gmean">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">gmean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.gmean" title="Link to this definition">#</a></dt>
<dd><p>Compute the weighted geometric mean along the specified axis.</p>
<p>The weighted geometric mean of the array <span class="math notranslate nohighlight">\(a_i\)</span> associated to weights
<span class="math notranslate nohighlight">\(w_i\)</span> is:</p>
<div class="math notranslate nohighlight">
\[\exp \left( \frac{ \sum_{i=1}^n w_i \ln a_i }{ \sum_{i=1}^n w_i }
           \right) \, ,\]</div>
<p>and, with equal weights, it gives:</p>
<div class="math notranslate nohighlight">
\[\sqrt[n]{ \prod_{i=1}^n a_i } \, .\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Input array or object that can be converted to an array.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">dtype, optional</span></dt><dd><p>Type to which the input arrays are cast before the calculation is
performed.</p>
</dd>
<dt><strong>weights</strong><span class="classifier">array_like, optional</span></dt><dd><p>The <cite>weights</cite> array must be broadcastable to the same shape as <cite>a</cite>.
Default is None, which gives each value a weight of 1.0.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>gmean</strong><span class="classifier">ndarray</span></dt><dd><p>See <cite>dtype</cite> parameter above.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.mean()</span></code></dt><dd><p>Arithmetic average</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.average()</span></code></dt><dd><p>Weighted average</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.hmean" title="barotropy.mcerp.stats.hmean"><code class="xref py py-func docutils literal notranslate"><span class="pre">hmean()</span></code></a></dt><dd><p>Harmonic mean</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The sample geometric mean is the exponential of the mean of the natural
logarithms of the observations.
Negative observations will produce NaNs in the output because the <em>natural</em>
logarithm (as opposed to the <em>complex</em> logarithm) is defined only for
non-negative reals.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rd5fa0d683cff-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>“Weighted Geometric Mean”, <em>Wikipedia</em>,
<a class="reference external" href="https://en.wikipedia.org/wiki/Weighted_geometric_mean">https://en.wikipedia.org/wiki/Weighted_geometric_mean</a>.</p>
</div>
<div class="citation" id="rd5fa0d683cff-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Grossman, J., Grossman, M., Katz, R., “Averages: A New Approach”,
Archimedes Foundation, 1983</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">gmean</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gmean</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="go">2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gmean</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="go">3.3800151591412964</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gmean</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">2.80668351922014</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.hmean">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">hmean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.hmean" title="Link to this definition">#</a></dt>
<dd><p>Calculate the weighted harmonic mean along the specified axis.</p>
<p>The weighted harmonic mean of the array <span class="math notranslate nohighlight">\(a_i\)</span> associated to weights
<span class="math notranslate nohighlight">\(w_i\)</span> is:</p>
<div class="math notranslate nohighlight">
\[\frac{ \sum_{i=1}^n w_i }{ \sum_{i=1}^n \frac{w_i}{a_i} } \, ,\]</div>
<p>and, with equal weights, it gives:</p>
<div class="math notranslate nohighlight">
\[\frac{ n }{ \sum_{i=1}^n \frac{1}{a_i} } \, .\]</div>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Input array, masked array or object that can be converted to an array.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>dtype</strong><span class="classifier">dtype, optional</span></dt><dd><p>Type of the returned array and of the accumulator in which the
elements are summed. If <cite>dtype</cite> is not specified, it defaults to the
dtype of <cite>a</cite>, unless <cite>a</cite> has an integer <cite>dtype</cite> with a precision less
than that of the default platform integer. In that case, the default
platform integer is used.</p>
</dd>
<dt><strong>weights</strong><span class="classifier">array_like, optional</span></dt><dd><p>The weights array can either be 1-D (in which case its length must be
the size of <cite>a</cite> along the given <cite>axis</cite>) or of the same shape as <cite>a</cite>.
Default is None, which gives each value a weight of 1.0.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.9.</span></p>
</div>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>hmean</strong><span class="classifier">ndarray</span></dt><dd><p>See <cite>dtype</cite> parameter above.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.mean()</span></code></dt><dd><p>Arithmetic average</p>
</dd>
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.average()</span></code></dt><dd><p>Weighted average</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.gmean" title="barotropy.mcerp.stats.gmean"><code class="xref py py-func docutils literal notranslate"><span class="pre">gmean()</span></code></a></dt><dd><p>Geometric mean</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The sample harmonic mean is the reciprocal of the mean of the reciprocals
of the observations.</p>
<p>The harmonic mean is computed over a single dimension of the input
array, axis=0 by default, or all values in the array if axis=None.
float64 intermediate and return values are used for integer inputs.</p>
<p>The harmonic mean is only defined if all observations are non-negative;
otherwise, the result is NaN.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rfe0ff4777840-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>“Weighted Harmonic Mean”, <em>Wikipedia</em>,
<a class="reference external" href="https://en.wikipedia.org/wiki/Harmonic_mean#Weighted_harmonic_mean">https://en.wikipedia.org/wiki/Harmonic_mean#Weighted_harmonic_mean</a></p>
</div>
<div class="citation" id="rfe0ff4777840-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Ferger, F., “The nature and use of the harmonic mean”, Journal of
the American Statistical Association, vol. 26, pp. 36-40, 1931</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">hmean</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hmean</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="go">1.6000000000000001</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hmean</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="go">2.6997245179063363</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hmean</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">1.9029126213592233</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.kendalltau">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">kendalltau</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.kendalltau" title="Link to this definition">#</a></dt>
<dd><p>Calculate Kendall’s tau, a correlation measure for ordinal data.</p>
<p>Kendall’s tau is a measure of the correspondence between two rankings.
Values close to 1 indicate strong agreement, and values close to -1
indicate strong disagreement. This implements two variants of Kendall’s
tau: tau-b (the default) and tau-c (also known as Stuart’s tau-c). These
differ only in how they are normalized to lie within the range -1 to 1;
the hypothesis tests (their p-values) are identical. Kendall’s original
tau-a is not implemented separately because both tau-b and tau-c reduce
to tau-a in the absence of ties.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x, y</strong><span class="classifier">array_like</span></dt><dd><p>Arrays of rankings, of the same shape. If arrays are not 1-D, they
will be flattened to 1-D.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘raise’, ‘omit’}, optional</span></dt><dd><p>Defines how to handle when input contains nan.
The following options are available (default is ‘propagate’):</p>
<ul class="simple">
<li><p>‘propagate’: returns nan</p></li>
<li><p>‘raise’: throws an error</p></li>
<li><p>‘omit’: performs the calculations ignoring nan values</p></li>
</ul>
</dd>
<dt><strong>method</strong><span class="classifier">{‘auto’, ‘asymptotic’, ‘exact’}, optional</span></dt><dd><p>Defines which method is used to calculate the p-value <a class="reference internal" href="#r91dec1fc1492-5" id="id43">[5]</a>.
The following options are available (default is ‘auto’):</p>
<ul class="simple">
<li><p>‘auto’: selects the appropriate method based on a trade-off
between speed and accuracy</p></li>
<li><p>‘asymptotic’: uses a normal approximation valid for large samples</p></li>
<li><p>‘exact’: computes the exact p-value, but can only be used if no ties
are present. As the sample size increases, the ‘exact’ computation
time may grow and the result may lose some precision.</p></li>
</ul>
</dd>
<dt><strong>variant</strong><span class="classifier">{‘b’, ‘c’}, optional</span></dt><dd><p>Defines which variant of Kendall’s tau is returned. Default is ‘b’.</p>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
The following options are available:</p>
<ul class="simple">
<li><p>‘two-sided’: the rank correlation is nonzero</p></li>
<li><p>‘less’: the rank correlation is negative (less than zero)</p></li>
<li><p>‘greater’: the rank correlation is positive (greater than zero)</p></li>
</ul>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>res</strong><span class="classifier">SignificanceResult</span></dt><dd><p>An object containing attributes:</p>
<dl class="simple">
<dt>statistic<span class="classifier">float</span></dt><dd><p>The tau statistic.</p>
</dd>
<dt>pvalue<span class="classifier">float</span></dt><dd><p>The p-value for a hypothesis test whose null hypothesis is
an absence of association, tau = 0.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>ValueError</dt><dd><p>If <cite>nan_policy</cite> is ‘omit’ and <cite>variant</cite> is not ‘b’ or
if <cite>method</cite> is ‘exact’ and there are ties between <cite>x</cite> and <cite>y</cite>.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.spearmanr" title="barotropy.mcerp.stats.spearmanr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">spearmanr</span></code></a></dt><dd><p>Calculates a Spearman rank-order correlation coefficient.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">theilslopes</span></code></dt><dd><p>Computes the Theil-Sen estimator for a set of points (x, y).</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">weightedtau</span></code></dt><dd><p>Computes a weighted version of Kendall’s tau.</p>
</dd>
<dt><span class="xref std std-ref">hypothesis_kendalltau</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The definition of Kendall’s tau that is used is <a class="reference internal" href="#r91dec1fc1492-2" id="id44">[2]</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">tau_b</span> <span class="o">=</span> <span class="p">(</span><span class="n">P</span> <span class="o">-</span> <span class="n">Q</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">((</span><span class="n">P</span> <span class="o">+</span> <span class="n">Q</span> <span class="o">+</span> <span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">P</span> <span class="o">+</span> <span class="n">Q</span> <span class="o">+</span> <span class="n">U</span><span class="p">))</span>

<span class="n">tau_c</span> <span class="o">=</span> <span class="mi">2</span> <span class="p">(</span><span class="n">P</span> <span class="o">-</span> <span class="n">Q</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">m</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
<p>where P is the number of concordant pairs, Q the number of discordant
pairs, T the number of ties only in <cite>x</cite>, and U the number of ties only in
<cite>y</cite>.  If a tie occurs for the same pair in both <cite>x</cite> and <cite>y</cite>, it is not
added to either T or U. n is the total number of samples, and m is the
number of unique values in either <cite>x</cite> or <cite>y</cite>, whichever is smaller.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r91dec1fc1492-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Maurice G. Kendall, “A New Measure of Rank Correlation”, Biometrika
Vol. 30, No. 1/2, pp. 81-93, 1938.</p>
</div>
<div class="citation" id="r91dec1fc1492-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id44">2</a><span class="fn-bracket">]</span></span>
<p>Maurice G. Kendall, “The treatment of ties in ranking problems”,
Biometrika Vol. 33, No. 3, pp. 239-251. 1945.</p>
</div>
<div class="citation" id="r91dec1fc1492-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>Gottfried E. Noether, “Elements of Nonparametric Statistics”, John
Wiley &amp; Sons, 1967.</p>
</div>
<div class="citation" id="r91dec1fc1492-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<p>Peter M. Fenwick, “A new data structure for cumulative frequency
tables”, Software: Practice and Experience, Vol. 24, No. 3,
pp. 327-336, 1994.</p>
</div>
<div class="citation" id="r91dec1fc1492-5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id43">5</a><span class="fn-bracket">]</span></span>
<p>Maurice G. Kendall, “Rank Correlation Methods” (4th Edition),
Charles Griffin &amp; Co., 1970.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">kendalltau</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">-0.47140452079103173</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">0.2827454599327748</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_kendalltau</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.kruskal">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">kruskal</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.kruskal" title="Link to this definition">#</a></dt>
<dd><p>Compute the Kruskal-Wallis H-test for independent samples.</p>
<p>The Kruskal-Wallis H-test tests the null hypothesis that the population
median of all of the groups are equal.  It is a non-parametric version of
ANOVA.  The test works on 2 or more independent samples, which may have
different sizes.  Note that rejecting the null hypothesis does not
indicate which of the groups differs.  Post hoc comparisons between
groups are required to determine which groups are different.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample1, sample2, …</strong><span class="classifier">array_like</span></dt><dd><p>Two or more arrays with the sample measurements can be given as
arguments. Samples must be one-dimensional.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The Kruskal-Wallis H statistic, corrected for ties.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The p-value for the test using the assumption that H has a chi
square distribution. The p-value returned is the survival function of
the chi square distribution evaluated at H.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.f_oneway" title="barotropy.mcerp.stats.f_oneway"><code class="xref py py-func docutils literal notranslate"><span class="pre">f_oneway()</span></code></a></dt><dd><p>1-way ANOVA.</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.mannwhitneyu" title="barotropy.mcerp.stats.mannwhitneyu"><code class="xref py py-func docutils literal notranslate"><span class="pre">mannwhitneyu()</span></code></a></dt><dd><p>Mann-Whitney rank test on two samples.</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.friedmanchisquare" title="barotropy.mcerp.stats.friedmanchisquare"><code class="xref py py-func docutils literal notranslate"><span class="pre">friedmanchisquare()</span></code></a></dt><dd><p>Friedman test for repeated measurements.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Due to the assumption that H has a chi square distribution, the number
of samples in each group must not be too small.  A typical rule is
that each sample must have at least 5 measurements.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="re67b77dea081-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>W. H. Kruskal &amp; W. W. Wallis, “Use of Ranks in
One-Criterion Variance Analysis”, Journal of the American Statistical
Association, Vol. 47, Issue 260, pp. 583-621, 1952.</p>
</div>
<div class="citation" id="re67b77dea081-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Kruskal-Wallis_one-way_analysis_of_variance">https://en.wikipedia.org/wiki/Kruskal-Wallis_one-way_analysis_of_variance</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">kruskal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">KruskalResult(statistic=0.2727272727272734, pvalue=0.6015081344405895)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">kruskal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
<span class="go">KruskalResult(statistic=7.0, pvalue=0.0301973834223185)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.ks_2samp">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">ks_2samp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.ks_2samp" title="Link to this definition">#</a></dt>
<dd><p>Performs the two-sample Kolmogorov-Smirnov test for goodness of fit.</p>
<p>This test compares the underlying continuous distributions F(x) and G(x)
of two independent samples.  See Notes for a description of the available
null and alternative hypotheses.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>data1, data2</strong><span class="classifier">array_like, 1-Dimensional</span></dt><dd><p>Two arrays of sample observations assumed to be drawn from a continuous
distribution, sample sizes can be different.</p>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the null and alternative hypotheses. Default is ‘two-sided’.
Please see explanations in the Notes below.</p>
</dd>
<dt><strong>method</strong><span class="classifier">{‘auto’, ‘exact’, ‘asymp’}, optional</span></dt><dd><p>Defines the method used for calculating the p-value.
The following options are available (default is ‘auto’):</p>
<blockquote>
<div><ul class="simple">
<li><p>‘auto’ : use ‘exact’ for small size arrays, ‘asymp’ for large</p></li>
<li><p>‘exact’ : use exact distribution of test statistic</p></li>
<li><p>‘asymp’ : use asymptotic distribution of test statistic</p></li>
</ul>
</div></blockquote>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt>res: KstestResult</dt><dd><p>An object containing attributes:</p>
<dl class="simple">
<dt>statistic<span class="classifier">float</span></dt><dd><p>KS test statistic.</p>
</dd>
<dt>pvalue<span class="classifier">float</span></dt><dd><p>One-tailed or two-tailed p-value.</p>
</dd>
<dt>statistic_location<span class="classifier">float</span></dt><dd><p>Value from <cite>data1</cite> or <cite>data2</cite> corresponding with the KS statistic;
i.e., the distance between the empirical distribution functions is
measured at this observation.</p>
</dd>
<dt>statistic_sign<span class="classifier">int</span></dt><dd><p>+1 if the empirical distribution function of <cite>data1</cite> exceeds
the empirical distribution function of <cite>data2</cite> at
<cite>statistic_location</cite>, otherwise -1.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.kstest" title="barotropy.mcerp.stats.kstest"><code class="xref py py-func docutils literal notranslate"><span class="pre">kstest()</span></code></a>, <code class="xref py py-func docutils literal notranslate"><span class="pre">ks_1samp()</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">epps_singleton_2samp()</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">anderson_ksamp()</span></code></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>There are three options for the null and corresponding alternative
hypothesis that can be selected using the <cite>alternative</cite> parameter.</p>
<ul class="simple">
<li><p><cite>less</cite>: The null hypothesis is that F(x) &gt;= G(x) for all x; the
alternative is that F(x) &lt; G(x) for at least one x. The statistic
is the magnitude of the minimum (most negative) difference between the
empirical distribution functions of the samples.</p></li>
<li><p><cite>greater</cite>: The null hypothesis is that F(x) &lt;= G(x) for all x; the
alternative is that F(x) &gt; G(x) for at least one x. The statistic
is the maximum (most positive) difference between the empirical
distribution functions of the samples.</p></li>
<li><p><cite>two-sided</cite>: The null hypothesis is that the two distributions are
identical, F(x)=G(x) for all x; the alternative is that they are not
identical. The statistic is the maximum absolute difference between the
empirical distribution functions of the samples.</p></li>
</ul>
<p>Note that the alternative hypotheses describe the <em>CDFs</em> of the
underlying distributions, not the observed values of the data. For example,
suppose x1 ~ F and x2 ~ G. If F(x) &gt; G(x) for all x, the values in
x1 tend to be less than those in x2.</p>
<p>If the KS statistic is large, then the p-value will be small, and this may
be taken as evidence against the null hypothesis in favor of the
alternative.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">method='exact'</span></code>, <cite>ks_2samp</cite> attempts to compute an exact p-value,
that is, the probability under the null hypothesis of obtaining a test
statistic value as extreme as the value computed from the data.
If <code class="docutils literal notranslate"><span class="pre">method='asymp'</span></code>, the asymptotic Kolmogorov-Smirnov distribution is
used to compute an approximate p-value.
If <code class="docutils literal notranslate"><span class="pre">method='auto'</span></code>, an exact p-value computation is attempted if both
sample sizes are less than 10000; otherwise, the asymptotic method is used.
In any case, if an exact p-value calculation is attempted and fails, a
warning will be emitted, and the asymptotic p-value will be returned.</p>
<p>The ‘two-sided’ ‘exact’ computation computes the complementary probability
and then subtracts from 1.  As such, the minimum probability it can return
is about 1e-16.  While the algorithm itself is exact, numerical
errors may accumulate for large sample sizes.   It is most suited to
situations in which one of the sample sizes is only a few thousand.</p>
<p>We generally follow Hodges’ treatment of Drion/Gnedenko/Korolyuk <a class="reference internal" href="#rfe9b933dfc5f-1" id="id52">[1]</a>.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rfe9b933dfc5f-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id52">1</a><span class="fn-bracket">]</span></span>
<p>Hodges, J.L. Jr.,  “The Significance Probability of the Smirnov
Two-Sample Test,” Arkiv fiur Matematik, 3, No. 43 (1958), 469-486.</p>
</div>
</div>
<p class="rubric">Examples</p>
<p>Suppose we wish to test the null hypothesis that two samples were drawn
from the same distribution.
We choose a confidence level of 95%; that is, we will reject the null
hypothesis in favor of the alternative if the p-value is less than 0.05.</p>
<p>If the first sample were drawn from a uniform distribution and the second
were drawn from the standard normal, we would expect the null hypothesis
to be rejected.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">110</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ks_2samp</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">)</span>
<span class="go">KstestResult(statistic=0.5454545454545454,</span>
<span class="go">             pvalue=7.37417839555191e-15,</span>
<span class="go">             statistic_location=-0.014071496412861274,</span>
<span class="go">             statistic_sign=-1)</span>
</pre></div>
</div>
<p>Indeed, the p-value is lower than our threshold of 0.05, so we reject the
null hypothesis in favor of the default “two-sided” alternative: the data
were <em>not</em> drawn from the same distribution.</p>
<p>When both samples are drawn from the same distribution, we expect the data
to be consistent with the null hypothesis most of the time.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sample1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">105</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">95</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ks_2samp</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">)</span>
<span class="go">KstestResult(statistic=0.10927318295739348,</span>
<span class="go">             pvalue=0.5438289009927495,</span>
<span class="go">             statistic_location=-0.1670157701848795,</span>
<span class="go">             statistic_sign=-1)</span>
</pre></div>
</div>
<p>As expected, the p-value of 0.54 is not below our threshold of 0.05, so
we cannot reject the null hypothesis.</p>
<p>Suppose, however, that the first sample were drawn from
a normal distribution shifted toward greater values. In this case,
the cumulative density function (CDF) of the underlying distribution tends
to be <em>less</em> than the CDF underlying the second sample. Therefore, we would
expect the null hypothesis to be rejected with <code class="docutils literal notranslate"><span class="pre">alternative='less'</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sample1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">105</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ks_2samp</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;less&#39;</span><span class="p">)</span>
<span class="go">KstestResult(statistic=0.4055137844611529,</span>
<span class="go">             pvalue=3.5474563068855554e-08,</span>
<span class="go">             statistic_location=-0.13249370614972575,</span>
<span class="go">             statistic_sign=-1)</span>
</pre></div>
</div>
<p>and indeed, with p-value smaller than our threshold, we reject the null
hypothesis in favor of the alternative.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.kstest">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">kstest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.kstest" title="Link to this definition">#</a></dt>
<dd><p>Performs the (one-sample or two-sample) Kolmogorov-Smirnov test for
goodness of fit.</p>
<p>The one-sample test compares the underlying distribution F(x) of a sample
against a given distribution G(x). The two-sample test compares the
underlying distributions of two independent samples. Both tests are valid
only for continuous distributions.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>rvs</strong><span class="classifier">str, array_like, or callable</span></dt><dd><p>If an array, it should be a 1-D array of observations of random
variables.
If a callable, it should be a function to generate random variables;
it is required to have a keyword argument <cite>size</cite>.
If a string, it should be the name of a distribution in <cite>scipy.stats</cite>,
which will be used to generate random variables.</p>
</dd>
<dt><strong>cdf</strong><span class="classifier">str, array_like or callable</span></dt><dd><p>If array_like, it should be a 1-D array of observations of random
variables, and the two-sample test is performed
(and rvs must be array_like).
If a callable, that callable is used to calculate the cdf.
If a string, it should be the name of a distribution in <cite>scipy.stats</cite>,
which will be used as the cdf function.</p>
</dd>
<dt><strong>args</strong><span class="classifier">tuple, sequence, optional</span></dt><dd><p>Distribution parameters, used if <cite>rvs</cite> or <cite>cdf</cite> are strings or
callables.</p>
</dd>
<dt><strong>N</strong><span class="classifier">int, optional</span></dt><dd><p>Sample size if <cite>rvs</cite> is string or callable.  Default is 20.</p>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the null and alternative hypotheses. Default is ‘two-sided’.
Please see explanations in the Notes below.</p>
</dd>
<dt><strong>method</strong><span class="classifier">{‘auto’, ‘exact’, ‘approx’, ‘asymp’}, optional</span></dt><dd><p>Defines the distribution used for calculating the p-value.
The following options are available (default is ‘auto’):</p>
<blockquote>
<div><ul class="simple">
<li><p>‘auto’ : selects one of the other options.</p></li>
<li><p>‘exact’ : uses the exact distribution of test statistic.</p></li>
<li><p>‘approx’ : approximates the two-sided probability with twice the
one-sided probability</p></li>
<li><p>‘asymp’: uses asymptotic distribution of test statistic</p></li>
</ul>
</div></blockquote>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt>res: KstestResult</dt><dd><p>An object containing attributes:</p>
<dl>
<dt>statistic<span class="classifier">float</span></dt><dd><p>KS test statistic, either D+, D-, or D (the maximum of the two)</p>
</dd>
<dt>pvalue<span class="classifier">float</span></dt><dd><p>One-tailed or two-tailed p-value.</p>
</dd>
<dt>statistic_location<span class="classifier">float</span></dt><dd><p>In a one-sample test, this is the value of <cite>rvs</cite>
corresponding with the KS statistic; i.e., the distance between
the empirical distribution function and the hypothesized cumulative
distribution function is measured at this observation.</p>
<p>In a two-sample test, this is the value from <cite>rvs</cite> or <cite>cdf</cite>
corresponding with the KS statistic; i.e., the distance between
the empirical distribution functions is measured at this
observation.</p>
</dd>
<dt>statistic_sign<span class="classifier">int</span></dt><dd><p>In a one-sample test, this is +1 if the KS statistic is the
maximum positive difference between the empirical distribution
function and the hypothesized cumulative distribution function
(D+); it is -1 if the KS statistic is the maximum negative
difference (D-).</p>
<p>In a two-sample test, this is +1 if the empirical distribution
function of <cite>rvs</cite> exceeds the empirical distribution
function of <cite>cdf</cite> at <cite>statistic_location</cite>, otherwise -1.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">ks_1samp()</span></code>, <a class="reference internal" href="#barotropy.mcerp.stats.ks_2samp" title="barotropy.mcerp.stats.ks_2samp"><code class="xref py py-func docutils literal notranslate"><span class="pre">ks_2samp()</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>There are three options for the null and corresponding alternative
hypothesis that can be selected using the <cite>alternative</cite> parameter.</p>
<ul class="simple">
<li><p><cite>two-sided</cite>: The null hypothesis is that the two distributions are
identical, F(x)=G(x) for all x; the alternative is that they are not
identical.</p></li>
<li><p><cite>less</cite>: The null hypothesis is that F(x) &gt;= G(x) for all x; the
alternative is that F(x) &lt; G(x) for at least one x.</p></li>
<li><p><cite>greater</cite>: The null hypothesis is that F(x) &lt;= G(x) for all x; the
alternative is that F(x) &gt; G(x) for at least one x.</p></li>
</ul>
<p>Note that the alternative hypotheses describe the <em>CDFs</em> of the
underlying distributions, not the observed values. For example,
suppose x1 ~ F and x2 ~ G. If F(x) &gt; G(x) for all x, the values in
x1 tend to be less than those in x2.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<p>Suppose we wish to test the null hypothesis that a sample is distributed
according to the standard normal.
We choose a confidence level of 95%; that is, we will reject the null
hypothesis in favor of the alternative if the p-value is less than 0.05.</p>
<p>When testing uniformly distributed data, we would expect the
null hypothesis to be rejected.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">),</span>
<span class="gp">... </span>             <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
<span class="go">KstestResult(statistic=0.5001899973268688,</span>
<span class="go">             pvalue=1.1616392184763533e-23,</span>
<span class="go">             statistic_location=0.00047625268963724654,</span>
<span class="go">             statistic_sign=-1)</span>
</pre></div>
</div>
<p>Indeed, the p-value is lower than our threshold of 0.05, so we reject the
null hypothesis in favor of the default “two-sided” alternative: the data
are <em>not</em> distributed according to the standard normal.</p>
<p>When testing random variates from the standard normal distribution, we
expect the data to be consistent with the null hypothesis most of the time.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">)</span>
<span class="go">KstestResult(statistic=0.05345882212970396,</span>
<span class="go">             pvalue=0.9227159037744717,</span>
<span class="go">             statistic_location=-1.2451343873745018,</span>
<span class="go">             statistic_sign=1)</span>
</pre></div>
</div>
<p>As expected, the p-value of 0.92 is not below our threshold of 0.05, so
we cannot reject the null hypothesis.</p>
<p>Suppose, however, that the random variates are distributed according to
a normal distribution that is shifted toward greater values. In this case,
the cumulative density function (CDF) of the underlying distribution tends
to be <em>less</em> than the CDF of the standard normal. Therefore, we would
expect the null hypothesis to be rejected with <code class="docutils literal notranslate"><span class="pre">alternative='less'</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;less&#39;</span><span class="p">)</span>
<span class="go">KstestResult(statistic=0.17482387821055168,</span>
<span class="go">             pvalue=0.001913921057766743,</span>
<span class="go">             statistic_location=0.3713830565352756,</span>
<span class="go">             statistic_sign=-1)</span>
</pre></div>
</div>
<p>and indeed, with p-value smaller than our threshold, we reject the null
hypothesis in favor of the alternative.</p>
<p>For convenience, the previous test can be performed using the name of the
distribution as the second argument.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;less&#39;</span><span class="p">)</span>
<span class="go">KstestResult(statistic=0.17482387821055168,</span>
<span class="go">             pvalue=0.001913921057766743,</span>
<span class="go">             statistic_location=0.3713830565352756,</span>
<span class="go">             statistic_sign=-1)</span>
</pre></div>
</div>
<p>The examples above have all been one-sample tests identical to those
performed by <cite>ks_1samp</cite>. Note that <cite>kstest</cite> can also perform two-sample
tests identical to those performed by <cite>ks_2samp</cite>. For example, when two
samples are drawn from the same distribution, we expect the data to be
consistent with the null hypothesis most of the time.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sample1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">laplace</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">105</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">laplace</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">95</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">kstest</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">)</span>
<span class="go">KstestResult(statistic=0.11779448621553884,</span>
<span class="go">             pvalue=0.4494256912629795,</span>
<span class="go">             statistic_location=0.6138814275424155,</span>
<span class="go">             statistic_sign=1)</span>
</pre></div>
</div>
<p>As expected, the p-value of 0.45 is not below our threshold of 0.05, so
we cannot reject the null hypothesis.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.kurtosis">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">kurtosis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.kurtosis" title="Link to this definition">#</a></dt>
<dd><p>Compute the kurtosis (Fisher or Pearson) of a dataset.</p>
<p>Kurtosis is the fourth central moment divided by the square of the
variance. If Fisher’s definition is used, then 3.0 is subtracted from
the result to give 0.0 for a normal distribution.</p>
<p>If bias is False then the kurtosis is calculated using k statistics to
eliminate bias coming from biased moment estimators</p>
<p>Use <cite>kurtosistest</cite> to see if result is close enough to normal.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array</span></dt><dd><p>Data for which the kurtosis is calculated.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>fisher</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, Fisher’s definition is used (normal ==&gt; 0.0). If False,
Pearson’s definition is used (normal ==&gt; 3.0).</p>
</dd>
<dt><strong>bias</strong><span class="classifier">bool, optional</span></dt><dd><p>If False, then the calculations are corrected for statistical bias.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>kurtosis</strong><span class="classifier">array</span></dt><dd><p>The kurtosis of values along an axis, returning NaN where all values
are equal.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r1ced5a0ff03b-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Zwillinger, D. and Kokoska, S. (2000). CRC Standard
Probability and Statistics Tables and Formulae. Chapman &amp; Hall: New
York. 2000.</p>
</div>
</div>
<p class="rubric">Examples</p>
<p>In Fisher’s definition, the kurtosis of the normal distribution is zero.
In the following example, the kurtosis is close to zero, because it was
calculated from the dataset, not from the continuous distribution.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span><span class="p">,</span> <span class="n">kurtosis</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kurtosis</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="go">-0.06928694200380558</span>
</pre></div>
</div>
<p>The distribution with a higher kurtosis has a heavier tail.
The zero valued kurtosis of the normal distribution in Fisher’s definition
can serve as a reference point.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">kurtosis</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">distnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;laplace&#39;</span><span class="p">,</span> <span class="s1">&#39;norm&#39;</span><span class="p">,</span> <span class="s1">&#39;uniform&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">distname</span> <span class="ow">in</span> <span class="n">distnames</span><span class="p">:</span>
<span class="gp">... </span>    <span class="k">if</span> <span class="n">distname</span> <span class="o">==</span> <span class="s1">&#39;uniform&#39;</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">dist</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="n">distname</span><span class="p">)(</span><span class="n">loc</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">dist</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">stats</span><span class="p">,</span> <span class="n">distname</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">data</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">kur</span> <span class="o">=</span> <span class="n">kurtosis</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">fisher</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">y</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">distname</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">kur</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
<span class="gp">... </span>    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<p>The Laplace distribution has a heavier tail than the normal distribution.
The uniform distribution (which has negative kurtosis) has the thinnest
tail.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.kurtosistest">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">kurtosistest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.kurtosistest" title="Link to this definition">#</a></dt>
<dd><p>Test whether a dataset has normal kurtosis.</p>
<p>This function tests the null hypothesis that the kurtosis
of the population from which the sample was drawn is that
of the normal distribution.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>a</strong><span class="classifier">array</span></dt><dd><p>Array of the sample data. Must contain at least five observations.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis.
The following options are available (default is ‘two-sided’):</p>
<ul class="simple">
<li><p>‘two-sided’: the kurtosis of the distribution underlying the sample
is different from that of the normal distribution</p></li>
<li><p>‘less’: the kurtosis of the distribution underlying the sample
is less than that of the normal distribution</p></li>
<li><p>‘greater’: the kurtosis of the distribution underlying the sample
is greater than that of the normal distribution</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.7.0.</span></p>
</div>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The computed z-score for this test.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The p-value for the hypothesis test.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><span class="xref std std-ref">hypothesis_kurtosistest</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Valid only for n&gt;20. This function uses the method described in <a class="reference internal" href="#r11488a178aa4-1" id="id55">[1]</a>.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r11488a178aa4-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id55">1</a><span class="fn-bracket">]</span></span>
<p>F. J. Anscombe, W. J. Glynn, “Distribution of the kurtosis
statistic b2 for normal samples”, Biometrika, vol. 70, pp. 227-234, 1983.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">kurtosistest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kurtosistest</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)))</span>
<span class="go">KurtosistestResult(statistic=-1.7058104152122062, pvalue=0.08804338332528348)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kurtosistest</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)),</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;less&#39;</span><span class="p">)</span>
<span class="go">KurtosistestResult(statistic=-1.7058104152122062, pvalue=0.04402169166264174)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kurtosistest</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)),</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="go">KurtosistestResult(statistic=-1.7058104152122062, pvalue=0.9559783083373583)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kurtosistest</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
<span class="go">KurtosistestResult(statistic=-1.475047944490622, pvalue=0.14019965402996987)</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_kurtosistest</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.levene">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">levene</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.levene" title="Link to this definition">#</a></dt>
<dd><p>Perform Levene test for equal variances.</p>
<p>The Levene test tests the null hypothesis that all input samples
are from populations with equal variances.  Levene’s test is an
alternative to Bartlett’s test <cite>bartlett</cite> in the case where
there are significant deviations from normality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sample1, sample2, …</strong><span class="classifier">array_like</span></dt><dd><p>The sample data, possibly with different lengths. Only one-dimensional
samples are accepted.</p>
</dd>
<dt><strong>center</strong><span class="classifier">{‘mean’, ‘median’, ‘trimmed’}, optional</span></dt><dd><p>Which function of the data to use in the test.  The default
is ‘median’.</p>
</dd>
<dt><strong>proportiontocut</strong><span class="classifier">float, optional</span></dt><dd><p>When <cite>center</cite> is ‘trimmed’, this gives the proportion of data points
to cut from each end. (See <cite>scipy.stats.trim_mean</cite>.)
Default is 0.05.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The test statistic.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The p-value for the test.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.fligner" title="barotropy.mcerp.stats.fligner"><code class="xref py py-func docutils literal notranslate"><span class="pre">fligner()</span></code></a></dt><dd><p>A non-parametric test for the equality of k variances</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.bartlett" title="barotropy.mcerp.stats.bartlett"><code class="xref py py-func docutils literal notranslate"><span class="pre">bartlett()</span></code></a></dt><dd><p>A parametric test for equality of k variances in normal samples</p>
</dd>
<dt><span class="xref std std-ref">hypothesis_levene</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Three variations of Levene’s test are possible.  The possibilities
and their recommended usages are:</p>
<ul class="simple">
<li><p>‘median’ : Recommended for skewed (non-normal) distributions&gt;</p></li>
<li><p>‘mean’ : Recommended for symmetric, moderate-tailed distributions.</p></li>
<li><p>‘trimmed’ : Recommended for heavy-tailed distributions.</p></li>
</ul>
<p>The test version using the mean was proposed in the original article
of Levene (<a class="reference internal" href="#r9690239ef8c4-2" id="id57">[2]</a>) while the median and trimmed mean have been studied by
Brown and Forsythe (<a class="reference internal" href="#r9690239ef8c4-3" id="id58">[3]</a>), sometimes also referred to as Brown-Forsythe
test.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r9690239ef8c4-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm">https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm</a></p>
</div>
<div class="citation" id="r9690239ef8c4-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id57">2</a><span class="fn-bracket">]</span></span>
<p>Levene, H. (1960). In Contributions to Probability and Statistics:
Essays in Honor of Harold Hotelling, I. Olkin et al. eds.,
Stanford University Press, pp. 278-292.</p>
</div>
<div class="citation" id="r9690239ef8c4-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id58">3</a><span class="fn-bracket">]</span></span>
<p>Brown, M. B. and Forsythe, A. B. (1974), Journal of the American
Statistical Association, 69, 364-367</p>
</div>
</div>
<p class="rubric">Examples</p>
<p>Test whether the lists <cite>a</cite>, <cite>b</cite> and <cite>c</cite> come from populations
with equal variances.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.88</span><span class="p">,</span> <span class="mf">9.12</span><span class="p">,</span> <span class="mf">9.04</span><span class="p">,</span> <span class="mf">8.98</span><span class="p">,</span> <span class="mf">9.00</span><span class="p">,</span> <span class="mf">9.08</span><span class="p">,</span> <span class="mf">9.01</span><span class="p">,</span> <span class="mf">8.85</span><span class="p">,</span> <span class="mf">9.06</span><span class="p">,</span> <span class="mf">8.99</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.88</span><span class="p">,</span> <span class="mf">8.95</span><span class="p">,</span> <span class="mf">9.29</span><span class="p">,</span> <span class="mf">9.44</span><span class="p">,</span> <span class="mf">9.15</span><span class="p">,</span> <span class="mf">9.58</span><span class="p">,</span> <span class="mf">8.36</span><span class="p">,</span> <span class="mf">9.18</span><span class="p">,</span> <span class="mf">8.67</span><span class="p">,</span> <span class="mf">9.05</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="p">[</span><span class="mf">8.95</span><span class="p">,</span> <span class="mf">9.12</span><span class="p">,</span> <span class="mf">8.95</span><span class="p">,</span> <span class="mf">8.85</span><span class="p">,</span> <span class="mf">9.03</span><span class="p">,</span> <span class="mf">8.84</span><span class="p">,</span> <span class="mf">9.07</span><span class="p">,</span> <span class="mf">8.98</span><span class="p">,</span> <span class="mf">8.86</span><span class="p">,</span> <span class="mf">8.98</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stat</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">levene</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span>
<span class="go">0.002431505967249681</span>
</pre></div>
</div>
<p>The small p-value suggests that the populations do not have equal
variances.</p>
<p>This is not surprising, given that the sample variance of <cite>b</cite> is much
larger than that of <cite>a</cite> and <cite>c</cite>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">]]</span>
<span class="go">[0.007054444444444413, 0.13073888888888888, 0.008890000000000002]</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_levene</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.linregress">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">linregress</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.linregress" title="Link to this definition">#</a></dt>
<dd><p>Calculate a linear least-squares regression for two sets of measurements.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x, y</strong><span class="classifier">array_like</span></dt><dd><p>Two sets of measurements.  Both arrays should have the same length N.  If
only <cite>x</cite> is given (and <code class="docutils literal notranslate"><span class="pre">y=None</span></code>), then it must be a two-dimensional
array where one dimension has length 2.  The two sets of measurements
are then found by splitting the array along the length-2 dimension. In
the case where <code class="docutils literal notranslate"><span class="pre">y=None</span></code> and <cite>x</cite> is a 2xN array, <code class="docutils literal notranslate"><span class="pre">linregress(x)</span></code> is
equivalent to <code class="docutils literal notranslate"><span class="pre">linregress(x[0],</span> <span class="pre">x[1])</span></code>.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.14.0: </span>Inference of the two sets of measurements from a single argument <cite>x</cite>
is deprecated will result in an error in SciPy 1.16.0; the sets
must be specified separately as <cite>x</cite> and <cite>y</cite>.</p>
</div>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
The following options are available:</p>
<ul class="simple">
<li><p>‘two-sided’: the slope of the regression line is nonzero</p></li>
<li><p>‘less’: the slope of the regression line is less than zero</p></li>
<li><p>‘greater’:  the slope of the regression line is greater than zero</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.7.0.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>result</strong><span class="classifier"><code class="docutils literal notranslate"><span class="pre">LinregressResult</span></code> instance</span></dt><dd><p>The return value is an object with the following attributes:</p>
<dl class="simple">
<dt>slope<span class="classifier">float</span></dt><dd><p>Slope of the regression line.</p>
</dd>
<dt>intercept<span class="classifier">float</span></dt><dd><p>Intercept of the regression line.</p>
</dd>
<dt>rvalue<span class="classifier">float</span></dt><dd><p>The Pearson correlation coefficient. The square of <code class="docutils literal notranslate"><span class="pre">rvalue</span></code>
is equal to the coefficient of determination.</p>
</dd>
<dt>pvalue<span class="classifier">float</span></dt><dd><p>The p-value for a hypothesis test whose null hypothesis is
that the slope is zero, using Wald Test with t-distribution of
the test statistic. See <cite>alternative</cite> above for alternative
hypotheses.</p>
</dd>
<dt>stderr<span class="classifier">float</span></dt><dd><p>Standard error of the estimated slope (gradient), under the
assumption of residual normality.</p>
</dd>
<dt>intercept_stderr<span class="classifier">float</span></dt><dd><p>Standard error of the estimated intercept, under the assumption
of residual normality.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.optimize.curve_fit</span></code></dt><dd><p>Use non-linear least squares to fit a function to data.</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.optimize.leastsq</span></code></dt><dd><p>Minimize the sum of squares of a set of equations.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>For compatibility with older versions of SciPy, the return value acts
like a <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> of length 5, with fields <code class="docutils literal notranslate"><span class="pre">slope</span></code>, <code class="docutils literal notranslate"><span class="pre">intercept</span></code>,
<code class="docutils literal notranslate"><span class="pre">rvalue</span></code>, <code class="docutils literal notranslate"><span class="pre">pvalue</span></code> and <code class="docutils literal notranslate"><span class="pre">stderr</span></code>, so one can continue to write:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">slope</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">se</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>With that style, however, the standard error of the intercept is not
available.  To have access to all the computed values, including the
standard error of the intercept, use the return value as an object
with attributes, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">intercept</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">intercept_stderr</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
</pre></div>
</div>
<p>Generate some data:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="mf">1.6</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Perform the linear regression:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>Coefficient of determination (R-squared):</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R-squared: </span><span class="si">{</span><span class="n">res</span><span class="o">.</span><span class="n">rvalue</span><span class="o">**</span><span class="mi">2</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">R-squared: 0.717533</span>
</pre></div>
</div>
<p>Plot the data along with the fitted line:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;original data&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">intercept</span> <span class="o">+</span> <span class="n">res</span><span class="o">.</span><span class="n">slope</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;fitted line&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Calculate 95% confidence interval on slope and intercept:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Two-sided inverse Students t-distribution</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># p - probability, df - degrees of freedom</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">t</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tinv</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">p</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="nb">abs</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">p</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">df</span><span class="p">))</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ts</span> <span class="o">=</span> <span class="n">tinv</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;slope (95%): </span><span class="si">{</span><span class="n">res</span><span class="o">.</span><span class="n">slope</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2"> +/- </span><span class="si">{</span><span class="n">ts</span><span class="o">*</span><span class="n">res</span><span class="o">.</span><span class="n">stderr</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">slope (95%): 1.453392 +/- 0.743465</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;intercept (95%): </span><span class="si">{</span><span class="n">res</span><span class="o">.</span><span class="n">intercept</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="gp">... </span>      <span class="sa">f</span><span class="s2">&quot; +/- </span><span class="si">{</span><span class="n">ts</span><span class="o">*</span><span class="n">res</span><span class="o">.</span><span class="n">intercept_stderr</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="go">intercept (95%): 0.616950 +/- 0.544475</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.mannwhitneyu">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">mannwhitneyu</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.mannwhitneyu" title="Link to this definition">#</a></dt>
<dd><p>Perform the Mann-Whitney U rank test on two independent samples.</p>
<p>The Mann-Whitney U test is a nonparametric test of the null hypothesis
that the distribution underlying sample <cite>x</cite> is the same as the
distribution underlying sample <cite>y</cite>. It is often used as a test of
difference in location between distributions.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x, y</strong><span class="classifier">array-like</span></dt><dd><p>N-d arrays of samples. The arrays must be broadcastable except along
the dimension given by <cite>axis</cite>.</p>
</dd>
<dt><strong>use_continuity</strong><span class="classifier">bool, optional</span></dt><dd><p>Whether a continuity correction (1/2) should be applied.
Default is True when <cite>method</cite> is <code class="docutils literal notranslate"><span class="pre">'asymptotic'</span></code>; has no effect
otherwise.</p>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
Let <em>SX(u)</em> and <em>SY(u)</em> be the survival functions of the
distributions underlying <cite>x</cite> and <cite>y</cite>, respectively. Then the following
alternative hypotheses are available:</p>
<ul class="simple">
<li><p>‘two-sided’: the distributions are not equal, i.e. <em>SX(u) ≠ SY(u)</em> for
at least one <em>u</em>.</p></li>
<li><p>‘less’: the distribution underlying <cite>x</cite> is stochastically less
than the distribution underlying <cite>y</cite>, i.e. <em>SX(u) &lt; SY(u)</em> for all <em>u</em>.</p></li>
<li><p>‘greater’: the distribution underlying <cite>x</cite> is stochastically greater
than the distribution underlying <cite>y</cite>, i.e. <em>SX(u) &gt; SY(u)</em> for all <em>u</em>.</p></li>
</ul>
<p>Under a more restrictive set of assumptions, the alternative hypotheses
can be expressed in terms of the locations of the distributions;
see <a class="reference internal" href="#r69b20ab6572f-5" id="id62">[5]</a> section 5.1.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>method</strong><span class="classifier">{‘auto’, ‘asymptotic’, ‘exact’} or <cite>PermutationMethod</cite> instance, optional</span></dt><dd><p>Selects the method used to calculate the <em>p</em>-value.
Default is ‘auto’. The following options are available.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">'asymptotic'</span></code>: compares the standardized test statistic
against the normal distribution, correcting for ties.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'exact'</span></code>: computes the exact <em>p</em>-value by comparing the observed
<span class="math notranslate nohighlight">\(U\)</span> statistic against the exact distribution of the <span class="math notranslate nohighlight">\(U\)</span>
statistic under the null hypothesis. No correction is made for ties.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">'auto'</span></code>: chooses <code class="docutils literal notranslate"><span class="pre">'exact'</span></code> when the size of one of the samples
is less than or equal to 8 and there are no ties;
chooses <code class="docutils literal notranslate"><span class="pre">'asymptotic'</span></code> otherwise.</p></li>
<li><p><cite>PermutationMethod</cite> instance. In this case, the p-value
is computed using <cite>permutation_test</cite> with the provided
configuration options and other appropriate settings.</p></li>
</ul>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>res</strong><span class="classifier">MannwhitneyuResult</span></dt><dd><p>An object containing attributes:</p>
<dl class="simple">
<dt>statistic<span class="classifier">float</span></dt><dd><p>The Mann-Whitney U statistic corresponding with sample <cite>x</cite>. See
Notes for the test statistic corresponding with sample <cite>y</cite>.</p>
</dd>
<dt>pvalue<span class="classifier">float</span></dt><dd><p>The associated <em>p</em>-value for the chosen <cite>alternative</cite>.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.stats.wilcoxon()</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.stats.ranksums()</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">scipy.stats.ttest_ind()</span></code></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>If <code class="docutils literal notranslate"><span class="pre">U1</span></code> is the statistic corresponding with sample <cite>x</cite>, then the
statistic corresponding with sample <cite>y</cite> is
<code class="docutils literal notranslate"><span class="pre">U2</span> <span class="pre">=</span> <span class="pre">x.shape[axis]</span> <span class="pre">*</span> <span class="pre">y.shape[axis]</span> <span class="pre">-</span> <span class="pre">U1</span></code>.</p>
<p><cite>mannwhitneyu</cite> is for independent samples. For related / paired samples,
consider <cite>scipy.stats.wilcoxon</cite>.</p>
<p><cite>method</cite> <code class="docutils literal notranslate"><span class="pre">'exact'</span></code> is recommended when there are no ties and when either
sample size is less than 8 <a class="reference internal" href="#r69b20ab6572f-1" id="id63">[1]</a>. The implementation follows the algorithm
reported in <a class="reference internal" href="#r69b20ab6572f-3" id="id64">[3]</a>.
Note that the exact method is <em>not</em> corrected for ties, but
<cite>mannwhitneyu</cite> will not raise errors or warnings if there are ties in the
data. If there are ties and either samples is small (fewer than ~10
observations), consider passing an instance of <cite>PermutationMethod</cite>
as the <cite>method</cite> to perform a permutation test.</p>
<p>The Mann-Whitney U test is a non-parametric version of the t-test for
independent samples. When the means of samples from the populations
are normally distributed, consider <cite>scipy.stats.ttest_ind</cite>.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r69b20ab6572f-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">1</a><span class="fn-bracket">]</span></span>
<p>H.B. Mann and D.R. Whitney, “On a test of whether one of two random
variables is stochastically larger than the other”, The Annals of
Mathematical Statistics, Vol. 18, pp. 50-60, 1947.</p>
</div>
<div class="citation" id="r69b20ab6572f-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Mann-Whitney U Test, Wikipedia,
<a class="reference external" href="http://en.wikipedia.org/wiki/Mann-Whitney_U_test">http://en.wikipedia.org/wiki/Mann-Whitney_U_test</a></p>
</div>
<div class="citation" id="r69b20ab6572f-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id64">3</a><span class="fn-bracket">]</span></span>
<p>Andreas Löffler,
“Über eine Partition der nat. Zahlen und ihr Anwendung beim U-Test”,
Wiss. Z. Univ. Halle, XXXII’83 pp. 87-89.</p>
</div>
<div class="citation" id="r69b20ab6572f-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id70">1</a>,<a role="doc-backlink" href="#id71">2</a>,<a role="doc-backlink" href="#id72">3</a>,<a role="doc-backlink" href="#id73">4</a>,<a role="doc-backlink" href="#id74">5</a>,<a role="doc-backlink" href="#id75">6</a>,<a role="doc-backlink" href="#id76">7</a>)</span>
<p>Rosie Shier, “Statistics: 2.3 The Mann-Whitney U Test”, Mathematics
Learning Support Centre, 2004.</p>
</div>
<div class="citation" id="r69b20ab6572f-5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id62">5</a><span class="fn-bracket">]</span></span>
<p>Michael P. Fay and Michael A. Proschan. “Wilcoxon-Mann-Whitney
or t-test? On assumptions for hypothesis tests and multiple interpretations of decision rules.” Statistics surveys, Vol. 4, pp.
1-39, 2010. <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2857732/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2857732/</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<p>We follow the example from <a class="reference internal" href="#r69b20ab6572f-4" id="id70">[4]</a>: nine randomly sampled young adults were
diagnosed with type II diabetes at the ages below.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">males</span> <span class="o">=</span> <span class="p">[</span><span class="mi">19</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">24</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">females</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">17</span><span class="p">,</span> <span class="mi">12</span><span class="p">]</span>
</pre></div>
</div>
<p>We use the Mann-Whitney U test to assess whether there is a statistically
significant difference in the diagnosis age of males and females.
The null hypothesis is that the distribution of male diagnosis ages is
the same as the distribution of female diagnosis ages. We decide
that a confidence level of 95% is required to reject the null hypothesis
in favor of the alternative that the distributions are different.
Since the number of samples is very small and there are no ties in the
data, we can compare the observed test statistic against the <em>exact</em>
distribution of the test statistic under the null hypothesis.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">mannwhitneyu</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">U1</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">males</span><span class="p">,</span> <span class="n">females</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;exact&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">U1</span><span class="p">)</span>
<span class="go">17.0</span>
</pre></div>
</div>
<p><cite>mannwhitneyu</cite> always reports the statistic associated with the first
sample, which, in this case, is males. This agrees with <span class="math notranslate nohighlight">\(U_M = 17\)</span>
reported in <a class="reference internal" href="#r69b20ab6572f-4" id="id71">[4]</a>. The statistic associated with the second statistic
can be calculated:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">nx</span><span class="p">,</span> <span class="n">ny</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">males</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">females</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">U2</span> <span class="o">=</span> <span class="n">nx</span><span class="o">*</span><span class="n">ny</span> <span class="o">-</span> <span class="n">U1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">U2</span><span class="p">)</span>
<span class="go">3.0</span>
</pre></div>
</div>
<p>This agrees with <span class="math notranslate nohighlight">\(U_F = 3\)</span> reported in <a class="reference internal" href="#r69b20ab6572f-4" id="id72">[4]</a>. The two-sided
<em>p</em>-value can be calculated from either statistic, and the value produced
by <cite>mannwhitneyu</cite> agrees with <span class="math notranslate nohighlight">\(p = 0.11\)</span> reported in <a class="reference internal" href="#r69b20ab6572f-4" id="id73">[4]</a>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="go">0.1111111111111111</span>
</pre></div>
</div>
<p>The exact distribution of the test statistic is asymptotically normal, so
the example continues by comparing the exact <em>p</em>-value against the
<em>p</em>-value produced using the normal approximation.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">pnorm</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">males</span><span class="p">,</span> <span class="n">females</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;asymptotic&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">pnorm</span><span class="p">)</span>
<span class="go">0.11134688653314041</span>
</pre></div>
</div>
<p>Here <cite>mannwhitneyu</cite>’s reported <em>p</em>-value appears to conflict with the
value <span class="math notranslate nohighlight">\(p = 0.09\)</span> given in <a class="reference internal" href="#r69b20ab6572f-4" id="id74">[4]</a>. The reason is that <a class="reference internal" href="#r69b20ab6572f-4" id="id75">[4]</a>
does not apply the continuity correction performed by <cite>mannwhitneyu</cite>;
<cite>mannwhitneyu</cite> reduces the distance between the test statistic and the
mean <span class="math notranslate nohighlight">\(\mu = n_x n_y / 2\)</span> by 0.5 to correct for the fact that the
discrete statistic is being compared against a continuous distribution.
Here, the <span class="math notranslate nohighlight">\(U\)</span> statistic used is less than the mean, so we reduce
the distance by adding 0.5 in the numerator.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">U</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">U1</span><span class="p">,</span> <span class="n">U2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">N</span> <span class="o">=</span> <span class="n">nx</span> <span class="o">+</span> <span class="n">ny</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">U</span> <span class="o">-</span> <span class="n">nx</span><span class="o">*</span><span class="n">ny</span><span class="o">/</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">nx</span><span class="o">*</span><span class="n">ny</span> <span class="o">*</span> <span class="p">(</span><span class="n">N</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">/</span> <span class="mi">12</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>  <span class="c1"># use CDF to get p-value from smaller statistic</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
<span class="go">0.11134688653314041</span>
</pre></div>
</div>
<p>If desired, we can disable the continuity correction to get a result
that agrees with that reported in <a class="reference internal" href="#r69b20ab6572f-4" id="id76">[4]</a>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">_</span><span class="p">,</span> <span class="n">pnorm</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">males</span><span class="p">,</span> <span class="n">females</span><span class="p">,</span> <span class="n">use_continuity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;asymptotic&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">pnorm</span><span class="p">)</span>
<span class="go">0.0864107329737</span>
</pre></div>
</div>
<p>Regardless of whether we perform an exact or asymptotic test, the
probability of the test statistic being as extreme or more extreme by
chance exceeds 5%, so we do not consider the results statistically
significant.</p>
<p>Suppose that, before seeing the data, we had hypothesized that females
would tend to be diagnosed at a younger age than males.
In that case, it would be natural to provide the female ages as the
first input, and we would have performed a one-sided test using
<code class="docutils literal notranslate"><span class="pre">alternative</span> <span class="pre">=</span> <span class="pre">'less'</span></code>: females are diagnosed at an age that is
stochastically less than that of males.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">females</span><span class="p">,</span> <span class="n">males</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;less&quot;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;exact&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="go">MannwhitneyuResult(statistic=3.0, pvalue=0.05555555555555555)</span>
</pre></div>
</div>
<p>Again, the probability of getting a sufficiently low value of the
test statistic by chance under the null hypothesis is greater than 5%,
so we do not reject the null hypothesis in favor of our alternative.</p>
<p>If it is reasonable to assume that the means of samples from the
populations are normally distributed, we could have used a t-test to
perform the analysis.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">ttest_ind</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">ttest_ind</span><span class="p">(</span><span class="n">females</span><span class="p">,</span> <span class="n">males</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;less&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-2.239334696520584,</span>
<span class="go">            pvalue=0.030068441095757924,</span>
<span class="go">            df=7.0)</span>
</pre></div>
</div>
<p>Under this assumption, the <em>p</em>-value would be low enough to reject the
null hypothesis in favor of the alternative.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.mode">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">mode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.mode" title="Link to this definition">#</a></dt>
<dd><p>Return an array of the modal (most common) value in the passed array.</p>
<p>If there is more than one such value, only one is returned.
The bin-count for the modal bins is also returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Numeric, n-dimensional array of which to find mode(s).</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>mode</strong><span class="classifier">ndarray</span></dt><dd><p>Array of modal values.</p>
</dd>
<dt><strong>count</strong><span class="classifier">ndarray</span></dt><dd><p>Array of counts for each mode.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The mode  is calculated using <cite>numpy.unique</cite>.
In NumPy versions 1.21 and after, all NaNs - even those with different
binary representations - are treated as equivalent and counted as separate
instances of the same value.</p>
<p>By convention, the mode of an empty array is NaN, and the associated count
is zero.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">ModeResult(mode=array([[3, 0, 6, 1]]), count=array([[4, 2, 2, 1]]))</span>
</pre></div>
</div>
<p>To get mode of whole array, specify <code class="docutils literal notranslate"><span class="pre">axis=None</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">ModeResult(mode=[[3]], count=[[5]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">ModeResult(mode=3, count=5)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.moment">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">moment</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.moment" title="Link to this definition">#</a></dt>
<dd><p>Calculate the nth moment about the mean for a sample.</p>
<p>A moment is a specific quantitative measure of the shape of a set of
points. It is often used to calculate coefficients of skewness and kurtosis
due to its close relationship with them.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Input array.</p>
</dd>
<dt><strong>order</strong><span class="classifier">int or 1-D array_like of ints, optional</span></dt><dd><p>Order of central moment that is returned. Default is 1.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>center</strong><span class="classifier">float or None, optional</span></dt><dd><p>The point about which moments are taken. This can be the sample mean,
the origin, or any other be point. If <cite>None</cite> (default) compute the
center as the sample mean.</p>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>n-th moment about the `center`</strong><span class="classifier">ndarray or float</span></dt><dd><p>The appropriate moment along the given axis or over all values if axis
is None. The denominator for the moment calculation is the number of
observations, no degrees of freedom correction is done.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.kurtosis" title="barotropy.mcerp.stats.kurtosis"><code class="xref py py-func docutils literal notranslate"><span class="pre">kurtosis()</span></code></a>, <a class="reference internal" href="#barotropy.mcerp.stats.skew" title="barotropy.mcerp.stats.skew"><code class="xref py py-func docutils literal notranslate"><span class="pre">skew()</span></code></a>, <a class="reference internal" href="#barotropy.mcerp.stats.describe" title="barotropy.mcerp.stats.describe"><code class="xref py py-func docutils literal notranslate"><span class="pre">describe()</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The k-th moment of a data sample is:</p>
<div class="math notranslate nohighlight">
\[m_k = \frac{1}{n} \sum_{i = 1}^n (x_i - c)^k\]</div>
<p>Where <cite>n</cite> is the number of samples, and <cite>c</cite> is the center around which the
moment is calculated. This function uses exponentiation by squares <a class="reference internal" href="#r59a837a703f3-1" id="id77">[1]</a> for
efficiency.</p>
<p>Note that, if <cite>a</cite> is an empty array (<code class="docutils literal notranslate"><span class="pre">a.size</span> <span class="pre">==</span> <span class="pre">0</span></code>), array <cite>moment</cite> with
one element (<cite>moment.size == 1</cite>) is treated the same as scalar <cite>moment</cite>
(<code class="docutils literal notranslate"><span class="pre">np.isscalar(moment)</span></code>). This might produce arrays of unexpected shape.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r59a837a703f3-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id77">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://eli.thegreenplace.net/2009/03/21/efficient-integer-exponentiation-algorithms">https://eli.thegreenplace.net/2009/03/21/efficient-integer-exponentiation-algorithms</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">moment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">moment</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">moment</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="go">2.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.mood">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">mood</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.mood" title="Link to this definition">#</a></dt>
<dd><p>Perform Mood’s test for equal scale parameters.</p>
<p>Mood’s two-sample test for scale parameters is a non-parametric
test for the null hypothesis that two samples are drawn from the
same distribution with the same scale parameter.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x, y</strong><span class="classifier">array_like</span></dt><dd><p>Arrays of sample data. There must be at least three observations
total.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
The following options are available:</p>
<ul class="simple">
<li><p>‘two-sided’: the scales of the distributions underlying <cite>x</cite> and <cite>y</cite>
are different.</p></li>
<li><p>‘less’: the scale of the distribution underlying <cite>x</cite> is less than
the scale of the distribution underlying <cite>y</cite>.</p></li>
<li><p>‘greater’: the scale of the distribution underlying <cite>x</cite> is greater
than the scale of the distribution underlying <cite>y</cite>.</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.7.0.</span></p>
</div>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>res</strong><span class="classifier">SignificanceResult</span></dt><dd><p>An object containing attributes:</p>
<dl class="simple">
<dt>statistic<span class="classifier">scalar or ndarray</span></dt><dd><p>The z-score for the hypothesis test.  For 1-D inputs a scalar is
returned.</p>
</dd>
<dt>pvalue<span class="classifier">scalar ndarray</span></dt><dd><p>The p-value for the hypothesis test.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.fligner" title="barotropy.mcerp.stats.fligner"><code class="xref py py-func docutils literal notranslate"><span class="pre">fligner()</span></code></a></dt><dd><p>A non-parametric test for the equality of k variances</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.ansari" title="barotropy.mcerp.stats.ansari"><code class="xref py py-func docutils literal notranslate"><span class="pre">ansari()</span></code></a></dt><dd><p>A non-parametric test for the equality of 2 variances</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.bartlett" title="barotropy.mcerp.stats.bartlett"><code class="xref py py-func docutils literal notranslate"><span class="pre">bartlett()</span></code></a></dt><dd><p>A parametric test for equality of k variances in normal samples</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.levene" title="barotropy.mcerp.stats.levene"><code class="xref py py-func docutils literal notranslate"><span class="pre">levene()</span></code></a></dt><dd><p>A parametric test for equality of k variances</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The data are assumed to be drawn from probability distributions <code class="docutils literal notranslate"><span class="pre">f(x)</span></code>
and <code class="docutils literal notranslate"><span class="pre">f(x/s)</span> <span class="pre">/</span> <span class="pre">s</span></code> respectively, for some probability density function f.
The null hypothesis is that <code class="docutils literal notranslate"><span class="pre">s</span> <span class="pre">==</span> <span class="pre">1</span></code>.</p>
<p>For multi-dimensional arrays, if the inputs are of shapes
<code class="docutils literal notranslate"><span class="pre">(n0,</span> <span class="pre">n1,</span> <span class="pre">n2,</span> <span class="pre">n3)</span></code>  and <code class="docutils literal notranslate"><span class="pre">(n0,</span> <span class="pre">m1,</span> <span class="pre">n2,</span> <span class="pre">n3)</span></code>, then if <code class="docutils literal notranslate"><span class="pre">axis=1</span></code>, the
resulting z and p values will have shape <code class="docutils literal notranslate"><span class="pre">(n0,</span> <span class="pre">n2,</span> <span class="pre">n3)</span></code>.  Note that
<code class="docutils literal notranslate"><span class="pre">n1</span></code> and <code class="docutils literal notranslate"><span class="pre">m1</span></code> don’t have to be equal, but the other dimensions do.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<dl class="simple">
<dt>[1] Mielke, Paul W. “Note on Some Squared Rank Tests with Existing Ties.”</dt><dd><p>Technometrics, vol. 9, no. 2, 1967, pp. 312-14. JSTOR,
<a class="reference external" href="https://doi.org/10.2307/1266427">https://doi.org/10.2307/1266427</a>. Accessed 18 May 2022.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">mood</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 6, 7)</span>
</pre></div>
</div>
<p>Find the number of points where the difference in scale is not significant:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span> <span class="o">&gt;</span> <span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="go">78</span>
</pre></div>
</div>
<p>Perform the test with different scales:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x1</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">35</span><span class="p">))</span> <span class="o">*</span> <span class="mf">10.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">mood</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">SignificanceResult(statistic=array([-5.76174136, -6.12650783]),</span>
<span class="go">                   pvalue=array([8.32505043e-09, 8.98287869e-10]))</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.normaltest">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">normaltest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.normaltest" title="Link to this definition">#</a></dt>
<dd><p>Test whether a sample differs from a normal distribution.</p>
<p>This function tests the null hypothesis that a sample comes
from a normal distribution.  It is based on D’Agostino and
Pearson’s <a class="reference internal" href="#ra45cec176914-1" id="id79">[1]</a>, <a class="reference internal" href="#ra45cec176914-2" id="id80">[2]</a> test that combines skew and kurtosis to
produce an omnibus test of normality.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>The array containing the sample to be tested. Must contain
at least eight observations.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float or array</span></dt><dd><p><code class="docutils literal notranslate"><span class="pre">s^2</span> <span class="pre">+</span> <span class="pre">k^2</span></code>, where <code class="docutils literal notranslate"><span class="pre">s</span></code> is the z-score returned by <cite>skewtest</cite> and
<code class="docutils literal notranslate"><span class="pre">k</span></code> is the z-score returned by <cite>kurtosistest</cite>.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float or array</span></dt><dd><p>A 2-sided chi squared probability for the hypothesis test.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><span class="xref std std-ref">hypothesis_normaltest</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="ra45cec176914-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id79">1</a><span class="fn-bracket">]</span></span>
<p>D’Agostino, R. B. (1971), “An omnibus test of normality for
moderate and large sample size”, Biometrika, 58, 341-348</p>
</div>
<div class="citation" id="ra45cec176914-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id80">2</a><span class="fn-bracket">]</span></span>
<p>D’Agostino, R. and Pearson, E. S. (1973), “Tests for departure from
normality”, Biometrika, 60, 613-622</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pts</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">pts</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">pts</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">normaltest</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">53.619...  # random</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">2.273917413209226e-12  # random</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_normaltest</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.pearsonr">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">pearsonr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.pearsonr" title="Link to this definition">#</a></dt>
<dd><p>Pearson correlation coefficient and p-value for testing non-correlation.</p>
<p>The Pearson correlation coefficient <a class="reference internal" href="#rac61604b8935-1" id="id83">[1]</a> measures the linear relationship
between two datasets. Like other correlation
coefficients, this one varies between -1 and +1 with 0 implying no
correlation. Correlations of -1 or +1 imply an exact linear relationship.
Positive correlations imply that as x increases, so does y. Negative
correlations imply that as x increases, y decreases.</p>
<p>This function also performs a test of the null hypothesis that the
distributions underlying the samples are uncorrelated and normally
distributed. (See Kowalski <a class="reference internal" href="#rac61604b8935-3" id="id84">[3]</a>
for a discussion of the effects of non-normality of the input on the
distribution of the correlation coefficient.)
The p-value roughly indicates the probability of an uncorrelated system
producing datasets that have a Pearson correlation at least as extreme
as the one computed from these datasets.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x</strong><span class="classifier">array_like</span></dt><dd><p>Input array.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array_like</span></dt><dd><p>Input array.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default</span></dt><dd><p>Axis along which to perform the calculation. Default is 0.
If None, ravel both arrays before performing the calculation.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.13.0.</span></p>
</div>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘greater’, ‘less’}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
The following options are available:</p>
<ul class="simple">
<li><p>‘two-sided’: the correlation is nonzero</p></li>
<li><p>‘less’: the correlation is negative (less than zero)</p></li>
<li><p>‘greater’:  the correlation is positive (greater than zero)</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.9.0.</span></p>
</div>
</dd>
<dt><strong>method</strong><span class="classifier">ResamplingMethod, optional</span></dt><dd><p>Defines the method used to compute the p-value. If <cite>method</cite> is an
instance of <cite>PermutationMethod</cite>/<cite>MonteCarloMethod</cite>, the p-value is
computed using
<cite>scipy.stats.permutation_test</cite>/<cite>scipy.stats.monte_carlo_test</cite> with the
provided configuration options and other appropriate settings.
Otherwise, the p-value is computed as documented in the notes.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.11.0.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>result</strong><span class="classifier"><cite>~scipy.stats._result_classes.PearsonRResult</cite></span></dt><dd><p>An object with the following attributes:</p>
<dl class="simple">
<dt>statistic<span class="classifier">float</span></dt><dd><p>Pearson product-moment correlation coefficient.</p>
</dd>
<dt>pvalue<span class="classifier">float</span></dt><dd><p>The p-value associated with the chosen alternative.</p>
</dd>
</dl>
<p>The object has the following method:</p>
<dl class="simple">
<dt>confidence_interval(confidence_level, method)</dt><dd><p>This computes the confidence interval of the correlation
coefficient <cite>statistic</cite> for the given confidence level.
The confidence interval is returned in a <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> with
fields <cite>low</cite> and <cite>high</cite>. If <cite>method</cite> is not provided, the
confidence interval is computed using the Fisher transformation
<a class="reference internal" href="#rac61604b8935-1" id="id85">[1]</a>. If <cite>method</cite> is an instance of <cite>BootstrapMethod</cite>, the
confidence interval is computed using <cite>scipy.stats.bootstrap</cite> with
the provided configuration options and other appropriate settings.
In some cases, confidence limits may be NaN due to a degenerate
resample, and this is typical for very small samples (~6
observations).</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>ValueError</dt><dd><p>If <cite>x</cite> and <cite>y</cite> do not have length at least 2.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Warns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><cite>~scipy.stats.ConstantInputWarning</cite></dt><dd><p>Raised if an input is a constant array.  The correlation coefficient
is not defined in this case, so <code class="docutils literal notranslate"><span class="pre">np.nan</span></code> is returned.</p>
</dd>
<dt><cite>~scipy.stats.NearConstantInputWarning</cite></dt><dd><p>Raised if an input is “nearly” constant.  The array <code class="docutils literal notranslate"><span class="pre">x</span></code> is considered
nearly constant if <code class="docutils literal notranslate"><span class="pre">norm(x</span> <span class="pre">-</span> <span class="pre">mean(x))</span> <span class="pre">&lt;</span> <span class="pre">1e-13</span> <span class="pre">*</span> <span class="pre">abs(mean(x))</span></code>.
Numerical errors in the calculation <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">-</span> <span class="pre">mean(x)</span></code> in this case might
result in an inaccurate calculation of r.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.spearmanr" title="barotropy.mcerp.stats.spearmanr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">spearmanr</span></code></a></dt><dd><p>Spearman rank-order correlation coefficient.</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.kendalltau" title="barotropy.mcerp.stats.kendalltau"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kendalltau</span></code></a></dt><dd><p>Kendall’s tau, a correlation measure for ordinal data.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The correlation coefficient is calculated as follows:</p>
<div class="math notranslate nohighlight">
\[r = \frac{\sum (x - m_x) (y - m_y)}
         {\sqrt{\sum (x - m_x)^2 \sum (y - m_y)^2}}\]</div>
<p>where <span class="math notranslate nohighlight">\(m_x\)</span> is the mean of the vector x and <span class="math notranslate nohighlight">\(m_y\)</span> is
the mean of the vector y.</p>
<p>Under the assumption that x and y are drawn from
independent normal distributions (so the population correlation coefficient
is 0), the probability density function of the sample correlation
coefficient r is (<a class="reference internal" href="#rac61604b8935-1" id="id86">[1]</a>, <a class="reference internal" href="#rac61604b8935-2" id="id87">[2]</a>):</p>
<div class="math notranslate nohighlight">
\[f(r) = \frac{{(1-r^2)}^{n/2-2}}{\mathrm{B}(\frac{1}{2},\frac{n}{2}-1)}\]</div>
<p>where n is the number of samples, and B is the beta function.  This
is sometimes referred to as the exact distribution of r.  This is
the distribution that is used in <cite>pearsonr</cite> to compute the p-value when
the <cite>method</cite> parameter is left at its default value (None).
The distribution is a beta distribution on the interval [-1, 1],
with equal shape parameters a = b = n/2 - 1.  In terms of SciPy’s
implementation of the beta distribution, the distribution of r is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dist</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">/</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>The default p-value returned by <cite>pearsonr</cite> is a two-sided p-value. For a
given sample with correlation coefficient r, the p-value is
the probability that abs(r’) of a random sample x’ and y’ drawn from
the population with zero correlation would be greater than or equal
to abs(r). In terms of the object <code class="docutils literal notranslate"><span class="pre">dist</span></code> shown above, the p-value
for a given r and length n can be computed as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">dist</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">r</span><span class="p">))</span>
</pre></div>
</div>
<p>When n is 2, the above continuous distribution is not well-defined.
One can interpret the limit of the beta distribution as the shape
parameters a and b approach a = b = 0 as a discrete distribution with
equal probability masses at r = 1 and r = -1.  More directly, one
can observe that, given the data x = [x1, x2] and y = [y1, y2], and
assuming x1 != x2 and y1 != y2, the only possible values for r are 1
and -1.  Because abs(r’) for any sample x’ and y’ with length 2 will
be 1, the two-sided p-value for a sample of length 2 is always 1.</p>
<p>For backwards compatibility, the object that is returned also behaves
like a tuple of length two that holds the statistic and the p-value.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rac61604b8935-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id83">1</a>,<a role="doc-backlink" href="#id85">2</a>,<a role="doc-backlink" href="#id86">3</a>)</span>
<p>“Pearson correlation coefficient”, Wikipedia,
<a class="reference external" href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">https://en.wikipedia.org/wiki/Pearson_correlation_coefficient</a></p>
</div>
<div class="citation" id="rac61604b8935-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id87">2</a><span class="fn-bracket">]</span></span>
<p>Student, “Probable error of a correlation coefficient”,
Biometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.</p>
</div>
<div class="citation" id="rac61604b8935-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id84">3</a><span class="fn-bracket">]</span></span>
<p>C. J. Kowalski, “On the Effects of Non-Normality on the Distribution
of the Sample Product-Moment Correlation Coefficient”
Journal of the Royal Statistical Society. Series C (Applied
Statistics), Vol. 21, No. 1 (1972), pp. 1-12.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span>
<span class="go">PearsonRResult(statistic=-0.828503883588428, pvalue=0.021280260007523286)</span>
</pre></div>
</div>
<p>To perform an exact permutation version of the test:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">7796654889291491997</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">method</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">PermutationMethod</span><span class="p">(</span><span class="n">n_resamples</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">)</span>
<span class="go">PearsonRResult(statistic=-0.828503883588428, pvalue=0.028174603174603175)</span>
</pre></div>
</div>
<p>To perform the test under the null hypothesis that the data were drawn from
<em>uniform</em> distributions:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">method</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">MonteCarloMethod</span><span class="p">(</span><span class="n">rvs</span><span class="o">=</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">)</span>
<span class="go">PearsonRResult(statistic=-0.828503883588428, pvalue=0.0188)</span>
</pre></div>
</div>
<p>To produce an asymptotic 90% confidence interval:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="p">(</span><span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="go">ConfidenceInterval(low=-0.9644331982722841, high=-0.3460237473272273)</span>
</pre></div>
</div>
<p>And for a bootstrap confidence interval:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">method</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">BootstrapMethod</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;BCa&#39;</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="p">(</span><span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">)</span>
<span class="go">ConfidenceInterval(low=-0.9983163756488651, high=-0.22771001702132443)  # may vary</span>
</pre></div>
</div>
<p>If N-dimensional arrays are provided, multiple tests are performed in a
single call according to the same conventions as most <cite>scipy.stats</cite> functions:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">2348246935601934321</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">statistic</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># between corresponding columns</span>
<span class="go">(15,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">statistic</span><span class="o">.</span><span class="n">shape</span>  <span class="c1"># between corresponding rows</span>
<span class="go">(8,)</span>
</pre></div>
</div>
<p>To perform all pairwise comparisons between slices of the arrays,
use standard NumPy broadcasting techniques. For instance, to compute the
correlation between all pairs of rows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">,</span> <span class="p">:],</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">statistic</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(8, 8)</span>
</pre></div>
</div>
<p>There is a linear dependence between x and y if y = a + b*x + e, where
a,b are constants and e is a random error term, assumed to be independent
of x. For simplicity, assume that x is standard normal, a=0, b=1 and let
e follow a normal distribution with mean zero and standard deviation s&gt;0.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">e</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">0.9001942438244763</span>
</pre></div>
</div>
<p>This should be close to the exact value given by</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="mi">1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="go">0.8944271909999159</span>
</pre></div>
</div>
<p>For s=0.5, we observe a high level of correlation. In general, a large
variance of the noise reduces the correlation, while the correlation
approaches one as the variance of the error goes to zero.</p>
<p>It is important to keep in mind that no correlation does not imply
independence unless (x, y) is jointly normal. Correlation can even be zero
when there is a very simple dependence structure: if X follows a
standard normal distribution, let y = abs(x). Note that the correlation
between x and y is zero. Indeed, since the expectation of x is zero,
cov(x, y) = E[x*y]. By definition, this equals E[x*abs(x)] which is zero
by symmetry. The following lines of code illustrate this observation:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">PearsonRResult(statistic=-0.05444919272687482, pvalue=0.22422294836207743)</span>
</pre></div>
</div>
<p>A non-zero correlation coefficient can be misleading. For example, if X has
a standard normal distribution, define y = x if x &lt; 0 and y = 0 otherwise.
A simple calculation shows that corr(x, y) = sqrt(2/Pi) = 0.797…,
implying a high level of correlation:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">PearsonRResult(statistic=0.861985781588, pvalue=4.813432002751103e-149)</span>
</pre></div>
</div>
<p>This is unintuitive since there is no dependence of x and y if x is larger
than zero which happens in about half of the cases if we sample x and y.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.percentileofscore">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">percentileofscore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.percentileofscore" title="Link to this definition">#</a></dt>
<dd><p>Compute the percentile rank of a score relative to a list of scores.</p>
<p>A <cite>percentileofscore</cite> of, for example, 80% means that 80% of the
scores in <cite>a</cite> are below the given score. In the case of gaps or
ties, the exact definition depends on the optional keyword, <cite>kind</cite>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>A 1-D array to which <cite>score</cite> is compared.</p>
</dd>
<dt><strong>score</strong><span class="classifier">array_like</span></dt><dd><p>Scores to compute percentiles for.</p>
</dd>
<dt><strong>kind</strong><span class="classifier">{‘rank’, ‘weak’, ‘strict’, ‘mean’}, optional</span></dt><dd><p>Specifies the interpretation of the resulting score.
The following options are available (default is ‘rank’):</p>
<blockquote>
<div><ul class="simple">
<li><p>‘rank’: Average percentage ranking of score.  In case of multiple
matches, average the percentage rankings of all matching scores.</p></li>
<li><p>‘weak’: This kind corresponds to the definition of a cumulative
distribution function.  A percentileofscore of 80% means that 80%
of values are less than or equal to the provided score.</p></li>
<li><p>‘strict’: Similar to “weak”, except that only values that are
strictly less than the given score are counted.</p></li>
<li><p>‘mean’: The average of the “weak” and “strict” scores, often used
in testing.  See <a class="reference external" href="https://en.wikipedia.org/wiki/Percentile_rank">https://en.wikipedia.org/wiki/Percentile_rank</a></p></li>
</ul>
</div></blockquote>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘raise’, ‘omit’}, optional</span></dt><dd><p>Specifies how to treat <cite>nan</cite> values in <cite>a</cite>.
The following options are available (default is ‘propagate’):</p>
<blockquote>
<div><ul class="simple">
<li><p>‘propagate’: returns nan (for each value in <cite>score</cite>).</p></li>
<li><p>‘raise’: throws an error</p></li>
<li><p>‘omit’: performs the calculations ignoring nan values</p></li>
</ul>
</div></blockquote>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>pcos</strong><span class="classifier">float</span></dt><dd><p>Percentile-position of score (0-100) relative to <cite>a</cite>.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.percentile</span></code></dt><dd></dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.stats.scoreatpercentile</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.stats.rankdata</span></code></dt><dd></dd>
</dl>
</div>
<p class="rubric">Examples</p>
<p>Three-quarters of the given values lie below a given score:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">percentileofscore</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">75.0</span>
</pre></div>
</div>
<p>With multiple matches, note how the scores of the two matches, 0.6
and 0.8 respectively, are averaged:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">percentileofscore</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">70.0</span>
</pre></div>
</div>
<p>Only 2/5 values are strictly less than 3:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">percentileofscore</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;strict&#39;</span><span class="p">)</span>
<span class="go">40.0</span>
</pre></div>
</div>
<p>But 4/5 values are less than or equal to 3:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">percentileofscore</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;weak&#39;</span><span class="p">)</span>
<span class="go">80.0</span>
</pre></div>
</div>
<p>The average between the weak and the strict scores is:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">percentileofscore</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
<span class="go">60.0</span>
</pre></div>
</div>
<p>Score arrays (of any dimensionality) are supported:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">percentileofscore</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="go">array([40., 70.])</span>
</pre></div>
</div>
<p>The inputs can be infinite:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">percentileofscore</span><span class="p">([</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">])</span>
<span class="go">array([75., 75., 100.])</span>
</pre></div>
</div>
<p>If <cite>a</cite> is empty, then the resulting percentiles are all <cite>nan</cite>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">percentileofscore</span><span class="p">([],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">array([nan, nan])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.pointbiserialr">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">pointbiserialr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.pointbiserialr" title="Link to this definition">#</a></dt>
<dd><p>Calculate a point biserial correlation coefficient and its p-value.</p>
<p>The point biserial correlation is used to measure the relationship
between a binary variable, x, and a continuous variable, y. Like other
correlation coefficients, this one varies between -1 and +1 with 0
implying no correlation. Correlations of -1 or +1 imply a determinative
relationship.</p>
<p>This function may be computed using a shortcut formula but produces the
same result as <cite>pearsonr</cite>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">array_like of bools</span></dt><dd><p>Input array.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array_like</span></dt><dd><p>Input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt>res: SignificanceResult</dt><dd><p>An object containing attributes:</p>
<dl class="simple">
<dt>statistic<span class="classifier">float</span></dt><dd><p>The R value.</p>
</dd>
<dt>pvalue<span class="classifier">float</span></dt><dd><p>The two-sided p-value.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><cite>pointbiserialr</cite> uses a t-test with <code class="docutils literal notranslate"><span class="pre">n-1</span></code> degrees of freedom.
It is equivalent to <cite>pearsonr</cite>.</p>
<p>The value of the point-biserial correlation can be calculated from:</p>
<div class="math notranslate nohighlight">
\[r_{pb} = \frac{\overline{Y_1} - \overline{Y_0}}
              {s_y}
         \sqrt{\frac{N_0 N_1}
                    {N (N - 1)}}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\overline{Y_{0}}\)</span> and <span class="math notranslate nohighlight">\(\overline{Y_{1}}\)</span> are means
of the metric observations coded 0 and 1 respectively; <span class="math notranslate nohighlight">\(N_{0}\)</span> and
<span class="math notranslate nohighlight">\(N_{1}\)</span> are number of observations coded 0 and 1 respectively;
<span class="math notranslate nohighlight">\(N\)</span> is the total number of observations and <span class="math notranslate nohighlight">\(s_{y}\)</span> is the
standard deviation of all the metric observations.</p>
<p>A value of <span class="math notranslate nohighlight">\(r_{pb}\)</span> that is significantly different from zero is
completely equivalent to a significant difference in means between the two
groups. Thus, an independent groups t Test with <span class="math notranslate nohighlight">\(N-2\)</span> degrees of
freedom may be used to test whether <span class="math notranslate nohighlight">\(r_{pb}\)</span> is nonzero. The
relation between the t-statistic for comparing two independent groups and
<span class="math notranslate nohighlight">\(r_{pb}\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[t = \sqrt{N - 2}\frac{r_{pb}}{\sqrt{1 - r^{2}_{pb}}}\]</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r295c3393b03a-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>J. Lev, “The Point Biserial Coefficient of Correlation”, Ann. Math.
Statist., Vol. 20, no.1, pp. 125-126, 1949.</p>
</div>
<div class="citation" id="r295c3393b03a-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>R.F. Tate, “Correlation Between a Discrete and a Continuous
Variable. Point-Biserial Correlation.”, Ann. Math. Statist., Vol. 25,
np. 3, pp. 603-607, 1954.</p>
</div>
<div class="citation" id="r295c3393b03a-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>D. Kornbrot “Point Biserial Correlation”, In Wiley StatsRef:
Statistics Reference Online (eds N. Balakrishnan, et al.), 2014.
<a href="#id91"><span class="problematic" id="id92">:doi:`10.1002/9781118445112.stat06227`</span></a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pointbiserialr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">(0.8660254037844386, 0.011724811003954652)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">(0.86602540378443871, 0.011724811003954626)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">array([[ 1.       ,  0.8660254],</span>
<span class="go">       [ 0.8660254,  1.       ]])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.rankdata">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">rankdata</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.rankdata" title="Link to this definition">#</a></dt>
<dd><p>Assign ranks to data, dealing with ties appropriately.</p>
<p>By default (<code class="docutils literal notranslate"><span class="pre">axis=None</span></code>), the data array is first flattened, and a flat
array of ranks is returned. Separately reshape the rank array to the
shape of the data array if desired (see Examples).</p>
<p>Ranks begin at 1.  The <cite>method</cite> argument controls how ranks are assigned
to equal values.  See <a class="reference internal" href="#r6d4d3430e7a8-1" id="id96">[1]</a> for further discussion of ranking methods.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>The array of values to be ranked.</p>
</dd>
<dt><strong>method</strong><span class="classifier">{‘average’, ‘min’, ‘max’, ‘dense’, ‘ordinal’}, optional</span></dt><dd><p>The method used to assign ranks to tied elements.
The following methods are available (default is ‘average’):</p>
<blockquote>
<div><ul class="simple">
<li><p>‘average’: The average of the ranks that would have been assigned to
all the tied values is assigned to each value.</p></li>
<li><p>‘min’: The minimum of the ranks that would have been assigned to all
the tied values is assigned to each value.  (This is also
referred to as “competition” ranking.)</p></li>
<li><p>‘max’: The maximum of the ranks that would have been assigned to all
the tied values is assigned to each value.</p></li>
<li><p>‘dense’: Like ‘min’, but the rank of the next highest element is
assigned the rank immediately after those assigned to the tied
elements.</p></li>
<li><p>‘ordinal’: All values are given a distinct rank, corresponding to
the order that the values occur in <cite>a</cite>.</p></li>
</ul>
</div></blockquote>
</dd>
<dt><strong>axis</strong><span class="classifier">{None, int}, optional</span></dt><dd><p>Axis along which to perform the ranking. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the data array
is first flattened.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}, optional</span></dt><dd><p>Defines how to handle when input contains nan.
The following options are available (default is ‘propagate’):</p>
<blockquote>
<div><ul class="simple">
<li><p>‘propagate’: propagates nans through the rank calculation</p></li>
<li><p>‘omit’: performs the calculations ignoring nan values</p></li>
<li><p>‘raise’: raises an error</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <cite>nan_policy</cite> is ‘propagate’, the output is an array of <em>all</em>
nans because ranks relative to nans in the input are undefined.
When <cite>nan_policy</cite> is ‘omit’, nans in <cite>a</cite> are ignored when ranking
the other values, and the corresponding locations of the output
are nan.</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.10.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>ranks</strong><span class="classifier">ndarray</span></dt><dd><p>An array of size equal to the size of <cite>a</cite>, containing rank
scores.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r6d4d3430e7a8-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id96">1</a><span class="fn-bracket">]</span></span>
<p>“Ranking”, <a class="reference external" href="https://en.wikipedia.org/wiki/Ranking">https://en.wikipedia.org/wiki/Ranking</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">rankdata</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rankdata</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="go">array([ 1. ,  2.5,  4. ,  2.5])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rankdata</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">)</span>
<span class="go">array([ 1,  2,  4,  2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rankdata</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">)</span>
<span class="go">array([ 1,  3,  4,  3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rankdata</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;dense&#39;</span><span class="p">)</span>
<span class="go">array([ 1,  2,  3,  2])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rankdata</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;ordinal&#39;</span><span class="p">)</span>
<span class="go">array([ 1,  2,  4,  3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rankdata</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="go">array([[1. , 2.5],</span>
<span class="go">      [4. , 2.5]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rankdata</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[1. , 2.5, 2.5],</span>
<span class="go">       [2. , 1. , 3. ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rankdata</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">],</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s2">&quot;propagate&quot;</span><span class="p">)</span>
<span class="go">array([nan, nan, nan, nan, nan, nan])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rankdata</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">],</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s2">&quot;omit&quot;</span><span class="p">)</span>
<span class="go">array([ 2.,  3.,  4., nan,  1., nan])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.ranksums">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">ranksums</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.ranksums" title="Link to this definition">#</a></dt>
<dd><p>Compute the Wilcoxon rank-sum statistic for two samples.</p>
<p>The Wilcoxon rank-sum test tests the null hypothesis that two sets
of measurements are drawn from the same distribution.  The alternative
hypothesis is that values in one sample are more likely to be
larger than the values in the other sample.</p>
<p>This test should be used to compare two samples from continuous
distributions.  It does not handle ties between measurements
in x and y.  For tie-handling and an optional continuity correction
see <cite>scipy.stats.mannwhitneyu</cite>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x,y</strong><span class="classifier">array_like</span></dt><dd><p>The data from the two samples.</p>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
The following options are available:</p>
<ul class="simple">
<li><p>‘two-sided’: one of the distributions (underlying <cite>x</cite> or <cite>y</cite>) is
stochastically greater than the other.</p></li>
<li><p>‘less’: the distribution underlying <cite>x</cite> is stochastically less
than the distribution underlying <cite>y</cite>.</p></li>
<li><p>‘greater’: the distribution underlying <cite>x</cite> is stochastically greater
than the distribution underlying <cite>y</cite>.</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.7.0.</span></p>
</div>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The test statistic under the large-sample approximation that the
rank sum statistic is normally distributed.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The p-value of the test.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r1ba6f0759aba-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Wilcoxon_rank-sum_test">https://en.wikipedia.org/wiki/Wilcoxon_rank-sum_test</a></p>
</div>
</div>
<p class="rubric">Examples</p>
<p>We can test the hypothesis that two independent unequal-sized samples are
drawn from the same distribution with computing the Wilcoxon rank-sum
statistic.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">ranksums</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample1</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sample2</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span> <span class="c1"># a shifted distribution</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ranksums</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">)</span>
<span class="go">RanksumsResult(statistic=-7.887059,</span>
<span class="go">               pvalue=3.09390448e-15) # may vary</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ranksums</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;less&#39;</span><span class="p">)</span>
<span class="go">RanksumsResult(statistic=-7.750585297581713,</span>
<span class="go">               pvalue=4.573497606342543e-15) # may vary</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ranksums</span><span class="p">(</span><span class="n">sample1</span><span class="p">,</span> <span class="n">sample2</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="go">RanksumsResult(statistic=-7.750585297581713,</span>
<span class="go">               pvalue=0.9999999999999954) # may vary</span>
</pre></div>
</div>
<p>The p-value of less than <code class="docutils literal notranslate"><span class="pre">0.05</span></code> indicates that this test rejects the
hypothesis at the 5% significance level.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.scoreatpercentile">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">scoreatpercentile</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.scoreatpercentile" title="Link to this definition">#</a></dt>
<dd><p>Calculate the score at a given percentile of the input sequence.</p>
<p>For example, the score at <code class="docutils literal notranslate"><span class="pre">per=50</span></code> is the median. If the desired quantile
lies between two data points, we interpolate between them, according to
the value of <cite>interpolation</cite>. If the parameter <cite>limit</cite> is provided, it
should be a tuple (lower, upper) of two values.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>A 1-D array of values from which to extract score.</p>
</dd>
<dt><strong>per</strong><span class="classifier">array_like</span></dt><dd><p>Percentile(s) at which to extract score.  Values should be in range
[0,100].</p>
</dd>
<dt><strong>limit</strong><span class="classifier">tuple, optional</span></dt><dd><p>Tuple of two scalars, the lower and upper limits within which to
compute the percentile. Values of <cite>a</cite> outside
this (closed) interval will be ignored.</p>
</dd>
<dt><strong>interpolation_method</strong><span class="classifier">{‘fraction’, ‘lower’, ‘higher’}, optional</span></dt><dd><p>Specifies the interpolation method to use,
when the desired quantile lies between two data points <cite>i</cite> and <cite>j</cite>
The following options are available (default is ‘fraction’):</p>
<blockquote>
<div><ul class="simple">
<li><p>‘fraction’: <code class="docutils literal notranslate"><span class="pre">i</span> <span class="pre">+</span> <span class="pre">(j</span> <span class="pre">-</span> <span class="pre">i)</span> <span class="pre">*</span> <span class="pre">fraction</span></code> where <code class="docutils literal notranslate"><span class="pre">fraction</span></code> is the
fractional part of the index surrounded by <code class="docutils literal notranslate"><span class="pre">i</span></code> and <code class="docutils literal notranslate"><span class="pre">j</span></code></p></li>
<li><p>‘lower’: <code class="docutils literal notranslate"><span class="pre">i</span></code></p></li>
<li><p>‘higher’: <code class="docutils literal notranslate"><span class="pre">j</span></code></p></li>
</ul>
</div></blockquote>
</dd>
<dt><strong>axis</strong><span class="classifier">int, optional</span></dt><dd><p>Axis along which the percentiles are computed. Default is None. If
None, compute over the whole array <cite>a</cite>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float or ndarray</span></dt><dd><p>Score at percentile(s).</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.percentileofscore" title="barotropy.mcerp.stats.percentileofscore"><code class="xref py py-obj docutils literal notranslate"><span class="pre">percentileofscore</span></code></a>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.percentile</span></code></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This function will become obsolete in the future.
For NumPy 1.9 and higher, <cite>numpy.percentile</cite> provides all the functionality
that <cite>scoreatpercentile</cite> provides.  And it’s significantly faster.
Therefore it’s recommended to use <cite>numpy.percentile</cite> for users that have
numpy &gt;= 1.9.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">scoreatpercentile</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="go">49.5</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.sem">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">sem</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.sem" title="Link to this definition">#</a></dt>
<dd><p>Compute standard error of the mean.</p>
<p>Calculate the standard error of the mean (or standard error of
measurement) of the values in the input array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>An array containing the values for which the standard error is
returned. Must contain at least two observations.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>Delta degrees-of-freedom. How many degrees of freedom to adjust
for bias in limited samples relative to the population estimate
of variance. Defaults to 1.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>s</strong><span class="classifier">ndarray or float</span></dt><dd><p>The standard error of the mean in the sample(s), along the input axis.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The default value for <cite>ddof</cite> is different to the default (0) used by other
ddof containing routines, such as np.std and np.nanstd.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<p>Find standard error along the first axis:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">sem</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">array([ 2.8284,  2.8284,  2.8284,  2.8284])</span>
</pre></div>
</div>
<p>Find standard error across the whole array, using n degrees of freedom:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">sem</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">1.2893796958227628</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.shapiro">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">shapiro</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.shapiro" title="Link to this definition">#</a></dt>
<dd><p>Perform the Shapiro-Wilk test for normality.</p>
<p>The Shapiro-Wilk test tests the null hypothesis that the
data was drawn from a normal distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>x</strong><span class="classifier">array_like</span></dt><dd><p>Array of sample data. Must contain at least three observations.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: None</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The test statistic.</p>
</dd>
<dt><strong>p-value</strong><span class="classifier">float</span></dt><dd><p>The p-value for the hypothesis test.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.anderson" title="barotropy.mcerp.stats.anderson"><code class="xref py py-func docutils literal notranslate"><span class="pre">anderson()</span></code></a></dt><dd><p>The Anderson-Darling test for normality</p>
</dd>
<dt><a class="reference internal" href="#barotropy.mcerp.stats.kstest" title="barotropy.mcerp.stats.kstest"><code class="xref py py-func docutils literal notranslate"><span class="pre">kstest()</span></code></a></dt><dd><p>The Kolmogorov-Smirnov test for goodness of fit.</p>
</dd>
<dt><span class="xref std std-ref">hypothesis_shapiro</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The algorithm used is described in <a class="reference internal" href="#r45a02875cbd4-4" id="id99">[4]</a> but censoring parameters as
described are not implemented. For N &gt; 5000 the W test statistic is
accurate, but the p-value may not be.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r45a02875cbd4-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm">https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm</a>
<a href="#id100"><span class="problematic" id="id101">:doi:`10.18434/M32189`</span></a></p>
</div>
<div class="citation" id="r45a02875cbd4-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Shapiro, S. S. &amp; Wilk, M.B, “An analysis of variance test for
normality (complete samples)”, Biometrika, 1965, Vol. 52,
pp. 591-611, <a href="#id102"><span class="problematic" id="id103">:doi:`10.2307/2333709`</span></a></p>
</div>
<div class="citation" id="r45a02875cbd4-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<p>Razali, N. M. &amp; Wah, Y. B., “Power comparisons of Shapiro-Wilk,
Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests”, Journal
of Statistical Modeling and Analytics, 2011, Vol. 2, pp. 21-33.</p>
</div>
<div class="citation" id="r45a02875cbd4-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id99">4</a><span class="fn-bracket">]</span></span>
<p>Royston P., “Remark AS R94: A Remark on Algorithm AS 181: The
W-test for Normality”, 1995, Applied Statistics, Vol. 44,
<a href="#id104"><span class="problematic" id="id105">:doi:`10.2307/2986146`</span></a></p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shapiro_test</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">shapiro</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shapiro_test</span>
<span class="go">ShapiroResult(statistic=0.9813305735588074, pvalue=0.16855233907699585)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shapiro_test</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">0.9813305735588074</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shapiro_test</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">0.16855233907699585</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_shapiro</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.skew">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">skew</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.skew" title="Link to this definition">#</a></dt>
<dd><p>Compute the sample skewness of a data set.</p>
<p>For normally distributed data, the skewness should be about zero. For
unimodal continuous distributions, a skewness value greater than zero means
that there is more weight in the right tail of the distribution. The
function <cite>skewtest</cite> can be used to determine if the skewness value
is close enough to zero, statistically speaking.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">ndarray</span></dt><dd><p>Input array.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>bias</strong><span class="classifier">bool, optional</span></dt><dd><p>If False, then the calculations are corrected for statistical bias.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>skewness</strong><span class="classifier">ndarray</span></dt><dd><p>The skewness of values along an axis, returning NaN where all values
are equal.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The sample skewness is computed as the Fisher-Pearson coefficient
of skewness, i.e.</p>
<div class="math notranslate nohighlight">
\[g_1=\frac{m_3}{m_2^{3/2}}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[m_i=\frac{1}{N}\sum_{n=1}^N(x[n]-\bar{x})^i\]</div>
<p>is the biased sample <span class="math notranslate nohighlight">\(i\texttt{th}\)</span> central moment, and
<span class="math notranslate nohighlight">\(\bar{x}\)</span> is
the sample mean.  If <code class="docutils literal notranslate"><span class="pre">bias</span></code> is False, the calculations are
corrected for bias and the value computed is the adjusted
Fisher-Pearson standardized moment coefficient, i.e.</p>
<div class="math notranslate nohighlight">
\[G_1=\frac{k_3}{k_2^{3/2}}=
    \frac{\sqrt{N(N-1)}}{N-2}\frac{m_3}{m_2^{3/2}}.\]</div>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rc37c286fb3bc-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Zwillinger, D. and Kokoska, S. (2000). CRC Standard
Probability and Statistics Tables and Formulae. Chapman &amp; Hall: New
York. 2000.
Section 2.2.24.1</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">skew</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skew</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="go">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skew</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">0.2650554122698573</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.skewtest">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">skewtest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.skewtest" title="Link to this definition">#</a></dt>
<dd><p>Test whether the skew is different from the normal distribution.</p>
<p>This function tests the null hypothesis that the skewness of
the population that the sample was drawn from is the same
as that of a corresponding normal distribution.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>a</strong><span class="classifier">array</span></dt><dd><p>The data to be tested. Must contain at least eight observations.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
The following options are available:</p>
<ul class="simple">
<li><p>‘two-sided’: the skewness of the distribution underlying the sample
is different from that of the normal distribution (i.e. 0)</p></li>
<li><p>‘less’: the skewness of the distribution underlying the sample
is less than that of the normal distribution</p></li>
<li><p>‘greater’: the skewness of the distribution underlying the sample
is greater than that of the normal distribution</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.7.0.</span></p>
</div>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>statistic</strong><span class="classifier">float</span></dt><dd><p>The computed z-score for this test.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">float</span></dt><dd><p>The p-value for the hypothesis test.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><span class="xref std std-ref">hypothesis_skewtest</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The sample size must be at least 8.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r0b64f083da70-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>R. B. D’Agostino, A. J. Belanger and R. B. D’Agostino Jr.,
“A suggestion for using powerful and informative tests of
normality”, American Statistician 44, pp. 316-321, 1990.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">skewtest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skewtest</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">])</span>
<span class="go">SkewtestResult(statistic=1.0108048609177787, pvalue=0.3121098361421897)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skewtest</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="go">SkewtestResult(statistic=0.44626385374196975, pvalue=0.6554066631275459)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skewtest</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8000</span><span class="p">])</span>
<span class="go">SkewtestResult(statistic=3.571773510360407, pvalue=0.0003545719905823133)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skewtest</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">101</span><span class="p">])</span>
<span class="go">SkewtestResult(statistic=3.5717766638478072, pvalue=0.000354567720281634)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skewtest</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;less&#39;</span><span class="p">)</span>
<span class="go">SkewtestResult(statistic=1.0108048609177787, pvalue=0.8439450819289052)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skewtest</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="go">SkewtestResult(statistic=1.0108048609177787, pvalue=0.15605491807109484)</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_skewtest</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.spearmanr">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">spearmanr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.spearmanr" title="Link to this definition">#</a></dt>
<dd><p>Calculate a Spearman correlation coefficient with associated p-value.</p>
<p>The Spearman rank-order correlation coefficient is a nonparametric measure
of the monotonicity of the relationship between two datasets.
Like other correlation coefficients,
this one varies between -1 and +1 with 0 implying no correlation.
Correlations of -1 or +1 imply an exact monotonic relationship. Positive
correlations imply that as x increases, so does y. Negative correlations
imply that as x increases, y decreases.</p>
<p>The p-value roughly indicates the probability of an uncorrelated system
producing datasets that have a Spearman correlation at least as extreme
as the one computed from these datasets. Although calculation of the
p-value does not make strong assumptions about the distributions underlying
the samples, it is only accurate for very large samples (&gt;500
observations). For smaller sample sizes, consider a permutation test (see
Examples section below).</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>a, b</strong><span class="classifier">1D or 2D array_like, b is optional</span></dt><dd><p>One or two 1-D or 2-D arrays containing multiple variables and
observations. When these are 1-D, each represents a vector of
observations of a single variable. For the behavior in the 2-D case,
see under <code class="docutils literal notranslate"><span class="pre">axis</span></code>, below.
Both arrays need to have the same length in the <code class="docutils literal notranslate"><span class="pre">axis</span></code> dimension.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>If axis=0 (default), then each column represents a variable, with
observations in the rows. If axis=1, the relationship is transposed:
each row represents a variable, while the columns contain observations.
If axis=None, then both arrays will be raveled.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘raise’, ‘omit’}, optional</span></dt><dd><p>Defines how to handle when input contains nan.
The following options are available (default is ‘propagate’):</p>
<ul class="simple">
<li><p>‘propagate’: returns nan</p></li>
<li><p>‘raise’: throws an error</p></li>
<li><p>‘omit’: performs the calculations ignoring nan values</p></li>
</ul>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
The following options are available:</p>
<ul class="simple">
<li><p>‘two-sided’: the correlation is nonzero</p></li>
<li><p>‘less’: the correlation is negative (less than zero)</p></li>
<li><p>‘greater’:  the correlation is positive (greater than zero)</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.7.0.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>res</strong><span class="classifier">SignificanceResult</span></dt><dd><p>An object containing attributes:</p>
<dl class="simple">
<dt>statistic<span class="classifier">float or ndarray (2-D square)</span></dt><dd><p>Spearman correlation matrix or correlation coefficient (if only 2
variables are given as parameters). Correlation matrix is square
with length equal to total number of variables (columns or rows) in
<code class="docutils literal notranslate"><span class="pre">a</span></code> and <code class="docutils literal notranslate"><span class="pre">b</span></code> combined.</p>
</dd>
<dt>pvalue<span class="classifier">float</span></dt><dd><p>The p-value for a hypothesis test whose null hypothesis
is that two samples have no ordinal correlation. See
<cite>alternative</cite> above for alternative hypotheses. <cite>pvalue</cite> has the
same shape as <cite>statistic</cite>.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt>ValueError</dt><dd><p>If <cite>axis</cite> is not 0, 1 or None, or if the number of dimensions of <cite>a</cite>
is greater than 2, or if <cite>b</cite> is None and the number of dimensions of
<cite>a</cite> is less than 2.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Warns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><cite>~scipy.stats.ConstantInputWarning</cite></dt><dd><p>Raised if an input is a constant array.  The correlation coefficient
is not defined in this case, so <code class="docutils literal notranslate"><span class="pre">np.nan</span></code> is returned.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><span class="xref std std-ref">hypothesis_spearmanr</span></dt><dd><p>Extended example</p>
</dd>
</dl>
</div>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rcf7feca3e5ac-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Zwillinger, D. and Kokoska, S. (2000). CRC Standard
Probability and Statistics Tables and Formulae. Chapman &amp; Hall: New
York. 2000.
Section  14.7</p>
</div>
<div class="citation" id="rcf7feca3e5ac-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Kendall, M. G. and Stuart, A. (1973).
The Advanced Theory of Statistics, Volume 2: Inference and Relationship.
Griffin. 1973.
Section 31.18</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">0.8207826816681233</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">0.08858700531354381</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x2n</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y2n</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">x2n</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">(-0.07960396039603959, 0.4311168705769747)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">x2n</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x2n</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">(-0.07960396039603959, 0.4311168705769747)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">x2n</span><span class="p">,</span> <span class="n">y2n</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">array([[ 1. , -0.07960396, -0.08314431, 0.09662166],</span>
<span class="go">       [-0.07960396, 1. , -0.14448245, 0.16738074],</span>
<span class="go">       [-0.08314431, -0.14448245, 1. , 0.03234323],</span>
<span class="go">       [ 0.09662166, 0.16738074, 0.03234323, 1. ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">array([[0. , 0.43111687, 0.41084066, 0.33891628],</span>
<span class="go">       [0.43111687, 0. , 0.15151618, 0.09600687],</span>
<span class="go">       [0.41084066, 0.15151618, 0. , 0.74938561],</span>
<span class="go">       [0.33891628, 0.09600687, 0.74938561, 0. ]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">x2n</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">y2n</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span>
<span class="go">array([[ 1. , -0.07960396, -0.08314431, 0.09662166],</span>
<span class="go">       [-0.07960396, 1. , -0.14448245, 0.16738074],</span>
<span class="go">       [-0.08314431, -0.14448245, 1. , 0.03234323],</span>
<span class="go">       [ 0.09662166, 0.16738074, 0.03234323, 1. ]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">x2n</span><span class="p">,</span> <span class="n">y2n</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">(0.044981624540613524, 0.5270803651336189)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">x2n</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y2n</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">(0.044981624540613524, 0.5270803651336189)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xint</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">xint</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">(0.09800224850707953, 0.3320271757932076)</span>
</pre></div>
</div>
<p>For small samples, consider performing a permutation test instead of
relying on the asymptotic p-value. Note that to calculate the null
distribution of the statistic (for all possibly pairings between
observations in sample <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>), only one of the two inputs needs
to be permuted.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.76405235</span><span class="p">,</span> <span class="mf">0.40015721</span><span class="p">,</span> <span class="mf">0.97873798</span><span class="p">,</span>
<span class="gp">... </span><span class="mf">2.2408932</span><span class="p">,</span> <span class="mf">1.86755799</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.97727788</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.71414076</span><span class="p">,</span> <span class="mf">0.2488</span><span class="p">,</span> <span class="mf">0.87551913</span><span class="p">,</span>
<span class="gp">... </span><span class="mf">2.6514917</span><span class="p">,</span> <span class="mf">2.01160156</span><span class="p">,</span> <span class="mf">0.47699563</span><span class="p">]</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span><span class="w"> </span><span class="nf">statistic</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="c1"># permute only `x`</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">statistic</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res_exact</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">permutation_test</span><span class="p">((</span><span class="n">x</span><span class="p">,),</span> <span class="n">statistic</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">permutation_type</span><span class="o">=</span><span class="s1">&#39;pairings&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res_asymptotic</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res_exact</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="n">res_asymptotic</span><span class="o">.</span><span class="n">pvalue</span> <span class="c1"># asymptotic pvalue is too low</span>
<span class="go">(0.10277777777777777, 0.07239650145772594)</span>
</pre></div>
</div>
<p>For a more detailed example, see <span class="xref std std-ref">hypothesis_spearmanr</span>.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.tmax">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">tmax</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.tmax" title="Link to this definition">#</a></dt>
<dd><p>Compute the trimmed maximum.</p>
<p>This function computes the maximum value of an array along a given axis,
while ignoring values larger than a specified upper limit.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Array of values.</p>
</dd>
<dt><strong>upperlimit</strong><span class="classifier">None or float, optional</span></dt><dd><p>Values in the input array greater than the given limit will be ignored.
When upperlimit is None, then all values are used. The default value
is None.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>inclusive</strong><span class="classifier">{True, False}, optional</span></dt><dd><p>This flag determines whether values exactly equal to the upper limit
are included.  The default value is True.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>tmax</strong><span class="classifier">float, int or ndarray</span></dt><dd><p>Trimmed maximum.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">19</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span>
<span class="go">13</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">12</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.tmean">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">tmean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.tmean" title="Link to this definition">#</a></dt>
<dd><p>Compute the trimmed mean.</p>
<p>This function finds the arithmetic mean of given values, ignoring values
outside the given <cite>limits</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Array of values.</p>
</dd>
<dt><strong>limits</strong><span class="classifier">None or (lower limit, upper limit), optional</span></dt><dd><p>Values in the input array less than the lower limit or greater than the
upper limit will be ignored.  When limits is None (default), then all
values are used.  Either of the limit values in the tuple can also be
None representing a half-open interval.</p>
</dd>
<dt><strong>inclusive</strong><span class="classifier">(bool, bool), optional</span></dt><dd><p>A tuple consisting of the (lower flag, upper flag).  These flags
determine whether values exactly equal to the lower or upper limits
are included.  The default value is (True, True).</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: None</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>tmean</strong><span class="classifier">ndarray</span></dt><dd><p>Trimmed mean.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-func docutils literal notranslate"><span class="pre">trim_mean()</span></code></dt><dd><p>Returns mean after trimming a proportion from both tails.</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tmean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">9.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tmean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">17</span><span class="p">))</span>
<span class="go">10.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.tmin">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">tmin</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.tmin" title="Link to this definition">#</a></dt>
<dd><p>Compute the trimmed minimum.</p>
<p>This function finds the minimum value of an array <cite>a</cite> along the
specified axis, but only considering values greater than a specified
lower limit.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Array of values.</p>
</dd>
<dt><strong>lowerlimit</strong><span class="classifier">None or float, optional</span></dt><dd><p>Values in the input array less than the given limit will be ignored.
When lowerlimit is None, then all values are used. The default value
is None.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>inclusive</strong><span class="classifier">{True, False}, optional</span></dt><dd><p>This flag determines whether values exactly equal to the lower limit
are included.  The default value is True.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>tmin</strong><span class="classifier">float, int or ndarray</span></dt><dd><p>Trimmed minimum.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tmin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">0</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tmin</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span>
<span class="go">13</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tmin</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="n">inclusive</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">14</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.tsem">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">tsem</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.tsem" title="Link to this definition">#</a></dt>
<dd><p>Compute the trimmed standard error of the mean.</p>
<p>This function finds the standard error of the mean for given
values, ignoring values outside the given <cite>limits</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Array of values.</p>
</dd>
<dt><strong>limits</strong><span class="classifier">None or (lower limit, upper limit), optional</span></dt><dd><p>Values in the input array less than the lower limit or greater than the
upper limit will be ignored. When limits is None, then all values are
used. Either of the limit values in the tuple can also be None
representing a half-open interval.  The default value is None.</p>
</dd>
<dt><strong>inclusive</strong><span class="classifier">(bool, bool), optional</span></dt><dd><p>A tuple consisting of the (lower flag, upper flag).  These flags
determine whether values exactly equal to the lower or upper limits
are included.  The default value is (True, True).</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>Delta degrees of freedom.  Default is 1.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>tsem</strong><span class="classifier">float</span></dt><dd><p>Trimmed standard error of the mean.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><cite>tsem</cite> uses unbiased sample standard deviation, i.e. it uses a
correction factor <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">/</span> <span class="pre">(n</span> <span class="pre">-</span> <span class="pre">1)</span></code>.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tsem</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">1.3228756555322954</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tsem</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">17</span><span class="p">))</span>
<span class="go">1.1547005383792515</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.tstd">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">tstd</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.tstd" title="Link to this definition">#</a></dt>
<dd><p>Compute the trimmed sample standard deviation.</p>
<p>This function finds the sample standard deviation of given values,
ignoring values outside the given <cite>limits</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Array of values.</p>
</dd>
<dt><strong>limits</strong><span class="classifier">None or (lower limit, upper limit), optional</span></dt><dd><p>Values in the input array less than the lower limit or greater than the
upper limit will be ignored. When limits is None, then all values are
used. Either of the limit values in the tuple can also be None
representing a half-open interval.  The default value is None.</p>
</dd>
<dt><strong>inclusive</strong><span class="classifier">(bool, bool), optional</span></dt><dd><p>A tuple consisting of the (lower flag, upper flag).  These flags
determine whether values exactly equal to the lower or upper limits
are included.  The default value is (True, True).</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>Delta degrees of freedom.  Default is 1.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>tstd</strong><span class="classifier">float</span></dt><dd><p>Trimmed sample standard deviation.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><cite>tstd</cite> computes the unbiased sample standard deviation, i.e. it uses a
correction factor <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">/</span> <span class="pre">(n</span> <span class="pre">-</span> <span class="pre">1)</span></code>.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tstd</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">5.9160797830996161</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tstd</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">17</span><span class="p">))</span>
<span class="go">4.4721359549995796</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.ttest_1samp">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">ttest_1samp</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.ttest_1samp" title="Link to this definition">#</a></dt>
<dd><p>Calculate the T-test for the mean of ONE group of scores.</p>
<p>This is a test for the null hypothesis that the expected value
(mean) of a sample of independent observations <cite>a</cite> is equal to the given
population mean, <cite>popmean</cite>.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Sample observations.</p>
</dd>
<dt><strong>popmean</strong><span class="classifier">float or array_like</span></dt><dd><p>Expected value in null hypothesis. If array_like, then its length along
<cite>axis</cite> must equal 1, and it must otherwise be broadcastable with <cite>a</cite>.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis.
The following options are available (default is ‘two-sided’):</p>
<ul class="simple">
<li><p>‘two-sided’: the mean of the underlying distribution of the sample
is different than the given population mean (<cite>popmean</cite>)</p></li>
<li><p>‘less’: the mean of the underlying distribution of the sample is
less than the given population mean (<cite>popmean</cite>)</p></li>
<li><p>‘greater’: the mean of the underlying distribution of the sample is
greater than the given population mean (<cite>popmean</cite>)</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>result</strong><span class="classifier"><cite>~scipy.stats._result_classes.TtestResult</cite></span></dt><dd><p>An object with the following attributes:</p>
<dl>
<dt>statistic<span class="classifier">float or array</span></dt><dd><p>The t-statistic.</p>
</dd>
<dt>pvalue<span class="classifier">float or array</span></dt><dd><p>The p-value associated with the given alternative.</p>
</dd>
<dt>df<span class="classifier">float or array</span></dt><dd><p>The number of degrees of freedom used in calculation of the
t-statistic; this is one less than the size of the sample
(<code class="docutils literal notranslate"><span class="pre">a.shape[axis]</span></code>).</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.10.0.</span></p>
</div>
</dd>
</dl>
<p>The object also has the following method:</p>
<dl>
<dt>confidence_interval(confidence_level=0.95)</dt><dd><p>Computes a confidence interval around the population
mean for the given confidence level.
The confidence interval is returned in a <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> with
fields <cite>low</cite> and <cite>high</cite>.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.10.0.</span></p>
</div>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The statistic is calculated as <code class="docutils literal notranslate"><span class="pre">(np.mean(a)</span> <span class="pre">-</span> <span class="pre">popmean)/se</span></code>, where
<code class="docutils literal notranslate"><span class="pre">se</span></code> is the standard error. Therefore, the statistic will be positive
when the sample mean is greater than the population mean and negative when
the sample mean is less than the population mean.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<p>Suppose we wish to test the null hypothesis that the mean of a population
is equal to 0.5. We choose a confidence level of 99%; that is, we will
reject the null hypothesis in favor of the alternative if the p-value is
less than 0.01.</p>
<p>When testing random variates from the standard uniform distribution, which
has a mean of 0.5, we expect the data to be consistent with the null
hypothesis most of the time.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvs</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">popmean</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">TtestResult(statistic=2.456308468440, pvalue=0.017628209047638, df=49)</span>
</pre></div>
</div>
<p>As expected, the p-value of 0.017 is not below our threshold of 0.01, so
we cannot reject the null hypothesis.</p>
<p>When testing data from the standard <em>normal</em> distribution, which has a mean
of 0, we would expect the null hypothesis to be rejected.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rvs</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">popmean</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-7.433605518875, pvalue=1.416760157221e-09, df=49)</span>
</pre></div>
</div>
<p>Indeed, the p-value is lower than our threshold of 0.01, so we reject the
null hypothesis in favor of the default “two-sided” alternative: the mean
of the population is <em>not</em> equal to 0.5.</p>
<p>However, suppose we were to test the null hypothesis against the
one-sided alternative that the mean of the population is <em>greater</em> than
0.5. Since the mean of the standard normal is less than 0.5, we would not
expect the null hypothesis to be rejected.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">popmean</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-7.433605518875, pvalue=0.99999999929, df=49)</span>
</pre></div>
</div>
<p>Unsurprisingly, with a p-value greater than our threshold, we would not
reject the null hypothesis.</p>
<p>Note that when working with a confidence level of 99%, a true null
hypothesis will be rejected approximately 1% of the time.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rvs</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">popmean</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="go">1</span>
</pre></div>
</div>
<p>Indeed, even though all 100 samples above were drawn from the standard
uniform distribution, which <em>does</em> have a population mean of 0.5, we would
mistakenly reject the null hypothesis for one of them.</p>
<p><cite>ttest_1samp</cite> can also compute a confidence interval around the population
mean.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rvs</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">popmean</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ci</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="p">(</span><span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ci</span>
<span class="go">ConfidenceInterval(low=-0.3193887540880017, high=0.2898583388980972)</span>
</pre></div>
</div>
<p>The bounds of the 95% confidence interval are the
minimum and maximum values of the parameter <cite>popmean</cite> for which the
p-value of the test would be 0.05.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">popmean</span><span class="o">=</span><span class="n">ci</span><span class="o">.</span><span class="n">low</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">popmean</span><span class="o">=</span><span class="n">ci</span><span class="o">.</span><span class="n">high</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">)</span>
</pre></div>
</div>
<p>Under certain assumptions about the population from which a sample
is drawn, the confidence interval with confidence level 95% is expected
to contain the true population mean in 95% of sample replications.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rvs</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">rvs</span><span class="p">,</span> <span class="n">popmean</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ci</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">confidence_interval</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contains_pop_mean</span> <span class="o">=</span> <span class="p">(</span><span class="n">ci</span><span class="o">.</span><span class="n">low</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">ci</span><span class="o">.</span><span class="n">high</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">contains_pop_mean</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="go">953</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.ttest_ind">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">ttest_ind</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.ttest_ind" title="Link to this definition">#</a></dt>
<dd><p>Calculate the T-test for the means of <em>two independent</em> samples of scores.</p>
<p>This is a test for the null hypothesis that 2 independent samples
have identical average (expected) values. This test assumes that the
populations have identical variances by default.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.17.0: </span>Use of argument(s) <code class="docutils literal notranslate"><span class="pre">{'trim',</span> <span class="pre">'equal_var',</span> <span class="pre">'alternative',</span> <span class="pre">'axis',</span> <span class="pre">'method',</span> <span class="pre">'nan_policy',</span> <span class="pre">'keepdims'}</span></code> by position is deprecated; beginning in 
SciPy 1.17.0, these will be keyword-only. Argument(s) <code class="docutils literal notranslate"><span class="pre">{'permutations',</span> <span class="pre">'random_state'}</span></code> are deprecated, whether passed by position or keyword; they will be removed in SciPy 1.17.0. Use <code class="docutils literal notranslate"><span class="pre">method</span></code> to perform a permutation test.</p>
</div>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>a, b</strong><span class="classifier">array_like</span></dt><dd><p>The arrays must have the same shape, except in the dimension
corresponding to <cite>axis</cite> (the first, by default).</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>equal_var</strong><span class="classifier">bool, optional</span></dt><dd><p>If True (default), perform a standard independent 2 sample test
that assumes equal population variances <a class="reference internal" href="#r3afbbc8ae2de-1" id="id114">[1]</a>.
If False, perform Welch’s t-test, which does not assume equal
population variance <a class="reference internal" href="#r3afbbc8ae2de-2" id="id115">[2]</a>.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 0.11.0.</span></p>
</div>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>permutations</strong><span class="classifier">non-negative int, np.inf, or None (default), optional</span></dt><dd><p>If 0 or None (default), use the t-distribution to calculate p-values.
Otherwise, <cite>permutations</cite> is  the number of random permutations that
will be used to estimate p-values using a permutation test. If
<cite>permutations</cite> equals or exceeds the number of distinct partitions of
the pooled data, an exact test is performed instead (i.e. each
distinct partition is used exactly once). See Notes for details.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.17.0: </span><cite>permutations</cite> is deprecated and will be removed in SciPy 1.7.0.
Use the <cite>n_resamples</cite> argument of <cite>PermutationMethod</cite>, instead,
and pass the instance as the <cite>method</cite> argument.</p>
</div>
</dd>
<dt><strong>random_state</strong><span class="classifier">{None, int, <cite>numpy.random.Generator</cite>,</span></dt><dd><blockquote>
<div><p><cite>numpy.random.RandomState</cite>}, optional</p>
</div></blockquote>
<p>If <cite>seed</cite> is None (or <cite>np.random</cite>), the <cite>numpy.random.RandomState</cite>
singleton is used.
If <cite>seed</cite> is an int, a new <code class="docutils literal notranslate"><span class="pre">RandomState</span></code> instance is used,
seeded with <cite>seed</cite>.
If <cite>seed</cite> is already a <code class="docutils literal notranslate"><span class="pre">Generator</span></code> or <code class="docutils literal notranslate"><span class="pre">RandomState</span></code> instance then
that instance is used.</p>
<p>Pseudorandom number generator state used to generate permutations
(used only when <cite>permutations</cite> is not None).</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 1.17.0: </span><cite>random_state</cite> is deprecated and will be removed in SciPy 1.7.0.
Use the <cite>rng</cite> argument of <cite>PermutationMethod</cite>, instead,
and pass the instance as the <cite>method</cite> argument.</p>
</div>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis.
The following options are available (default is ‘two-sided’):</p>
<ul class="simple">
<li><p>‘two-sided’: the means of the distributions underlying the samples
are unequal.</p></li>
<li><p>‘less’: the mean of the distribution underlying the first sample
is less than the mean of the distribution underlying the second
sample.</p></li>
<li><p>‘greater’: the mean of the distribution underlying the first
sample is greater than the mean of the distribution underlying
the second sample.</p></li>
</ul>
</dd>
<dt><strong>trim</strong><span class="classifier">float, optional</span></dt><dd><p>If nonzero, performs a trimmed (Yuen’s) t-test.
Defines the fraction of elements to be trimmed from each end of the
input samples. If 0 (default), no elements will be trimmed from either
side. The number of trimmed elements from each tail is the floor of the
trim times the number of elements. Valid range is [0, .5).</p>
</dd>
<dt><strong>method</strong><span class="classifier">ResamplingMethod, optional</span></dt><dd><p>Defines the method used to compute the p-value. If <cite>method</cite> is an
instance of <cite>PermutationMethod</cite>/<cite>MonteCarloMethod</cite>, the p-value is
computed using
<cite>scipy.stats.permutation_test</cite>/<cite>scipy.stats.monte_carlo_test</cite> with the
provided configuration options and other appropriate settings.
Otherwise, the p-value is computed by comparing the test statistic
against a theoretical t-distribution.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.15.0.</span></p>
</div>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>result</strong><span class="classifier"><cite>~scipy.stats._result_classes.TtestResult</cite></span></dt><dd><p>An object with the following attributes:</p>
<dl>
<dt>statistic<span class="classifier">float or ndarray</span></dt><dd><p>The t-statistic.</p>
</dd>
<dt>pvalue<span class="classifier">float or ndarray</span></dt><dd><p>The p-value associated with the given alternative.</p>
</dd>
<dt>df<span class="classifier">float or ndarray</span></dt><dd><p>The number of degrees of freedom used in calculation of the
t-statistic. This is always NaN for a permutation t-test.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.11.0.</span></p>
</div>
</dd>
</dl>
<p>The object also has the following method:</p>
<dl>
<dt>confidence_interval(confidence_level=0.95)</dt><dd><p>Computes a confidence interval around the difference in
population means for the given confidence level.
The confidence interval is returned in a <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> with
fields <code class="docutils literal notranslate"><span class="pre">low</span></code> and <code class="docutils literal notranslate"><span class="pre">high</span></code>.
When a permutation t-test is performed, the confidence interval
is not computed, and fields <code class="docutils literal notranslate"><span class="pre">low</span></code> and <code class="docutils literal notranslate"><span class="pre">high</span></code> contain NaN.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.11.0.</span></p>
</div>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Suppose we observe two independent samples, e.g. flower petal lengths, and
we are considering whether the two samples were drawn from the same
population (e.g. the same species of flower or two species with similar
petal characteristics) or two different populations.</p>
<p>The t-test quantifies the difference between the arithmetic means
of the two samples. The p-value quantifies the probability of observing
as or more extreme values assuming the null hypothesis, that the
samples are drawn from populations with the same population means, is true.
A p-value larger than a chosen threshold (e.g. 5% or 1%) indicates that
our observation is not so unlikely to have occurred by chance. Therefore,
we do not reject the null hypothesis of equal population means.
If the p-value is smaller than our threshold, then we have evidence
against the null hypothesis of equal population means.</p>
<p>By default, the p-value is determined by comparing the t-statistic of the
observed data against a theoretical t-distribution.</p>
<p>(In the following, note that the argument <cite>permutations</cite> itself is
deprecated, but a nearly identical test may be performed by creating
an instance of <cite>scipy.stats.PermutationMethod</cite> with <code class="docutils literal notranslate"><span class="pre">n_resamples=permutuations</span></code>
and passing it as the <cite>method</cite> argument.)
When <code class="docutils literal notranslate"><span class="pre">1</span> <span class="pre">&lt;</span> <span class="pre">permutations</span> <span class="pre">&lt;</span> <span class="pre">binom(n,</span> <span class="pre">k)</span></code>, where</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">k</span></code> is the number of observations in <cite>a</cite>,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n</span></code> is the total number of observations in <cite>a</cite> and <cite>b</cite>, and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">binom(n,</span> <span class="pre">k)</span></code> is the binomial coefficient (<code class="docutils literal notranslate"><span class="pre">n</span></code> choose <code class="docutils literal notranslate"><span class="pre">k</span></code>),</p></li>
</ul>
<p>the data are pooled (concatenated), randomly assigned to either group <cite>a</cite>
or <cite>b</cite>, and the t-statistic is calculated. This process is performed
repeatedly (<cite>permutation</cite> times), generating a distribution of the
t-statistic under the null hypothesis, and the t-statistic of the observed
data is compared to this distribution to determine the p-value.
Specifically, the p-value reported is the “achieved significance level”
(ASL) as defined in 4.4 of <a class="reference internal" href="#r3afbbc8ae2de-3" id="id116">[3]</a>. Note that there are other ways of
estimating p-values using randomized permutation tests; for other
options, see the more general <cite>permutation_test</cite>.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">permutations</span> <span class="pre">&gt;=</span> <span class="pre">binom(n,</span> <span class="pre">k)</span></code>, an exact test is performed: the data
are partitioned between the groups in each distinct way exactly once.</p>
<p>The permutation test can be computationally expensive and not necessarily
more accurate than the analytical test, but it does not make strong
assumptions about the shape of the underlying distribution.</p>
<p>Use of trimming is commonly referred to as the trimmed t-test. At times
called Yuen’s t-test, this is an extension of Welch’s t-test, with the
difference being the use of winsorized means in calculation of the variance
and the trimmed sample size in calculation of the statistic. Trimming is
recommended if the underlying distribution is long-tailed or contaminated
with outliers <a class="reference internal" href="#r3afbbc8ae2de-4" id="id117">[4]</a>.</p>
<p>The statistic is calculated as <code class="docutils literal notranslate"><span class="pre">(np.mean(a)</span> <span class="pre">-</span> <span class="pre">np.mean(b))/se</span></code>, where
<code class="docutils literal notranslate"><span class="pre">se</span></code> is the standard error. Therefore, the statistic will be positive
when the sample mean of <cite>a</cite> is greater than the sample mean of <cite>b</cite> and
negative when the sample mean of <cite>a</cite> is less than the sample mean of
<cite>b</cite>.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r3afbbc8ae2de-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id114">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test">https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test</a></p>
</div>
<div class="citation" id="r3afbbc8ae2de-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id115">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Welch%27s_t-test">https://en.wikipedia.org/wiki/Welch%27s_t-test</a></p>
</div>
<div class="citation" id="r3afbbc8ae2de-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id116">3</a><span class="fn-bracket">]</span></span>
<ol class="upperalpha simple" start="2">
<li><p>Efron and T. Hastie. Computer Age Statistical Inference. (2016).</p></li>
</ol>
</div>
<div class="citation" id="r3afbbc8ae2de-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id117">4</a><span class="fn-bracket">]</span></span>
<p>Yuen, Karen K. “The Two-Sample Trimmed t for Unequal Population
Variances.” Biometrika, vol. 61, no. 1, 1974, pp. 165-170. JSTOR,
www.jstor.org/stable/2334299. Accessed 30 Mar. 2021.</p>
</div>
<div class="citation" id="r3afbbc8ae2de-5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></span>
<p>Yuen, Karen K., and W. J. Dixon. “The Approximate Behaviour and
Performance of the Two-Sample Trimmed t.” Biometrika, vol. 60,
no. 2, 1973, pp. 369-374. JSTOR, www.jstor.org/stable/2334550.
Accessed 30 Mar. 2021.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
</pre></div>
</div>
<p>Test with sample with identical means:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rvs1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvs2</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs2</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-0.4390847099199348,</span>
<span class="go">            pvalue=0.6606952038870015,</span>
<span class="go">            df=998.0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs2</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-0.4390847099199348,</span>
<span class="go">            pvalue=0.6606952553131064,</span>
<span class="go">            df=997.4602304121448)</span>
</pre></div>
</div>
<p><cite>ttest_ind</cite> underestimates p for unequal variances:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rvs3</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs3</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-1.6370984482905417,</span>
<span class="go">            pvalue=0.1019251574705033,</span>
<span class="go">            df=998.0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs3</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-1.637098448290542,</span>
<span class="go">            pvalue=0.10202110497954867,</span>
<span class="go">            df=765.1098655246868)</span>
</pre></div>
</div>
<p>When <code class="docutils literal notranslate"><span class="pre">n1</span> <span class="pre">!=</span> <span class="pre">n2</span></code>, the equal variance t-statistic is no longer equal to the
unequal variance t-statistic:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rvs4</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs4</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-1.9481646859513422,</span>
<span class="go">            pvalue=0.05186270935842703,</span>
<span class="go">            df=598.0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs4</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-1.3146566100751664,</span>
<span class="go">            pvalue=0.1913495266513811,</span>
<span class="go">            df=110.41349083985212)</span>
</pre></div>
</div>
<p>T-test with different means, variance, and n:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rvs5</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs5</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-2.8415950600298774,</span>
<span class="go">            pvalue=0.0046418707568707885,</span>
<span class="go">            df=598.0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs5</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-1.8686598649188084,</span>
<span class="go">            pvalue=0.06434714193919686,</span>
<span class="go">            df=109.32167496550137)</span>
</pre></div>
</div>
<p>Take these two samples, one of which has an extreme tail.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="p">(</span><span class="mi">56</span><span class="p">,</span> <span class="mf">128.6</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mf">123.8</span><span class="p">,</span> <span class="mf">64.34</span><span class="p">,</span> <span class="mi">78</span><span class="p">,</span> <span class="mf">763.3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">2.9</span><span class="p">,</span> <span class="mf">4.2</span><span class="p">)</span>
</pre></div>
</div>
<p>Use the <cite>trim</cite> keyword to perform a trimmed (Yuen) t-test. For example,
using 20% trimming, <code class="docutils literal notranslate"><span class="pre">trim=.2</span></code>, the test will reduce the impact of one
(<code class="docutils literal notranslate"><span class="pre">np.floor(trim*len(a))</span></code>) element from each tail of sample <cite>a</cite>. It will
have no effect on sample <cite>b</cite> because <code class="docutils literal notranslate"><span class="pre">np.floor(trim*len(b))</span></code> is 0.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">trim</span><span class="o">=</span><span class="mf">.2</span><span class="p">)</span>
<span class="go">TtestResult(statistic=3.4463884028073513,</span>
<span class="go">            pvalue=0.01369338726499547,</span>
<span class="go">            df=6.0)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.ttest_rel">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">ttest_rel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.ttest_rel" title="Link to this definition">#</a></dt>
<dd><p>Calculate the t-test on TWO RELATED samples of scores, a and b.</p>
<p>This is a test for the null hypothesis that two related or
repeated samples have identical average (expected) values.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>a, b</strong><span class="classifier">array_like</span></dt><dd><p>The arrays must have the same shape.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>alternative</strong><span class="classifier">{‘two-sided’, ‘less’, ‘greater’}, optional</span></dt><dd><p>Defines the alternative hypothesis.
The following options are available (default is ‘two-sided’):</p>
<ul class="simple">
<li><p>‘two-sided’: the means of the distributions underlying the samples
are unequal.</p></li>
<li><p>‘less’: the mean of the distribution underlying the first sample
is less than the mean of the distribution underlying the second
sample.</p></li>
<li><p>‘greater’: the mean of the distribution underlying the first
sample is greater than the mean of the distribution underlying
the second sample.</p></li>
</ul>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.6.0.</span></p>
</div>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt><strong>result</strong><span class="classifier"><cite>~scipy.stats._result_classes.TtestResult</cite></span></dt><dd><p>An object with the following attributes:</p>
<dl>
<dt>statistic<span class="classifier">float or array</span></dt><dd><p>The t-statistic.</p>
</dd>
<dt>pvalue<span class="classifier">float or array</span></dt><dd><p>The p-value associated with the given alternative.</p>
</dd>
<dt>df<span class="classifier">float or array</span></dt><dd><p>The number of degrees of freedom used in calculation of the
t-statistic; this is one less than the size of the sample
(<code class="docutils literal notranslate"><span class="pre">a.shape[axis]</span></code>).</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.10.0.</span></p>
</div>
</dd>
</dl>
<p>The object also has the following method:</p>
<dl>
<dt>confidence_interval(confidence_level=0.95)</dt><dd><p>Computes a confidence interval around the difference in
population means for the given confidence level.
The confidence interval is returned in a <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> with
fields <cite>low</cite> and <cite>high</cite>.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.10.0.</span></p>
</div>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Examples for use are scores of the same set of student in
different exams, or repeated sampling from the same units. The
test measures whether the average score differs significantly
across samples (e.g. exams). If we observe a large p-value, for
example greater than 0.05 or 0.1 then we cannot reject the null
hypothesis of identical average scores. If the p-value is smaller
than the threshold, e.g. 1%, 5% or 10%, then we reject the null
hypothesis of equal averages. Small p-values are associated with
large t-statistics.</p>
<p>The t-statistic is calculated as <code class="docutils literal notranslate"><span class="pre">np.mean(a</span> <span class="pre">-</span> <span class="pre">b)/se</span></code>, where <code class="docutils literal notranslate"><span class="pre">se</span></code> is the
standard error. Therefore, the t-statistic will be positive when the sample
mean of <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-</span> <span class="pre">b</span></code> is greater than zero and negative when the sample mean of
<code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">-</span> <span class="pre">b</span></code> is less than zero.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/T-test#Dependent_t-test_for_paired_samples">https://en.wikipedia.org/wiki/T-test#Dependent_t-test_for_paired_samples</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rvs1</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvs2</span> <span class="o">=</span> <span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">... </span>        <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_rel</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs2</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-0.4549717054410304, pvalue=0.6493274702088672, df=499)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rvs3</span> <span class="o">=</span> <span class="p">(</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="gp">... </span>        <span class="o">+</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_rel</span><span class="p">(</span><span class="n">rvs1</span><span class="p">,</span> <span class="n">rvs3</span><span class="p">)</span>
<span class="go">TtestResult(statistic=-5.879467544540889, pvalue=7.540777129099917e-09, df=499)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.tvar">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">tvar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.tvar" title="Link to this definition">#</a></dt>
<dd><p>Compute the trimmed variance.</p>
<p>This function computes the sample variance of an array of values,
while ignoring values which are outside of given <cite>limits</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Array of values.</p>
</dd>
<dt><strong>limits</strong><span class="classifier">None or (lower limit, upper limit), optional</span></dt><dd><p>Values in the input array less than the lower limit or greater than the
upper limit will be ignored. When limits is None, then all values are
used. Either of the limit values in the tuple can also be None
representing a half-open interval.  The default value is None.</p>
</dd>
<dt><strong>inclusive</strong><span class="classifier">(bool, bool), optional</span></dt><dd><p>A tuple consisting of the (lower flag, upper flag).  These flags
determine whether values exactly equal to the lower or upper limits
are included.  The default value is (True, True).</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>Delta degrees of freedom.  Default is 1.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>tvar</strong><span class="classifier">float</span></dt><dd><p>Trimmed variance.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p><cite>tvar</cite> computes the unbiased sample variance, i.e. it uses a correction
factor <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">/</span> <span class="pre">(n</span> <span class="pre">-</span> <span class="pre">1)</span></code>.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tvar</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">35.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">tvar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">17</span><span class="p">))</span>
<span class="go">20.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.variation">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">variation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.variation" title="Link to this definition">#</a></dt>
<dd><p>Compute the coefficient of variation.</p>
<p>The coefficient of variation is the standard deviation divided by the
mean.  This function is equivalent to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="n">ddof</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>The default for <code class="docutils literal notranslate"><span class="pre">ddof</span></code> is 0, but many definitions of the coefficient
of variation use the square root of the unbiased sample variance
for the sample standard deviation, which corresponds to <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code>.</p>
<p>The function does not take the absolute value of the mean of the data,
so the return value is negative if the mean is negative.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>Input array.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>Gives the “Delta Degrees Of Freedom” used when computing the
standard deviation.  The divisor used in the calculation of the
standard deviation is <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">-</span> <span class="pre">ddof</span></code>, where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of
elements.  <cite>ddof</cite> must be less than <code class="docutils literal notranslate"><span class="pre">N</span></code>; if it isn’t, the result
will be <code class="docutils literal notranslate"><span class="pre">nan</span></code> or <code class="docutils literal notranslate"><span class="pre">inf</span></code>, depending on <code class="docutils literal notranslate"><span class="pre">N</span></code> and the values in
the array.  By default <cite>ddof</cite> is zero for backwards compatibility,
but it is recommended to use <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code> to ensure that the sample
standard deviation is computed as the square root of the unbiased
sample variance.</p>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>variation</strong><span class="classifier">ndarray</span></dt><dd><p>The calculated variation along the requested axis.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>There are several edge cases that are handled without generating a
warning:</p>
<ul class="simple">
<li><p>If both the mean and the standard deviation are zero, <code class="docutils literal notranslate"><span class="pre">nan</span></code>
is returned.</p></li>
<li><p>If the mean is zero and the standard deviation is nonzero, <code class="docutils literal notranslate"><span class="pre">inf</span></code>
is returned.</p></li>
<li><p>If the input has length zero (either because the array has zero
length, or all the input values are <code class="docutils literal notranslate"><span class="pre">nan</span></code> and <code class="docutils literal notranslate"><span class="pre">nan_policy</span></code> is
<code class="docutils literal notranslate"><span class="pre">'omit'</span></code>), <code class="docutils literal notranslate"><span class="pre">nan</span></code> is returned.</p></li>
<li><p>If the input contains <code class="docutils literal notranslate"><span class="pre">inf</span></code>, <code class="docutils literal notranslate"><span class="pre">nan</span></code> is returned.</p></li>
</ul>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rd982c6588744-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>Zwillinger, D. and Kokoska, S. (2000). CRC Standard
Probability and Statistics Tables and Formulae. Chapman &amp; Hall: New
York. 2000.</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">variation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">variation</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">0.5270462766947299</span>
</pre></div>
</div>
<p>Compute the variation along a given dimension of an array that contains
a few <code class="docutils literal notranslate"><span class="pre">nan</span></code> values:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span>  <span class="mf">10.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">19.0</span><span class="p">,</span> <span class="mf">23.0</span><span class="p">,</span> <span class="mf">29.0</span><span class="p">,</span> <span class="mf">98.0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span>  <span class="mf">29.0</span><span class="p">,</span>   <span class="mf">30.0</span><span class="p">,</span> <span class="mf">32.0</span><span class="p">,</span> <span class="mf">33.0</span><span class="p">,</span> <span class="mf">35.0</span><span class="p">,</span> <span class="mf">56.0</span><span class="p">,</span> <span class="mf">57.0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mf">12.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">16.0</span><span class="p">,</span> <span class="mf">16.0</span><span class="p">,</span> <span class="mf">17.0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">variation</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;omit&#39;</span><span class="p">)</span>
<span class="go">array([1.05109361, 0.31428986, 0.146483  ])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.wilcoxon">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">wilcoxon</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.wilcoxon" title="Link to this definition">#</a></dt>
<dd><p>Calculate the Wilcoxon signed-rank test.</p>
<p>The Wilcoxon signed-rank test tests the null hypothesis that two
related paired samples come from the same distribution. In particular,
it tests whether the distribution of the differences <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">-</span> <span class="pre">y</span></code> is symmetric
about zero. It is a non-parametric version of the paired T-test.</p>
<dl class="field-list">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl>
<dt><strong>x</strong><span class="classifier">array_like</span></dt><dd><p>Either the first set of measurements (in which case <code class="docutils literal notranslate"><span class="pre">y</span></code> is the second
set of measurements), or the differences between two sets of
measurements (in which case <code class="docutils literal notranslate"><span class="pre">y</span></code> is not to be specified.)  Must be
one-dimensional.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array_like, optional</span></dt><dd><p>Either the second set of measurements (if <code class="docutils literal notranslate"><span class="pre">x</span></code> is the first set of
measurements), or not specified (if <code class="docutils literal notranslate"><span class="pre">x</span></code> is the differences between
two sets of measurements.)  Must be one-dimensional.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When <cite>y</cite> is provided, <cite>wilcoxon</cite> calculates the test statistic
based on the ranks of the absolute values of <code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">-</span> <span class="pre">y</span></code>.
Roundoff error in the subtraction can result in elements of <code class="docutils literal notranslate"><span class="pre">d</span></code>
being assigned different ranks even when they would be tied with
exact arithmetic. Rather than passing <cite>x</cite> and <cite>y</cite> separately,
consider computing the difference <code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">-</span> <span class="pre">y</span></code>, rounding as needed to
ensure that only truly unique elements are numerically distinct,
and passing the result as <cite>x</cite>, leaving <cite>y</cite> at the default (None).</p>
</div>
</dd>
<dt><strong>zero_method</strong><span class="classifier">{“wilcox”, “pratt”, “zsplit”}, optional</span></dt><dd><p>There are different conventions for handling pairs of observations
with equal values (“zero-differences”, or “zeros”).</p>
<ul class="simple">
<li><p>“wilcox”: Discards all zero-differences (default); see <a class="reference internal" href="#r0289633e5f45-4" id="id124">[4]</a>.</p></li>
<li><p>“pratt”: Includes zero-differences in the ranking process,
but drops the ranks of the zeros (more conservative); see <a class="reference internal" href="#r0289633e5f45-3" id="id125">[3]</a>.
In this case, the normal approximation is adjusted as in <a class="reference internal" href="#r0289633e5f45-5" id="id126">[5]</a>.</p></li>
<li><p>“zsplit”: Includes zero-differences in the ranking process and
splits the zero rank between positive and negative ones.</p></li>
</ul>
</dd>
<dt><strong>correction</strong><span class="classifier">bool, optional</span></dt><dd><p>If True, apply continuity correction by adjusting the Wilcoxon rank
statistic by 0.5 towards the mean value when computing the
z-statistic if a normal approximation is used.  Default is False.</p>
</dd>
<dt><strong>alternative</strong><span class="classifier">{“two-sided”, “greater”, “less”}, optional</span></dt><dd><p>Defines the alternative hypothesis. Default is ‘two-sided’.
In the following, let <code class="docutils literal notranslate"><span class="pre">d</span></code> represent the difference between the paired
samples: <code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">-</span> <span class="pre">y</span></code> if both <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> are provided, or
<code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">x</span></code> otherwise.</p>
<ul class="simple">
<li><p>‘two-sided’: the distribution underlying <code class="docutils literal notranslate"><span class="pre">d</span></code> is not symmetric
about zero.</p></li>
<li><p>‘less’: the distribution underlying <code class="docutils literal notranslate"><span class="pre">d</span></code> is stochastically less
than a distribution symmetric about zero.</p></li>
<li><p>‘greater’: the distribution underlying <code class="docutils literal notranslate"><span class="pre">d</span></code> is stochastically
greater than a distribution symmetric about zero.</p></li>
</ul>
</dd>
<dt><strong>method</strong><span class="classifier">{“auto”, “exact”, “asymptotic”} or <cite>PermutationMethod</cite> instance, optional</span></dt><dd><p>Method to calculate the p-value, see Notes. Default is “auto”.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, default: 0</span></dt><dd><p>If an int, the axis of the input along which to compute the statistic.
The statistic of each axis-slice (e.g. row) of the input will appear in a
corresponding element of the output.
If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the input will be raveled before computing the statistic.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘omit’, ‘raise’}</span></dt><dd><p>Defines how to handle input NaNs.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">propagate</span></code>: if a NaN is present in the axis slice (e.g. row) along
which the  statistic is computed, the corresponding entry of the output
will be NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">omit</span></code>: NaNs will be omitted when performing the calculation.
If insufficient data remains in the axis slice along which the
statistic is computed, the corresponding entry of the output will be
NaN.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raise</span></code>: if a NaN is present, a <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> will be raised.</p></li>
</ul>
</dd>
<dt><strong>keepdims</strong><span class="classifier">bool, default: False</span></dt><dd><p>If this is set to True, the axes which are reduced are left
in the result as dimensions with size one. With this option,
the result will broadcast correctly against the input array.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl>
<dt>An object with the following attributes.</dt><dd></dd>
<dt><strong>statistic</strong><span class="classifier">array_like</span></dt><dd><p>If <cite>alternative</cite> is “two-sided”, the sum of the ranks of the
differences above or below zero, whichever is smaller.
Otherwise the sum of the ranks of the differences above zero.</p>
</dd>
<dt><strong>pvalue</strong><span class="classifier">array_like</span></dt><dd><p>The p-value for the test depending on <cite>alternative</cite> and <cite>method</cite>.</p>
</dd>
<dt><strong>zstatistic</strong><span class="classifier">array_like</span></dt><dd><p>When <code class="docutils literal notranslate"><span class="pre">method</span> <span class="pre">=</span> <span class="pre">'asymptotic'</span></code>, this is the normalized z-statistic:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="n">mn</span> <span class="o">-</span> <span class="n">d</span><span class="p">)</span> <span class="o">/</span> <span class="n">se</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">T</span></code> is <cite>statistic</cite> as defined above, <code class="docutils literal notranslate"><span class="pre">mn</span></code> is the mean of the
distribution under the null hypothesis, <code class="docutils literal notranslate"><span class="pre">d</span></code> is a continuity
correction, and <code class="docutils literal notranslate"><span class="pre">se</span></code> is the standard error.
When <code class="docutils literal notranslate"><span class="pre">method</span> <span class="pre">!=</span> <span class="pre">'asymptotic'</span></code>, this attribute is not available.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#barotropy.mcerp.stats.kruskal" title="barotropy.mcerp.stats.kruskal"><code class="xref py py-func docutils literal notranslate"><span class="pre">kruskal()</span></code></a>, <a class="reference internal" href="#barotropy.mcerp.stats.mannwhitneyu" title="barotropy.mcerp.stats.mannwhitneyu"><code class="xref py py-func docutils literal notranslate"><span class="pre">mannwhitneyu()</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>In the following, let <code class="docutils literal notranslate"><span class="pre">d</span></code> represent the difference between the paired
samples: <code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">x</span> <span class="pre">-</span> <span class="pre">y</span></code> if both <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> are provided, or <code class="docutils literal notranslate"><span class="pre">d</span> <span class="pre">=</span> <span class="pre">x</span></code>
otherwise. Assume that all elements of <code class="docutils literal notranslate"><span class="pre">d</span></code> are independent and
identically distributed observations, and all are distinct and nonzero.</p>
<ul class="simple">
<li><p>When <code class="docutils literal notranslate"><span class="pre">len(d)</span></code> is sufficiently large, the null distribution of the
normalized test statistic (<cite>zstatistic</cite> above) is approximately normal,
and <code class="docutils literal notranslate"><span class="pre">method</span> <span class="pre">=</span> <span class="pre">'asymptotic'</span></code> can be used to compute the p-value.</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">len(d)</span></code> is small, the normal approximation may not be accurate,
and <code class="docutils literal notranslate"><span class="pre">method='exact'</span></code> is preferred (at the cost of additional
execution time).</p></li>
<li><p>The default, <code class="docutils literal notranslate"><span class="pre">method='auto'</span></code>, selects between the two:
<code class="docutils literal notranslate"><span class="pre">method='exact'</span></code> is used when <code class="docutils literal notranslate"><span class="pre">len(d)</span> <span class="pre">&lt;=</span> <span class="pre">50</span></code>, and
<code class="docutils literal notranslate"><span class="pre">method='asymptotic'</span></code> is used otherwise.</p></li>
</ul>
<p>The presence of “ties” (i.e. not all elements of <code class="docutils literal notranslate"><span class="pre">d</span></code> are unique) or
“zeros” (i.e. elements of <code class="docutils literal notranslate"><span class="pre">d</span></code> are zero) changes the null distribution
of the test statistic, and <code class="docutils literal notranslate"><span class="pre">method='exact'</span></code> no longer calculates
the exact p-value. If <code class="docutils literal notranslate"><span class="pre">method='asymptotic'</span></code>, the z-statistic is adjusted
for more accurate comparison against the standard normal, but still,
for finite sample sizes, the standard normal is only an approximation of
the true null distribution of the z-statistic. For such situations, the
<cite>method</cite> parameter also accepts instances of <cite>PermutationMethod</cite>. In this
case, the p-value is computed using <cite>permutation_test</cite> with the provided
configuration options and other appropriate settings.</p>
<p>The presence of ties and zeros affects the resolution of <code class="docutils literal notranslate"><span class="pre">method='auto'</span></code>
accordingly: exhasutive permutations are performed when <code class="docutils literal notranslate"><span class="pre">len(d)</span> <span class="pre">&lt;=</span> <span class="pre">13</span></code>,
and the asymptotic method is used otherwise. Note that they asymptotic
method may not be very accurate even for <code class="docutils literal notranslate"><span class="pre">len(d)</span> <span class="pre">&gt;</span> <span class="pre">14</span></code>; the threshold
was chosen as a compromise between execution time and accuracy under the
constraint that the results must be deterministic. Consider providing an
instance of <cite>PermutationMethod</cite> method manually, choosing the
<code class="docutils literal notranslate"><span class="pre">n_resamples</span></code> parameter to balance time constraints and accuracy
requirements.</p>
<p>Please also note that in the edge case that all elements of <code class="docutils literal notranslate"><span class="pre">d</span></code> are zero,
the p-value relying on the normal approximaton cannot be computed (NaN)
if <code class="docutils literal notranslate"><span class="pre">zero_method='wilcox'</span></code> or <code class="docutils literal notranslate"><span class="pre">zero_method='pratt'</span></code>.</p>
<p>Beginning in SciPy 1.9, <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code> inputs (not recommended for new
code) are converted to <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> before the calculation is performed. In
this case, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> of appropriate shape
rather than a 2D <code class="docutils literal notranslate"><span class="pre">np.matrix</span></code>. Similarly, while masked elements of masked
arrays are ignored, the output will be a scalar or <code class="docutils literal notranslate"><span class="pre">np.ndarray</span></code> rather than a
masked array with <code class="docutils literal notranslate"><span class="pre">mask=False</span></code>.</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="r0289633e5f45-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test">https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test</a></p>
</div>
<div class="citation" id="r0289633e5f45-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Conover, W.J., Practical Nonparametric Statistics, 1971.</p>
</div>
<div class="citation" id="r0289633e5f45-3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id125">3</a><span class="fn-bracket">]</span></span>
<p>Pratt, J.W., Remarks on Zeros and Ties in the Wilcoxon Signed
Rank Procedures, Journal of the American Statistical Association,
Vol. 54, 1959, pp. 655-667. <a href="#id127"><span class="problematic" id="id128">:doi:`10.1080/01621459.1959.10501526`</span></a></p>
</div>
<div class="citation" id="r0289633e5f45-4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id124">1</a>,<a role="doc-backlink" href="#id138">2</a>)</span>
<p>Wilcoxon, F., Individual Comparisons by Ranking Methods,
Biometrics Bulletin, Vol. 1, 1945, pp. 80-83. <a href="#id129"><span class="problematic" id="id130">:doi:`10.2307/3001968`</span></a></p>
</div>
<div class="citation" id="r0289633e5f45-5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id126">5</a><span class="fn-bracket">]</span></span>
<p>Cureton, E.E., The Normal Approximation to the Signed-Rank
Sampling Distribution When Zero Differences are Present,
Journal of the American Statistical Association, Vol. 62, 1967,
pp. 1068-1069. <a href="#id131"><span class="problematic" id="id132">:doi:`10.1080/01621459.1967.10500917`</span></a></p>
</div>
</div>
<p class="rubric">Examples</p>
<p>In <a class="reference internal" href="#r0289633e5f45-4" id="id138">[4]</a>, the differences in height between cross- and self-fertilized
corn plants is given as follows:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">41</span><span class="p">,</span> <span class="o">-</span><span class="mi">48</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="o">-</span><span class="mi">67</span><span class="p">,</span> <span class="mi">75</span><span class="p">]</span>
</pre></div>
</div>
<p>Cross-fertilized plants appear to be higher. To test the null
hypothesis that there is no height difference, we can apply the
two-sided test:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">wilcoxon</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">wilcoxon</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">(24.0, 0.041259765625)</span>
</pre></div>
</div>
<p>Hence, we would reject the null hypothesis at a confidence level of 5%,
concluding that there is a difference in height between the groups.
To confirm that the median of the differences can be assumed to be
positive, we use:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">wilcoxon</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">(96.0, 0.0206298828125)</span>
</pre></div>
</div>
<p>This shows that the null hypothesis that the median is negative can be
rejected at a confidence level of 5% in favor of the alternative that
the median is greater than zero. The p-values above are exact. Using the
normal approximation gives very similar values:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">wilcoxon</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;asymptotic&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">pvalue</span>
<span class="go">(24.0, 0.04088813291185591)</span>
</pre></div>
</div>
<p>Note that the statistic changed to 96 in the one-sided case (the sum
of ranks of positive differences) whereas it is 24 in the two-sided
case (the minimum of sum of ranks above and below zero).</p>
<p>In the example above, the differences in height between paired plants are
provided to <cite>wilcoxon</cite> directly. Alternatively, <cite>wilcoxon</cite> accepts two
samples of equal length, calculates the differences between paired
elements, then performs the test. Consider the samples <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.825</span><span class="p">,</span> <span class="mf">0.375</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.525</span><span class="p">,</span> <span class="mf">0.775</span><span class="p">,</span> <span class="mf">0.325</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">wilcoxon</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span>
<span class="go">WilcoxonResult(statistic=5.0, pvalue=0.5625)</span>
</pre></div>
</div>
<p>Note that had we calculated the differences by hand, the test would have
produced different results:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.025</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref</span> <span class="o">=</span> <span class="n">wilcoxon</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ref</span>
<span class="go">WilcoxonResult(statistic=6.0, pvalue=0.5)</span>
</pre></div>
</div>
<p>The substantial difference is due to roundoff error in the results of
<code class="docutils literal notranslate"><span class="pre">x-y</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">y</span><span class="p">)</span>
<span class="go">array([2.08166817e-17, 6.93889390e-17, 1.38777878e-17, 4.16333634e-17])</span>
</pre></div>
</div>
<p>Even though we expected all the elements of <code class="docutils literal notranslate"><span class="pre">(x-y)[1:]</span></code> to have the same
magnitude <code class="docutils literal notranslate"><span class="pre">0.05</span></code>, they have slightly different magnitudes in practice,
and therefore are assigned different ranks in the test. Before performing
the test, consider calculating <code class="docutils literal notranslate"><span class="pre">d</span></code> and adjusting it as necessary to
ensure that theoretically identically values are not numerically distinct.
For example:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">around</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">,</span> <span class="n">decimals</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">wilcoxon</span><span class="p">(</span><span class="n">d2</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;greater&#39;</span><span class="p">)</span>
<span class="go">WilcoxonResult(statistic=6.0, pvalue=0.5)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.wrap">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">wrap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/barotropy/mcerp/stats.html#wrap"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#barotropy.mcerp.stats.wrap" title="Link to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.zmap">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">zmap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.zmap" title="Link to this definition">#</a></dt>
<dd><p>Calculate the relative z-scores.</p>
<p>Return an array of z-scores, i.e., scores that are standardized to
zero mean and unit variance, where mean and variance are calculated
from the comparison array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>scores</strong><span class="classifier">array_like</span></dt><dd><p>The input for which z-scores are calculated.</p>
</dd>
<dt><strong>compare</strong><span class="classifier">array_like</span></dt><dd><p>The input from which the mean and standard deviation of the
normalization are taken; assumed to have the same dimension as
<cite>scores</cite>.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>Axis over which mean and variance of <cite>compare</cite> are calculated.
Default is 0. If None, compute over the whole array <cite>scores</cite>.</p>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>Degrees of freedom correction in the calculation of the
standard deviation. Default is 0.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘raise’, ‘omit’}, optional</span></dt><dd><p>Defines how to handle the occurrence of nans in <cite>compare</cite>.
‘propagate’ returns nan, ‘raise’ raises an exception, ‘omit’
performs the calculations ignoring nan values. Default is
‘propagate’. Note that when the value is ‘omit’, nans in <cite>scores</cite>
also propagate to the output, but they do not affect the z-scores
computed for the non-nan values.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>zscore</strong><span class="classifier">array_like</span></dt><dd><p>Z-scores, in the same shape as <cite>scores</cite>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This function preserves ndarray subclasses, and works also with
matrices and masked arrays (it uses <cite>asanyarray</cite> instead of
<cite>asarray</cite> for parameters).</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">zmap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">zmap</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">array([-1.06066017,  0.        ,  0.35355339,  0.70710678])</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="barotropy.mcerp.stats.zscore">
<span class="sig-prename descclassname"><span class="pre">barotropy.mcerp.stats.</span></span><span class="sig-name descname"><span class="pre">zscore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#barotropy.mcerp.stats.zscore" title="Link to this definition">#</a></dt>
<dd><p>Compute the z score.</p>
<p>Compute the z score of each value in the sample, relative to the
sample mean and standard deviation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>a</strong><span class="classifier">array_like</span></dt><dd><p>An array like object containing the sample data.</p>
</dd>
<dt><strong>axis</strong><span class="classifier">int or None, optional</span></dt><dd><p>Axis along which to operate. Default is 0. If None, compute over
the whole array <cite>a</cite>.</p>
</dd>
<dt><strong>ddof</strong><span class="classifier">int, optional</span></dt><dd><p>Degrees of freedom correction in the calculation of the
standard deviation. Default is 0.</p>
</dd>
<dt><strong>nan_policy</strong><span class="classifier">{‘propagate’, ‘raise’, ‘omit’}, optional</span></dt><dd><p>Defines how to handle when input contains nan. ‘propagate’ returns nan,
‘raise’ throws an error, ‘omit’ performs the calculations ignoring nan
values. Default is ‘propagate’.  Note that when the value is ‘omit’,
nans in the input also propagate to the output, but they do not affect
the z-scores computed for the non-nan values.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><dl class="simple">
<dt><strong>zscore</strong><span class="classifier">array_like</span></dt><dd><p>The z-scores, standardized by mean and standard deviation of
input array <cite>a</cite>.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.mean</span></code></dt><dd><p>Arithmetic average</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.std</span></code></dt><dd><p>Arithmetic standard deviation</p>
</dd>
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">scipy.stats.gzscore</span></code></dt><dd><p>Geometric standard score</p>
</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This function preserves ndarray subclasses, and works also with
matrices and masked arrays (it uses <cite>asanyarray</cite> instead of
<cite>asarray</cite> for parameters).</p>
<p class="rubric">References</p>
<div role="list" class="citation-list">
<div class="citation" id="rd678efbcabdf-1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<p>“Standard score”, <em>Wikipedia</em>,
<a class="reference external" href="https://en.wikipedia.org/wiki/Standard_score">https://en.wikipedia.org/wiki/Standard_score</a>.</p>
</div>
<div class="citation" id="rd678efbcabdf-2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></span>
<p>Huck, S. W., Cross, T. L., Clark, S. B, “Overcoming misconceptions
about Z-scores”, Teaching Statistics, vol. 8, pp. 38-40, 1986</p>
</div>
</div>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mf">0.7972</span><span class="p">,</span>  <span class="mf">0.0767</span><span class="p">,</span>  <span class="mf">0.4383</span><span class="p">,</span>  <span class="mf">0.7866</span><span class="p">,</span>  <span class="mf">0.8091</span><span class="p">,</span>
<span class="gp">... </span>               <span class="mf">0.1954</span><span class="p">,</span>  <span class="mf">0.6307</span><span class="p">,</span>  <span class="mf">0.6599</span><span class="p">,</span>  <span class="mf">0.1065</span><span class="p">,</span>  <span class="mf">0.0508</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">zscore</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">array([ 1.1273, -1.247 , -0.0552,  1.0923,  1.1664, -0.8559,  0.5786,</span>
<span class="go">        0.6748, -1.1488, -1.3324])</span>
</pre></div>
</div>
<p>Computing along a specified axis, using n-1 degrees of freedom
(<code class="docutils literal notranslate"><span class="pre">ddof=1</span></code>) to calculate the standard deviation:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">0.3148</span><span class="p">,</span>  <span class="mf">0.0478</span><span class="p">,</span>  <span class="mf">0.6243</span><span class="p">,</span>  <span class="mf">0.4608</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span> <span class="mf">0.7149</span><span class="p">,</span>  <span class="mf">0.0775</span><span class="p">,</span>  <span class="mf">0.6072</span><span class="p">,</span>  <span class="mf">0.9656</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span> <span class="mf">0.6341</span><span class="p">,</span>  <span class="mf">0.1403</span><span class="p">,</span>  <span class="mf">0.9759</span><span class="p">,</span>  <span class="mf">0.4064</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span> <span class="mf">0.5918</span><span class="p">,</span>  <span class="mf">0.6948</span><span class="p">,</span>  <span class="mf">0.904</span> <span class="p">,</span>  <span class="mf">0.3721</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span> <span class="mf">0.0921</span><span class="p">,</span>  <span class="mf">0.2481</span><span class="p">,</span>  <span class="mf">0.1188</span><span class="p">,</span>  <span class="mf">0.1366</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">zscore</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">array([[-0.19264823, -1.28415119,  1.07259584,  0.40420358],</span>
<span class="go">       [ 0.33048416, -1.37380874,  0.04251374,  1.00081084],</span>
<span class="go">       [ 0.26796377, -1.12598418,  1.23283094, -0.37481053],</span>
<span class="go">       [-0.22095197,  0.24468594,  1.19042819, -1.21416216],</span>
<span class="go">       [-0.82780366,  1.4457416 , -0.43867764, -0.1792603 ]])</span>
</pre></div>
</div>
<p>An example with <code class="docutils literal notranslate"><span class="pre">nan_policy='omit'</span></code>:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">25.11</span><span class="p">,</span> <span class="mf">30.10</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="mf">32.02</span><span class="p">,</span> <span class="mf">43.15</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mf">14.95</span><span class="p">,</span> <span class="mf">16.06</span><span class="p">,</span> <span class="mf">121.25</span><span class="p">,</span> <span class="mf">94.35</span><span class="p">,</span> <span class="mf">29.81</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">zscore</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nan_policy</span><span class="o">=</span><span class="s1">&#39;omit&#39;</span><span class="p">)</span>
<span class="go">array([[-1.13490897, -0.37830299,         nan, -0.08718406,  1.60039602],</span>
<span class="go">       [-0.91611681, -0.89090508,  1.4983032 ,  0.88731639, -0.5785977 ]])</span>
</pre></div>
</div>
</dd></dl>

</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mcerp-real-time-latin-hypercube-sampling-based-monte-carlo-error-propagation">mcerp: Real-time latin-hypercube-sampling-based Monte Carlo Error Propagation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.anderson"><code class="docutils literal notranslate"><span class="pre">anderson()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ansari"><code class="docutils literal notranslate"><span class="pre">ansari()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.bartlett"><code class="docutils literal notranslate"><span class="pre">bartlett()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.bayes_mvs"><code class="docutils literal notranslate"><span class="pre">bayes_mvs()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.binom_test"><code class="docutils literal notranslate"><span class="pre">binom_test()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.chisquare"><code class="docutils literal notranslate"><span class="pre">chisquare()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.describe"><code class="docutils literal notranslate"><span class="pre">describe()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.f_oneway"><code class="docutils literal notranslate"><span class="pre">f_oneway()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.fligner"><code class="docutils literal notranslate"><span class="pre">fligner()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.friedmanchisquare"><code class="docutils literal notranslate"><span class="pre">friedmanchisquare()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.gmean"><code class="docutils literal notranslate"><span class="pre">gmean()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.hmean"><code class="docutils literal notranslate"><span class="pre">hmean()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kendalltau"><code class="docutils literal notranslate"><span class="pre">kendalltau()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kruskal"><code class="docutils literal notranslate"><span class="pre">kruskal()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ks_2samp"><code class="docutils literal notranslate"><span class="pre">ks_2samp()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kstest"><code class="docutils literal notranslate"><span class="pre">kstest()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kurtosis"><code class="docutils literal notranslate"><span class="pre">kurtosis()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.kurtosistest"><code class="docutils literal notranslate"><span class="pre">kurtosistest()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.levene"><code class="docutils literal notranslate"><span class="pre">levene()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.linregress"><code class="docutils literal notranslate"><span class="pre">linregress()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.mannwhitneyu"><code class="docutils literal notranslate"><span class="pre">mannwhitneyu()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.mode"><code class="docutils literal notranslate"><span class="pre">mode()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.moment"><code class="docutils literal notranslate"><span class="pre">moment()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.mood"><code class="docutils literal notranslate"><span class="pre">mood()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.normaltest"><code class="docutils literal notranslate"><span class="pre">normaltest()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.pearsonr"><code class="docutils literal notranslate"><span class="pre">pearsonr()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.percentileofscore"><code class="docutils literal notranslate"><span class="pre">percentileofscore()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.pointbiserialr"><code class="docutils literal notranslate"><span class="pre">pointbiserialr()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.rankdata"><code class="docutils literal notranslate"><span class="pre">rankdata()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ranksums"><code class="docutils literal notranslate"><span class="pre">ranksums()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.scoreatpercentile"><code class="docutils literal notranslate"><span class="pre">scoreatpercentile()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.sem"><code class="docutils literal notranslate"><span class="pre">sem()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.shapiro"><code class="docutils literal notranslate"><span class="pre">shapiro()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.skew"><code class="docutils literal notranslate"><span class="pre">skew()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.skewtest"><code class="docutils literal notranslate"><span class="pre">skewtest()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.spearmanr"><code class="docutils literal notranslate"><span class="pre">spearmanr()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tmax"><code class="docutils literal notranslate"><span class="pre">tmax()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tmean"><code class="docutils literal notranslate"><span class="pre">tmean()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tmin"><code class="docutils literal notranslate"><span class="pre">tmin()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tsem"><code class="docutils literal notranslate"><span class="pre">tsem()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tstd"><code class="docutils literal notranslate"><span class="pre">tstd()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ttest_1samp"><code class="docutils literal notranslate"><span class="pre">ttest_1samp()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ttest_ind"><code class="docutils literal notranslate"><span class="pre">ttest_ind()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.ttest_rel"><code class="docutils literal notranslate"><span class="pre">ttest_rel()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.tvar"><code class="docutils literal notranslate"><span class="pre">tvar()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.variation"><code class="docutils literal notranslate"><span class="pre">variation()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.wilcoxon"><code class="docutils literal notranslate"><span class="pre">wilcoxon()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.wrap"><code class="docutils literal notranslate"><span class="pre">wrap()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.zmap"><code class="docutils literal notranslate"><span class="pre">zmap()</span></code></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#barotropy.mcerp.stats.zscore"><code class="docutils literal notranslate"><span class="pre">zscore()</span></code></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Roberto Agromayor, Simone Parisi, Amit Kumar, Fredrik Haglind
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Sustainable Thermal Power DTU.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>